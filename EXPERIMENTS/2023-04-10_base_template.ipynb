{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting some quick picks for 2023-04-08\n",
    "\n",
    "http://ufcstats.com/event-details/3dc3022232b79c7a\n",
    "\n",
    "https://www.bestfightodds.com/events/ufc-287-2760\n",
    "\n",
    "Unfortunately I forgot to run the full script prior to this, so it's a bit jank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/john/play/sports/') # add parent directory to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 248)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>FighterResult</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Rnd</th>\n",
       "      <th>Time</th>\n",
       "      <th>Event</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>TSL</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_weight</th>\n",
       "      <th>FighterID_espn_opp</th>\n",
       "      <th>n_career_fights_opp</th>\n",
       "      <th>n_ufc_fights_opp</th>\n",
       "      <th>t_since_first_fight_opp</th>\n",
       "      <th>t_since_prev_fight_opp</th>\n",
       "      <th>total_ufc_cage_time_opp</th>\n",
       "      <th>min_weight_opp</th>\n",
       "      <th>max_weight_opp</th>\n",
       "      <th>prev_weight_opp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>1991-09-26</td>\n",
       "      <td>L</td>\n",
       "      <td>TKO (Injury)</td>\n",
       "      <td>1</td>\n",
       "      <td>4:42</td>\n",
       "      <td>Desafio: Jiu-Jitsu vs. Luta Livre</td>\n",
       "      <td>2354059</td>\n",
       "      <td>2558095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2354059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>1991-09-26</td>\n",
       "      <td>W</td>\n",
       "      <td>TKO (Injury)</td>\n",
       "      <td>1</td>\n",
       "      <td>4:42</td>\n",
       "      <td>Desafio: Jiu-Jitsu vs. Luta Livre</td>\n",
       "      <td>2558095</td>\n",
       "      <td>2354059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2558095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>W</td>\n",
       "      <td>Submission (Rear Naked Choke)</td>\n",
       "      <td>1</td>\n",
       "      <td>7:03</td>\n",
       "      <td>Desafio: Gracie Vale Tudo</td>\n",
       "      <td>2501396</td>\n",
       "      <td>2354119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2501396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>L</td>\n",
       "      <td>Submission (Rear Naked Choke)</td>\n",
       "      <td>1</td>\n",
       "      <td>7:03</td>\n",
       "      <td>Desafio: Gracie Vale Tudo</td>\n",
       "      <td>2354119</td>\n",
       "      <td>2501396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2354119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993-08-29_2354132_3107994</td>\n",
       "      <td>1993-08-29</td>\n",
       "      <td>W</td>\n",
       "      <td>Submission (Strikes)</td>\n",
       "      <td>1</td>\n",
       "      <td>2:46</td>\n",
       "      <td>CP X CB: Capoeira vs. Chute Boxe</td>\n",
       "      <td>3107994</td>\n",
       "      <td>2354132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3107994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fight_id       Date FighterResult  \\\n",
       "0  1991-09-26_2354059_2558095 1991-09-26             L   \n",
       "1  1991-09-26_2354059_2558095 1991-09-26             W   \n",
       "2  1992-01-01_2354119_2501396 1992-01-01             W   \n",
       "3  1992-01-01_2354119_2501396 1992-01-01             L   \n",
       "4  1993-08-29_2354132_3107994 1993-08-29             W   \n",
       "\n",
       "                        Decision Rnd  Time                              Event  \\\n",
       "0                   TKO (Injury)   1  4:42  Desafio: Jiu-Jitsu vs. Luta Livre   \n",
       "1                   TKO (Injury)   1  4:42  Desafio: Jiu-Jitsu vs. Luta Livre   \n",
       "2  Submission (Rear Naked Choke)   1  7:03          Desafio: Gracie Vale Tudo   \n",
       "3  Submission (Rear Naked Choke)   1  7:03          Desafio: Gracie Vale Tudo   \n",
       "4           Submission (Strikes)   1  2:46   CP X CB: Capoeira vs. Chute Boxe   \n",
       "\n",
       "  OpponentID_espn FighterID_espn  TSL  ...  prev_weight  FighterID_espn_opp  \\\n",
       "0         2354059        2558095  NaN  ...          NaN             2354059   \n",
       "1         2558095        2354059  NaN  ...          NaN             2558095   \n",
       "2         2501396        2354119  NaN  ...          NaN             2501396   \n",
       "3         2354119        2501396  NaN  ...          NaN             2354119   \n",
       "4         3107994        2354132  NaN  ...          NaN             3107994   \n",
       "\n",
       "   n_career_fights_opp n_ufc_fights_opp  t_since_first_fight_opp  \\\n",
       "0                    0                0                        0   \n",
       "1                    0                0                        0   \n",
       "2                    0                0                        0   \n",
       "3                    0                0                        0   \n",
       "4                    0                0                        0   \n",
       "\n",
       "   t_since_prev_fight_opp  total_ufc_cage_time_opp  min_weight_opp  \\\n",
       "0                     NaN                      0.0           185.0   \n",
       "1                     NaN                      0.0             NaN   \n",
       "2                     NaN                      0.0           185.0   \n",
       "3                     NaN                      0.0           170.0   \n",
       "4                     NaN                      0.0             NaN   \n",
       "\n",
       "   max_weight_opp  prev_weight_opp  \n",
       "0           185.0              NaN  \n",
       "1             NaN              NaN  \n",
       "2           185.0              NaN  \n",
       "3           170.0              NaN  \n",
       "4             NaN              NaN  \n",
       "\n",
       "[5 rows x 248 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from db import base_db_interface\n",
    "\n",
    "raw_df = base_db_interface.read(\"bfo_espn_ufc_features\")\n",
    "for dt_col in [\"Date\", \"DOB\", \"DOB_opp\"]:\n",
    "    raw_df[dt_col] = pd.to_datetime(raw_df[dt_col])\n",
    "raw_df[[\"FighterOpen\", \"OpponentOpen\"]] = raw_df[[\"FighterOpen\", \"OpponentOpen\"]]\\\n",
    "    .astype(float)\n",
    "\n",
    "raw_df = raw_df.drop_duplicates(subset=[\"FighterID_espn\", \"OpponentID_espn\", \"fight_id\"])\n",
    "raw_df[\"FighterID_espn\"] = raw_df[\"FighterID_espn\"].fillna(\"unknown\")\n",
    "raw_df[\"OpponentID_espn\"] = raw_df[\"OpponentID_espn\"].fillna(\"unknown\")\n",
    "print(raw_df.shape)\n",
    "raw_df.head() # show the first 5 rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awful, Ugly, Stinky, No-Good Hack\n",
    "\n",
    "Necessary in order to get data for the upcoming fights. The join is very difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 17)\n",
      "(30, 19)\n",
      "(30, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>EventHref</th>\n",
       "      <th>Date</th>\n",
       "      <th>FighterID_bfo</th>\n",
       "      <th>OpponentID_bfo</th>\n",
       "      <th>FighterName</th>\n",
       "      <th>OpponentName</th>\n",
       "      <th>FighterOpen</th>\n",
       "      <th>OpponentOpen</th>\n",
       "      <th>FighterCloseLeft</th>\n",
       "      <th>...</th>\n",
       "      <th>BioName_opp</th>\n",
       "      <th>FighterID_espn_opp</th>\n",
       "      <th>Country_opp</th>\n",
       "      <th>WT Class_opp</th>\n",
       "      <th>Team_opp</th>\n",
       "      <th>Nickname_opp</th>\n",
       "      <th>ReachInches_opp</th>\n",
       "      <th>WeightPounds_opp</th>\n",
       "      <th>HeightInches_opp</th>\n",
       "      <th>DOB_opp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Aaron-Phillips-4905</td>\n",
       "      <td>Gaston-Bolanos-6991</td>\n",
       "      <td>aaron phillips</td>\n",
       "      <td>gaston bolanos</td>\n",
       "      <td>+140</td>\n",
       "      <td>-160</td>\n",
       "      <td>+150</td>\n",
       "      <td>...</td>\n",
       "      <td>gaston bolaños</td>\n",
       "      <td>4393818</td>\n",
       "      <td>USA</td>\n",
       "      <td>Bantamweight</td>\n",
       "      <td>Combat Sports Academy</td>\n",
       "      <td>The Dreamkiller</td>\n",
       "      <td>69.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1992-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Arnold-Allen-4218</td>\n",
       "      <td>Max-Holloway-3090</td>\n",
       "      <td>arnold allen</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>+125</td>\n",
       "      <td>-145</td>\n",
       "      <td>+145</td>\n",
       "      <td>...</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>2614933</td>\n",
       "      <td>USA</td>\n",
       "      <td>Featherweight</td>\n",
       "      <td>Gracie Technics</td>\n",
       "      <td>Blessed</td>\n",
       "      <td>69.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1991-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Azamat-Murzakanov-7264</td>\n",
       "      <td>Dustin-Jacoby-2939</td>\n",
       "      <td>azamat murzakanov</td>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>+170</td>\n",
       "      <td>-200</td>\n",
       "      <td>+125</td>\n",
       "      <td>...</td>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>2594871</td>\n",
       "      <td>USA</td>\n",
       "      <td>Light Heavyweight</td>\n",
       "      <td>FactoryX Muay Thai</td>\n",
       "      <td>The Hanyak</td>\n",
       "      <td>76.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1988-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Bill-Algeo-9171</td>\n",
       "      <td>Tj-Brown-10260</td>\n",
       "      <td>bill algeo</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>-139</td>\n",
       "      <td>+119</td>\n",
       "      <td>-210</td>\n",
       "      <td>...</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>4063667</td>\n",
       "      <td>USA</td>\n",
       "      <td>Featherweight</td>\n",
       "      <td>Westside Fight Team</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>72.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1990-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Billy-Quarantillo-4159</td>\n",
       "      <td>Edson-Barboza-2099</td>\n",
       "      <td>billy quarantillo</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>-155</td>\n",
       "      <td>+135</td>\n",
       "      <td>-190</td>\n",
       "      <td>...</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>2526299</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Featherweight</td>\n",
       "      <td>American Top Team</td>\n",
       "      <td>Junior</td>\n",
       "      <td>75.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1986-01-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Event  \\\n",
       "0  UFC Fight Night: Holloway vs. Allen   \n",
       "1  UFC Fight Night: Holloway vs. Allen   \n",
       "2  UFC Fight Night: Holloway vs. Allen   \n",
       "3  UFC Fight Night: Holloway vs. Allen   \n",
       "4  UFC Fight Night: Holloway vs. Allen   \n",
       "\n",
       "                                        EventHref       Date  \\\n",
       "0  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "1  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "2  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "3  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "4  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "\n",
       "            FighterID_bfo       OpponentID_bfo        FighterName  \\\n",
       "0     Aaron-Phillips-4905  Gaston-Bolanos-6991     aaron phillips   \n",
       "1       Arnold-Allen-4218    Max-Holloway-3090       arnold allen   \n",
       "2  Azamat-Murzakanov-7264   Dustin-Jacoby-2939  azamat murzakanov   \n",
       "3         Bill-Algeo-9171       Tj-Brown-10260         bill algeo   \n",
       "4  Billy-Quarantillo-4159   Edson-Barboza-2099  billy quarantillo   \n",
       "\n",
       "     OpponentName FighterOpen OpponentOpen FighterCloseLeft  ...  \\\n",
       "0  gaston bolanos        +140         -160             +150  ...   \n",
       "1    max holloway        +125         -145             +145  ...   \n",
       "2   dustin jacoby        +170         -200             +125  ...   \n",
       "3        tj brown        -139         +119             -210  ...   \n",
       "4   edson barboza        -155         +135             -190  ...   \n",
       "\n",
       "      BioName_opp FighterID_espn_opp Country_opp       WT Class_opp  \\\n",
       "0  gaston bolaños            4393818         USA       Bantamweight   \n",
       "1    max holloway            2614933         USA      Featherweight   \n",
       "2   dustin jacoby            2594871         USA  Light Heavyweight   \n",
       "3        tj brown            4063667         USA      Featherweight   \n",
       "4   edson barboza            2526299      Brazil      Featherweight   \n",
       "\n",
       "                Team_opp     Nickname_opp  ReachInches_opp WeightPounds_opp  \\\n",
       "0  Combat Sports Academy  The Dreamkiller             69.0            135.0   \n",
       "1        Gracie Technics          Blessed             69.0            146.0   \n",
       "2     FactoryX Muay Thai       The Hanyak             76.0            206.0   \n",
       "3    Westside Fight Team         Downtown             72.0            145.0   \n",
       "4      American Top Team           Junior             75.0            145.0   \n",
       "\n",
       "  HeightInches_opp    DOB_opp  \n",
       "0             67.0 1992-09-14  \n",
       "1             71.0 1991-12-04  \n",
       "2             75.0 1988-04-04  \n",
       "3             69.0 1990-05-22  \n",
       "4             71.0 1986-01-21  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wrangle.clean_espn_data import EspnDataCleaner\n",
    "\n",
    "# Get odds for upcoming fight\n",
    "bfo_df = base_db_interface.read(\"clean_fighter_odds_data\")\n",
    "bfo_df[\"Date\"] = pd.to_datetime(bfo_df[\"Date\"])\n",
    "bfo_to_espn_map = base_db_interface.read(\"bfo_to_espn_map\")\n",
    "upcoming_bfo_df = bfo_df.query(\"EventHref == \\\n",
    "                               '/events/ufc-fight-night-holloway-vs-allen-2796'\")\n",
    "upcoming_bfo_df = upcoming_bfo_df.rename(\n",
    "    columns={\"FighterID\": \"FighterID_bfo\", \"OpponentID\": \"OpponentID_bfo\"}\n",
    ")\n",
    "print(upcoming_bfo_df.shape)\n",
    "upcoming_bfo_df = upcoming_bfo_df.merge(\n",
    "    bfo_to_espn_map[[\"FighterID_bfo\", \"FighterID_espn\"]].drop_duplicates(),\n",
    "    on=[\"FighterID_bfo\"],\n",
    "    how=\"left\"\n",
    ").merge(\n",
    "    bfo_to_espn_map[[\"OpponentID_bfo\", \"OpponentID_espn\"]].drop_duplicates(),\n",
    "    on=[\"OpponentID_bfo\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(upcoming_bfo_df.shape)\n",
    "# Get bios for fighters in upcoming fight\n",
    "espn_dc = EspnDataCleaner()\n",
    "espn_dc._parse_bios()\n",
    "espn_dc.clean_bio_df\n",
    "bio_df = espn_dc.clean_bio_df.rename(columns={\n",
    "    \"FighterID\":\"FighterID_espn\", \"Name\": \"BioName\",\n",
    "})\n",
    "upcoming_bfo_df = upcoming_bfo_df.merge(\n",
    "    bio_df,\n",
    "    left_on=\"FighterID_espn\",\n",
    "    right_on=\"FighterID_espn\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_dropme\", \"\")\n",
    ").merge(\n",
    "    bio_df,\n",
    "    left_on=\"OpponentID_espn\",\n",
    "    right_on=\"FighterID_espn\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_opp\")\n",
    ")\n",
    "print(upcoming_bfo_df.shape)\n",
    "\n",
    "upcoming_bfo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 248) (133102, 250)\n",
      "shape of tonight's fight: (26, 250)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>FighterResult</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Rnd</th>\n",
       "      <th>Time</th>\n",
       "      <th>Event</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>TSL</th>\n",
       "      <th>...</th>\n",
       "      <th>n_career_fights_opp</th>\n",
       "      <th>n_ufc_fights_opp</th>\n",
       "      <th>t_since_first_fight_opp</th>\n",
       "      <th>t_since_prev_fight_opp</th>\n",
       "      <th>total_ufc_cage_time_opp</th>\n",
       "      <th>min_weight_opp</th>\n",
       "      <th>max_weight_opp</th>\n",
       "      <th>prev_weight_opp</th>\n",
       "      <th>BioName</th>\n",
       "      <th>BioName_opp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132984</th>\n",
       "      <td>2023-04-15_3949555_4863327</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3949555</td>\n",
       "      <td>4863327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>3990</td>\n",
       "      <td>357.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.0</td>\n",
       "      <td>daniel zellhuber</td>\n",
       "      <td>lando vannata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132985</th>\n",
       "      <td>2023-04-15_4040197_4397782</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4040197</td>\n",
       "      <td>4397782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>3347</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>joselyne edwards</td>\n",
       "      <td>lucie pudilova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132986</th>\n",
       "      <td>2023-04-15_3994033_4232775</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3994033</td>\n",
       "      <td>4232775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>4027</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2719.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205.0</td>\n",
       "      <td>tanner boser</td>\n",
       "      <td>ion cutelaba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132987</th>\n",
       "      <td>2023-04-15_4063667_4076472</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4063667</td>\n",
       "      <td>4076472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>3444</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1818.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>bill algeo</td>\n",
       "      <td>tj brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132988</th>\n",
       "      <td>2023-04-15_3045734_3961293</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3961293</td>\n",
       "      <td>3045734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>3591</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>pedro munhoz</td>\n",
       "      <td>chris gutierrez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fight_id       Date FighterResult Decision   Rnd  \\\n",
       "132984  2023-04-15_3949555_4863327 2023-04-15          None     None  None   \n",
       "132985  2023-04-15_4040197_4397782 2023-04-15          None     None  None   \n",
       "132986  2023-04-15_3994033_4232775 2023-04-15          None     None  None   \n",
       "132987  2023-04-15_4063667_4076472 2023-04-15          None     None  None   \n",
       "132988  2023-04-15_3045734_3961293 2023-04-15          None     None  None   \n",
       "\n",
       "        Time                                Event OpponentID_espn  \\\n",
       "132984  None  UFC Fight Night: Holloway vs. Allen         3949555   \n",
       "132985  None  UFC Fight Night: Holloway vs. Allen         4040197   \n",
       "132986  None  UFC Fight Night: Holloway vs. Allen         3994033   \n",
       "132987  None  UFC Fight Night: Holloway vs. Allen         4063667   \n",
       "132988  None  UFC Fight Night: Holloway vs. Allen         3961293   \n",
       "\n",
       "       FighterID_espn  TSL  ...  n_career_fights_opp  n_ufc_fights_opp  \\\n",
       "132984        4863327  NaN  ...                   20                12   \n",
       "132985        4397782  NaN  ...                   21                 8   \n",
       "132986        4232775  NaN  ...                   27                13   \n",
       "132987        4076472  NaN  ...                   26                 6   \n",
       "132988        3045734  NaN  ...                   24                 8   \n",
       "\n",
       "        t_since_first_fight_opp t_since_prev_fight_opp  \\\n",
       "132984                     3990                  357.0   \n",
       "132985                     3347                  238.0   \n",
       "132986                     4027                  147.0   \n",
       "132987                     3444                  126.0   \n",
       "132988                     3591                  154.0   \n",
       "\n",
       "        total_ufc_cage_time_opp  min_weight_opp  max_weight_opp  \\\n",
       "132984                   3089.0             NaN             NaN   \n",
       "132985                   2124.0             NaN             NaN   \n",
       "132986                   2719.0             NaN             NaN   \n",
       "132987                   1818.0             NaN             NaN   \n",
       "132988                   2294.0             NaN             NaN   \n",
       "\n",
       "        prev_weight_opp           BioName      BioName_opp  \n",
       "132984            155.0  daniel zellhuber    lando vannata  \n",
       "132985            135.0  joselyne edwards   lucie pudilova  \n",
       "132986            205.0      tanner boser     ion cutelaba  \n",
       "132987            145.0        bill algeo         tj brown  \n",
       "132988            135.0      pedro munhoz  chris gutierrez  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't like this line, \n",
    "df = raw_df.merge(\n",
    "    upcoming_bfo_df,\n",
    "    on=[\"FighterID_espn\", \"OpponentID_espn\", \"Date\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_dropme\")\n",
    ")\n",
    "drop_cols = df.columns[df.columns.str.endswith(\"_dropme\")]\n",
    "for drop_col in drop_cols:\n",
    "    col = drop_col[:-len(\"_dropme\")]\n",
    "    df[col] = df[col].fillna(df[drop_col])\n",
    "df = df.drop(columns=drop_cols)\n",
    "print(raw_df.shape, df.shape)\n",
    "foo = df.query(\"EventHref == '/events/ufc-fight-night-holloway-vs-allen-2796'\")\n",
    "print(\"shape of tonight's fight:\", foo.shape)\n",
    "foo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# OKAY PCA HAPPENS HERE. Just do everything in-sample for now. \n",
    "stat_cols = [\n",
    "    'TSL', 'TSA', 'SSL',\n",
    "    'SSA', #'TSL-TSA', \n",
    "    'KD', #'%BODY', '%HEAD', '%LEG', \n",
    "    'SCBL',\n",
    "    'SCBA', 'SCHL', 'SCHA', 'SCLL', 'SCLA', 'RV', 'TDL', 'TDA', 'TDS',\n",
    "    # 'TK ACC', 'SR', # I don't believe in ratio features in PCA, \n",
    "    # # because of the possibility of division by zero and heteroskedasticity\n",
    "    'SGBL', 'SGBA', 'SGHL', 'SGHA', 'SGLL', 'SGLA', 'AD', 'ADTB',\n",
    "    'ADHG', 'ADTM', 'ADTS', 'SM', 'SDBL', 'SDBA', 'SDHL',\n",
    "    'SDHA', 'SDLL', 'SDLA',\n",
    "    #'time_seconds',\n",
    "    # 'TD_fails', #'submission_rate',\n",
    "    'TD_fail', # formerly 'TD_fails'\n",
    "    'SDL', 'SCL', # formerly 'distance_strikes_landed', 'clinch_strikes_landed',\n",
    "    #'KD_power', \n",
    "    'SGL', # formerly 'ground_strikes_landed'\n",
    "]\n",
    "df[[\"KD\", \"KD_opp\"]] = df[[\"KD\", \"KD_opp\"]].astype(float) \n",
    "# convert from string to float. rather annoying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_diff_df = {\n",
    "    \"FighterID_espn\": df[\"FighterID_espn\"],\n",
    "    \"OpponentID_espn\": df[\"OpponentID_espn\"],\n",
    "    \"Date\": df[\"Date\"],\n",
    "    \"gender\": df[\"gender\"],\n",
    "    \"fight_id\": df[\"fight_id\"],\n",
    "}\n",
    "diff_cols = [col+\"_diff\" for col in stat_cols]\n",
    "for col, diff_col in zip(stat_cols, diff_cols):\n",
    "    stat_diff_df[diff_col] = (\n",
    "        np.sqrt(df[col]) - np.sqrt(df[col+\"_opp\"])\n",
    "    )\n",
    "# stat_diff_df = pd.DataFrame(stat_diff_df).dropna(subset=diff_cols).reset_index()\n",
    "stat_diff_df = pd.DataFrame(stat_diff_df).reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elo estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pca = 14\n",
    "# n_pca = 1 # just for testing\n",
    "bin_elo_alpha = 0.45\n",
    "acc_elo_alpha = 0.45\n",
    "pca_elo_alpha = 0.45\n",
    "real_elo_alpha = 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 814.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 829.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 828.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 825.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 835.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 825.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 830.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 830.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 836.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 826.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 832.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 830.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 824.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 831.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>fight_id</th>\n",
       "      <th>PC_0</th>\n",
       "      <th>pred_elo_PC_0</th>\n",
       "      <th>fighter_elo_PC_0</th>\n",
       "      <th>opponent_elo_PC_0</th>\n",
       "      <th>updated_fighter_elo_PC_0</th>\n",
       "      <th>updated_opponent_elo_PC_0</th>\n",
       "      <th>PC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>fighter_elo_PC_12</th>\n",
       "      <th>opponent_elo_PC_12</th>\n",
       "      <th>updated_fighter_elo_PC_12</th>\n",
       "      <th>updated_opponent_elo_PC_12</th>\n",
       "      <th>PC_13</th>\n",
       "      <th>pred_elo_PC_13</th>\n",
       "      <th>fighter_elo_PC_13</th>\n",
       "      <th>opponent_elo_PC_13</th>\n",
       "      <th>updated_fighter_elo_PC_13</th>\n",
       "      <th>updated_opponent_elo_PC_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2558095</td>\n",
       "      <td>2354059</td>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2354059</td>\n",
       "      <td>2558095</td>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2354119</td>\n",
       "      <td>2501396</td>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2501396</td>\n",
       "      <td>2354119</td>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2354132</td>\n",
       "      <td>3107994</td>\n",
       "      <td>1993-08-29_2354132_3107994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133097</th>\n",
       "      <td>2512976</td>\n",
       "      <td>3146944</td>\n",
       "      <td>2023-05-13_2512976_3146944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.619807</td>\n",
       "      <td>-0.109493</td>\n",
       "      <td>0.510314</td>\n",
       "      <td>-0.109493</td>\n",
       "      <td>0.510314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314846</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>-0.314846</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>0.639975</td>\n",
       "      <td>0.317220</td>\n",
       "      <td>0.639975</td>\n",
       "      <td>0.317220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133098</th>\n",
       "      <td>2516131</td>\n",
       "      <td>2951361</td>\n",
       "      <td>2023-06-10_2516131_2951361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.443042</td>\n",
       "      <td>1.176898</td>\n",
       "      <td>0.733856</td>\n",
       "      <td>1.176898</td>\n",
       "      <td>0.733856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610091</td>\n",
       "      <td>0.349301</td>\n",
       "      <td>-0.260790</td>\n",
       "      <td>0.349301</td>\n",
       "      <td>-0.260790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133099</th>\n",
       "      <td>2951361</td>\n",
       "      <td>2516131</td>\n",
       "      <td>2023-06-10_2516131_2951361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.443042</td>\n",
       "      <td>0.733856</td>\n",
       "      <td>1.176898</td>\n",
       "      <td>0.733856</td>\n",
       "      <td>1.176898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.610091</td>\n",
       "      <td>-0.260790</td>\n",
       "      <td>0.349301</td>\n",
       "      <td>-0.260790</td>\n",
       "      <td>0.349301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133100</th>\n",
       "      <td>2560746</td>\n",
       "      <td>3027545</td>\n",
       "      <td>2023-07-08_2560746_3027545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.415478</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.393125</td>\n",
       "      <td>-0.492688</td>\n",
       "      <td>-0.393125</td>\n",
       "      <td>-0.492688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.131069</td>\n",
       "      <td>0.107960</td>\n",
       "      <td>0.239029</td>\n",
       "      <td>0.107960</td>\n",
       "      <td>0.239029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133101</th>\n",
       "      <td>3027545</td>\n",
       "      <td>2560746</td>\n",
       "      <td>2023-07-08_2560746_3027545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.415478</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492688</td>\n",
       "      <td>-0.393125</td>\n",
       "      <td>-0.492688</td>\n",
       "      <td>-0.393125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.131069</td>\n",
       "      <td>0.239029</td>\n",
       "      <td>0.107960</td>\n",
       "      <td>0.239029</td>\n",
       "      <td>0.107960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133102 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FighterID_espn OpponentID_espn                    fight_id  PC_0  \\\n",
       "0             2558095         2354059  1991-09-26_2354059_2558095   NaN   \n",
       "1             2354059         2558095  1991-09-26_2354059_2558095   NaN   \n",
       "2             2354119         2501396  1992-01-01_2354119_2501396   NaN   \n",
       "3             2501396         2354119  1992-01-01_2354119_2501396   NaN   \n",
       "4             2354132         3107994  1993-08-29_2354132_3107994   NaN   \n",
       "...               ...             ...                         ...   ...   \n",
       "133097        2512976         3146944  2023-05-13_2512976_3146944   NaN   \n",
       "133098        2516131         2951361  2023-06-10_2516131_2951361   NaN   \n",
       "133099        2951361         2516131  2023-06-10_2516131_2951361   NaN   \n",
       "133100        2560746         3027545  2023-07-08_2560746_3027545   NaN   \n",
       "133101        3027545         2560746  2023-07-08_2560746_3027545   NaN   \n",
       "\n",
       "        pred_elo_PC_0  fighter_elo_PC_0  opponent_elo_PC_0  \\\n",
       "0            0.000000          0.000000           0.000000   \n",
       "1            0.000000          0.000000           0.000000   \n",
       "2            0.000000          0.000000           0.000000   \n",
       "3            0.000000          0.000000           0.000000   \n",
       "4            0.000000          0.000000           0.000000   \n",
       "...               ...               ...                ...   \n",
       "133097      -0.619807         -0.109493           0.510314   \n",
       "133098       0.443042          1.176898           0.733856   \n",
       "133099      -0.443042          0.733856           1.176898   \n",
       "133100      -0.415478          0.355464           0.770942   \n",
       "133101       0.415478          0.770942           0.355464   \n",
       "\n",
       "        updated_fighter_elo_PC_0  updated_opponent_elo_PC_0  PC_1  ...  \\\n",
       "0                       0.000000                   0.000000   NaN  ...   \n",
       "1                       0.000000                   0.000000   NaN  ...   \n",
       "2                       0.000000                   0.000000   NaN  ...   \n",
       "3                       0.000000                   0.000000   NaN  ...   \n",
       "4                       0.000000                   0.000000   NaN  ...   \n",
       "...                          ...                        ...   ...  ...   \n",
       "133097                 -0.109493                   0.510314   NaN  ...   \n",
       "133098                  1.176898                   0.733856   NaN  ...   \n",
       "133099                  0.733856                   1.176898   NaN  ...   \n",
       "133100                  0.355464                   0.770942   NaN  ...   \n",
       "133101                  0.770942                   0.355464   NaN  ...   \n",
       "\n",
       "        fighter_elo_PC_12  opponent_elo_PC_12  updated_fighter_elo_PC_12  \\\n",
       "0                0.000000            0.000000                   0.000000   \n",
       "1                0.000000            0.000000                   0.000000   \n",
       "2                0.000000            0.000000                   0.000000   \n",
       "3                0.000000            0.000000                   0.000000   \n",
       "4                0.000000            0.000000                   0.000000   \n",
       "...                   ...                 ...                        ...   \n",
       "133097          -0.314846            0.003451                  -0.314846   \n",
       "133098           0.127486            0.230649                   0.127486   \n",
       "133099           0.230649            0.127486                   0.230649   \n",
       "133100          -0.393125           -0.492688                  -0.393125   \n",
       "133101          -0.492688           -0.393125                  -0.492688   \n",
       "\n",
       "        updated_opponent_elo_PC_12  PC_13  pred_elo_PC_13  fighter_elo_PC_13  \\\n",
       "0                         0.000000    NaN        0.000000           0.000000   \n",
       "1                         0.000000    NaN        0.000000           0.000000   \n",
       "2                         0.000000    NaN        0.000000           0.000000   \n",
       "3                         0.000000    NaN        0.000000           0.000000   \n",
       "4                         0.000000    NaN        0.000000           0.000000   \n",
       "...                            ...    ...             ...                ...   \n",
       "133097                    0.003451    NaN        0.322755           0.639975   \n",
       "133098                    0.230649    NaN        0.610091           0.349301   \n",
       "133099                    0.127486    NaN       -0.610091          -0.260790   \n",
       "133100                   -0.492688    NaN       -0.131069           0.107960   \n",
       "133101                   -0.393125    NaN        0.131069           0.239029   \n",
       "\n",
       "        opponent_elo_PC_13  updated_fighter_elo_PC_13  \\\n",
       "0                 0.000000                   0.000000   \n",
       "1                 0.000000                   0.000000   \n",
       "2                 0.000000                   0.000000   \n",
       "3                 0.000000                   0.000000   \n",
       "4                 0.000000                   0.000000   \n",
       "...                    ...                        ...   \n",
       "133097            0.317220                   0.639975   \n",
       "133098           -0.260790                   0.349301   \n",
       "133099            0.349301                  -0.260790   \n",
       "133100            0.239029                   0.107960   \n",
       "133101            0.107960                   0.239029   \n",
       "\n",
       "        updated_opponent_elo_PC_13  \n",
       "0                         0.000000  \n",
       "1                         0.000000  \n",
       "2                         0.000000  \n",
       "3                         0.000000  \n",
       "4                         0.000000  \n",
       "...                            ...  \n",
       "133097                    0.317220  \n",
       "133098                   -0.260790  \n",
       "133099                    0.349301  \n",
       "133100                    0.239029  \n",
       "133101                    0.107960  \n",
       "\n",
       "[133102 rows x 87 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.mma_features import PcaEloWrapper, BinaryEloWrapper\n",
    "\n",
    "pca_ew = PcaEloWrapper(\n",
    "    n_pca=n_pca, target_cols=diff_cols, alpha=pca_elo_alpha,\n",
    "    conditional_var_col=None, # for consistency\n",
    ")\n",
    "pca_elo_feat_df = pca_ew.fit_transform_all(stat_diff_df)\n",
    "pca_elo_feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FighterID_espn                133102\n",
       " OpponentID_espn               133102\n",
       " fight_id                      133102\n",
       " PC_0                            7928\n",
       " pred_elo_PC_0                 133102\n",
       "                                ...  \n",
       " pred_elo_PC_13                133102\n",
       " fighter_elo_PC_13             133102\n",
       " opponent_elo_PC_13            133102\n",
       " updated_fighter_elo_PC_13     133102\n",
       " updated_opponent_elo_PC_13    133102\n",
       " Length: 87, dtype: int64,\n",
       " index              133102\n",
       " FighterID_espn     133102\n",
       " OpponentID_espn    133102\n",
       " Date               133102\n",
       " gender             133102\n",
       " fight_id           133102\n",
       " TSL_diff            18156\n",
       " TSA_diff            18156\n",
       " SSL_diff            18156\n",
       " SSA_diff            18156\n",
       " KD_diff             18156\n",
       " SCBL_diff            7942\n",
       " SCBA_diff            7942\n",
       " SCHL_diff            7942\n",
       " SCHA_diff            7942\n",
       " SCLL_diff            7942\n",
       " SCLA_diff            7942\n",
       " RV_diff             18156\n",
       " TDL_diff            18156\n",
       " TDA_diff            18156\n",
       " TDS_diff             7942\n",
       " SGBL_diff            7942\n",
       " SGBA_diff            7942\n",
       " SGHL_diff            7942\n",
       " SGHA_diff            7942\n",
       " SGLL_diff            7942\n",
       " SGLA_diff            7942\n",
       " AD_diff              7942\n",
       " ADTB_diff            7942\n",
       " ADHG_diff            7942\n",
       " ADTM_diff            7942\n",
       " ADTS_diff            7942\n",
       " SM_diff             18156\n",
       " SDBL_diff            7942\n",
       " SDBA_diff            7942\n",
       " SDHL_diff            7942\n",
       " SDHA_diff            7942\n",
       " SDLL_diff            7942\n",
       " SDLA_diff            7942\n",
       " TD_fail_diff        18156\n",
       " SDL_diff            18142\n",
       " SCL_diff            18142\n",
       " SGL_diff            18142\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_elo_feat_df.notnull().sum(), stat_diff_df.notnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some targets for Elo estimators along the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    65262\n",
       "1.0    65262\n",
       "NaN     2578\n",
       "Name: win_target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"win_target\"] = df[\"FighterResult\"].replace({\"W\":1, \"L\":0, \"D\":np.nan})\n",
    "df[\"win_target\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    45420\n",
       "1.0    45420\n",
       "NaN    42262\n",
       "Name: win_target_finish, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have to parse the decision column to get the detailed result\n",
    "def parse_decision(s):\n",
    "    if (s.startswith(\"submission\") or \n",
    "        s.startswith(\"sumission\") or\n",
    "        s.startswith(\"technical submission\")\n",
    "    ):\n",
    "        return \"submission\"\n",
    "    if (s.startswith(\"tko\") or \n",
    "        s.startswith(\"ko\") or\n",
    "        (s == 'could not continue')\n",
    "    ):\n",
    "        return \"tko_ko\"\n",
    "    if \"decision\" in s:\n",
    "        return \"decision\"\n",
    "    return \"other\"\n",
    "\n",
    "temp_decision = df[\"Decision\"].fillna(\"-\").str.lower().str.strip()\n",
    "decision_clean = temp_decision.apply(parse_decision)\n",
    "result_sign = df[\"FighterResult\"].map({\"W\": 1, \"L\":-1, \"D\": 0})\n",
    "decision_score = decision_clean.map({\"tko_ko\":2, \"submission\":2, \n",
    "                                                    \"decision\":1, \"other\":0})\n",
    "df[\"ordinal_fighter_result\"] = result_sign * decision_score\n",
    "submission_score = decision_clean.map({\"submission\":1, \"decision\":0, \n",
    "                                            \"other\":0, \"tko_ko\":0})\n",
    "tko_ko_score = decision_clean.map({\"submission\":0, \"decision\":0, \n",
    "                                            \"other\":0, \"tko_ko\":1})\n",
    "decision_score = decision_clean.map({\"submission\":0, \"decision\":1, \n",
    "                                            \"other\":0, \"tko_ko\":0})\n",
    "finish_score = decision_clean.map({\"submission\":1, \"decision\":0, \n",
    "                                            \"other\":0, \"tko_ko\":1})\n",
    "df[\"submission_fighter_result\"] = result_sign * submission_score\n",
    "df[\"tko_ko_fighter_result\"] = result_sign * tko_ko_score\n",
    "df[\"decision_fighter_result\"] = result_sign * decision_score\n",
    "df[\"finish_fighter_result\"] = result_sign * finish_score\n",
    "\n",
    "df[\"win_target_finish\"] = df[\"win_target\"] * decision_clean.map({\n",
    "    \"submission\":1, \"tko_ko\":1,\n",
    "    \"decision\":np.nan, \"other\":np.nan, \n",
    "})\n",
    "df[\"win_target_finish\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9891662033628346"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_fight_time(row):\n",
    "    if not np.isnan(row[\"time_dur\"]):\n",
    "        return row[\"time_dur\"]\n",
    "    if row[\"Rnd\"] == \"-\":\n",
    "        return np.nan\n",
    "    if row[\"Time\"] == \"-\":\n",
    "        # assuming 5 minute rounds\n",
    "        # fill in something for now\n",
    "        return int(row[\"Rnd\"]) * 5 * 60\n",
    "    n_rounds = row[\"Rnd\"].strip()\n",
    "    min, sec = row[\"Time\"].strip().split(\":\")\n",
    "    if n_rounds == \"-\":\n",
    "        return np.nan\n",
    "    n_rounds = int(n_rounds) - 1\n",
    "    if (min == \"-\") | (sec == \"-\"):\n",
    "        return np.nan\n",
    "    min = int(min)\n",
    "    sec = int(sec)\n",
    "    # assuming 5 minute rounds\n",
    "    return (n_rounds * 5 * 60) + min * 60 + sec\n",
    "    \n",
    "df[\"Rnd\"] = df[\"Rnd\"].fillna(\"-\")\n",
    "df[\"Time\"] = df[\"Time\"].fillna(\"-\")\n",
    "df[\"fight_time\"] = df.apply(parse_fight_time, axis=1)\n",
    "df[\"fight_time\"].notnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = (-1)**df[\"win_target\"]\n",
    "# restrict btw 1 and 25 minutes (length of a title fight)\n",
    "# short fight times -> big outliers\n",
    "clipped_time_dur = df[\"fight_time\"].clip(60, (5*5*60))\n",
    "df[\"signed_inverse_fight_time\"] = y / clipped_time_dur\n",
    "df[\"signed_inverse_sqrt_fight_time\"] = y / np.sqrt(clipped_time_dur)\n",
    "df[\"signed_inverse_log_fight_time\"] = y / np.log(clipped_time_dur)\n",
    "\n",
    "df[\"signed_inverse_fight_time\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for signed_inverse_fight_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 820.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 9)\n",
      "getting elo features for win_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 809.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for win_target_finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 816.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>fight_id</th>\n",
       "      <th>win_target</th>\n",
       "      <th>pred_elo_win_target</th>\n",
       "      <th>fighter_elo_win_target</th>\n",
       "      <th>opponent_elo_win_target</th>\n",
       "      <th>updated_fighter_elo_win_target</th>\n",
       "      <th>updated_opponent_elo_win_target</th>\n",
       "      <th>win_target_finish</th>\n",
       "      <th>pred_elo_win_target_finish</th>\n",
       "      <th>fighter_elo_win_target_finish</th>\n",
       "      <th>opponent_elo_win_target_finish</th>\n",
       "      <th>updated_fighter_elo_win_target_finish</th>\n",
       "      <th>updated_opponent_elo_win_target_finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2558095</td>\n",
       "      <td>2354059</td>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2354059</td>\n",
       "      <td>2558095</td>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2354119</td>\n",
       "      <td>2501396</td>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2501396</td>\n",
       "      <td>2354119</td>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2354132</td>\n",
       "      <td>3107994</td>\n",
       "      <td>1993-08-29_2354132_3107994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FighterID_espn OpponentID_espn                    fight_id  win_target  \\\n",
       "0        2558095         2354059  1991-09-26_2354059_2558095         0.0   \n",
       "1        2354059         2558095  1991-09-26_2354059_2558095         1.0   \n",
       "2        2354119         2501396  1992-01-01_2354119_2501396         1.0   \n",
       "3        2501396         2354119  1992-01-01_2354119_2501396         0.0   \n",
       "4        2354132         3107994  1993-08-29_2354132_3107994         1.0   \n",
       "\n",
       "   pred_elo_win_target  fighter_elo_win_target  opponent_elo_win_target  \\\n",
       "0                  0.5                     0.0                      0.0   \n",
       "1                  0.5                     0.0                      0.0   \n",
       "2                  0.5                     0.0                      0.0   \n",
       "3                  0.5                     0.0                      0.0   \n",
       "4                  0.5                     0.0                      0.0   \n",
       "\n",
       "   updated_fighter_elo_win_target  updated_opponent_elo_win_target  \\\n",
       "0                         -0.1125                           0.1125   \n",
       "1                          0.1125                          -0.1125   \n",
       "2                          0.1125                          -0.1125   \n",
       "3                         -0.1125                           0.1125   \n",
       "4                          0.1125                          -0.1125   \n",
       "\n",
       "   win_target_finish  pred_elo_win_target_finish  \\\n",
       "0                0.0                         0.5   \n",
       "1                1.0                         0.5   \n",
       "2                1.0                         0.5   \n",
       "3                0.0                         0.5   \n",
       "4                1.0                         0.5   \n",
       "\n",
       "   fighter_elo_win_target_finish  opponent_elo_win_target_finish  \\\n",
       "0                            0.0                             0.0   \n",
       "1                            0.0                             0.0   \n",
       "2                            0.0                             0.0   \n",
       "3                            0.0                             0.0   \n",
       "4                            0.0                             0.0   \n",
       "\n",
       "   updated_fighter_elo_win_target_finish  \\\n",
       "0                                -0.1125   \n",
       "1                                 0.1125   \n",
       "2                                 0.1125   \n",
       "3                                -0.1125   \n",
       "4                                 0.1125   \n",
       "\n",
       "   updated_opponent_elo_win_target_finish  \n",
       "0                                  0.1125  \n",
       "1                                 -0.1125  \n",
       "2                                 -0.1125  \n",
       "3                                  0.1125  \n",
       "4                                 -0.1125  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.mma_features import RealEloWrapper\n",
    "\n",
    "real_elo_target_cols = [\n",
    "#     \"fighter_result_time_left\", \n",
    "#     \"ml_logit_mvmt\",\n",
    "    # \"ordinal_fighter_result\",\n",
    "    # \"submission_fighter_result\",\n",
    "    # \"tko_ko_fighter_result\",\n",
    "    # \"decision_fighter_result\",\n",
    "    # \"finish_fighter_result\",\n",
    "    \"signed_inverse_fight_time\",\n",
    "    # \"signed_inverse_sqrt_fight_time\",\n",
    "    # \"signed_inverse_log_fight_time\",\n",
    "]\n",
    "diff_elo_target_cols = [\n",
    "]\n",
    "\n",
    "binary_elo_target_cols = [\"win_target\", \"win_target_finish\"]\n",
    "\n",
    "elo_alphas = {\n",
    "    col: real_elo_alpha \n",
    "    for col in (real_elo_target_cols + diff_elo_target_cols)\n",
    "}\n",
    "# elo_alphas[\"ml_logit_mvmt\"] = 0.225\n",
    "\n",
    "real_ew = RealEloWrapper(elo_alphas=elo_alphas)\n",
    "real_elo_feat_df = real_ew.fit_transform_all(df)\n",
    "print(real_elo_feat_df.shape)\n",
    "real_elo_feat_df.head()\n",
    "\n",
    "elo_alphas = {\n",
    "    col: bin_elo_alpha for col in binary_elo_target_cols\n",
    "}\n",
    "bin_ew = BinaryEloWrapper(elo_alphas=elo_alphas)\n",
    "bin_elo_feat_df = bin_ew.fit_transform_all(df)\n",
    "print(bin_elo_feat_df.shape)\n",
    "bin_elo_feat_df.head()\n",
    "# feat_ml_df[\"log_height_diff\"] = np.log(feat_ml_df[\"imp_height\"]) - np.log(feat_ml_df[\"imp_height_opp\"])\n",
    "# feat_ml_df[\"log_age_diff\"] = np.log(feat_ml_df[\"age\"]) - np.log(feat_ml_df[\"age_opp\"])\n",
    "# feat_ml_df[\"log_reach_diff\"] = np.log(feat_ml_df[\"imp_reach\"]) - np.log(feat_ml_df[\"imp_reach_opp\"])\n",
    "# feat_ml_df[\"log_reach_diff\"] = feat_ml_df[\"log_reach_diff\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 360)\n"
     ]
    }
   ],
   "source": [
    "elo_feat_df = df.merge(\n",
    "    pca_elo_feat_df, \n",
    "    how=\"left\", \n",
    "    on=[\"fight_id\", \"FighterID_espn\", \"OpponentID_espn\"],\n",
    ").merge(\n",
    "    real_elo_feat_df.drop(columns=real_elo_target_cols),\n",
    "    how=\"left\",\n",
    "    on=[\"fight_id\", \"FighterID_espn\", \"OpponentID_espn\"],\n",
    ").merge(\n",
    "    bin_elo_feat_df.drop(columns=binary_elo_target_cols),\n",
    "    how=\"left\",\n",
    "    on=[\"fight_id\", \"FighterID_espn\", \"OpponentID_espn\"],\n",
    ")\n",
    "print(elo_feat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fight_id                                  133102\n",
       "Date                                      133102\n",
       "FighterResult                             132984\n",
       "Decision                                  132984\n",
       "Rnd                                       133102\n",
       "                                           ...  \n",
       "pred_elo_win_target_finish                133102\n",
       "fighter_elo_win_target_finish             133102\n",
       "opponent_elo_win_target_finish            133102\n",
       "updated_fighter_elo_win_target_finish     133102\n",
       "updated_opponent_elo_win_target_finish    133102\n",
       "Length: 360, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elo_feat_df.notnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpler features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 20) (133102, 360)\n"
     ]
    }
   ],
   "source": [
    "from model.mma_elo_model import unknown_fighter_id\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_simple_features(df):\n",
    "    # simple things that i needn't get from the fighter stats page\n",
    "    # eg number of fights, t_since_last_fight\n",
    "    assert (df[\"fight_id\"].value_counts() == 2).all()\n",
    "    df = df.assign(\n",
    "        is_ufc=df[\"Event\"].fillna(\"\").str.contains(\"UFC\"),\n",
    "        Date=pd.to_datetime(df[\"Date\"]),\n",
    "    )\n",
    "    feat_df = df.sort_values(\"Date\").copy()[[\n",
    "        \"fight_id\", \"FighterID_espn\", \"OpponentID_espn\", \"Date\", \"is_ufc\"\n",
    "    ]]\n",
    "    # Rolling features over fighter_careers\n",
    "    # because the data is doubled, we can simply group by the fighter id\n",
    "    feat_df[\"dummy\"] = 1\n",
    "    # total fights\n",
    "    feat_df[\"total_fights\"] = feat_df.groupby(\"FighterID_espn\")[\"dummy\"].cumsum()\n",
    "    feat_df[\"total_fights_opp\"] = feat_df.groupby(\"OpponentID_espn\")[\"dummy\"].cumsum()\n",
    "    # total ufc fights\n",
    "    feat_df[\"total_ufc_fights\"] = feat_df.groupby(\"FighterID_espn\")[\"is_ufc\"].cumsum()\n",
    "    feat_df[\"total_ufc_fights_opp\"] = feat_df.groupby(\"OpponentID_espn\")[\"is_ufc\"].cumsum()\n",
    "    # time since last fight\n",
    "    feat_df[\"t_since_last_fight\"] = feat_df.groupby(\"FighterID_espn\")[\"Date\"].diff().dt.days\n",
    "    feat_df[\"t_since_last_fight_opp\"] = feat_df.groupby(\"OpponentID_espn\")[\"Date\"].diff().dt.days\n",
    "    fill_val = 2*365 # arbitrarily say 2 years\n",
    "    feat_df[\"t_since_last_fight\"] = np.maximum(fill_val, feat_df[\"t_since_last_fight\"].fillna(fill_val))   \n",
    "    feat_df[\"t_since_last_fight_opp\"] = np.maximum(fill_val, feat_df[\"t_since_last_fight_opp\"].fillna(fill_val)) \n",
    "    # time since first fight\n",
    "    feat_df[\"t_since_first_fight\"] = (feat_df[\"Date\"] - feat_df.groupby(\"FighterID_espn\")[\"Date\"].transform(\"min\")).dt.days\n",
    "    feat_df[\"t_since_first_fight_opp\"] = (feat_df[\"Date\"] - feat_df.groupby(\"OpponentID_espn\")[\"Date\"].transform(\"min\")).dt.days\n",
    "    # compute diffs\n",
    "    feat_df[\"t_since_last_fight_diff\"] = (feat_df[\"t_since_last_fight\"] - \n",
    "                                            feat_df[\"t_since_last_fight_opp\"])\n",
    "    feat_df[\"t_since_last_fight_log_diff\"] = (np.log(feat_df[\"t_since_last_fight\"]) - \n",
    "                                                np.log(feat_df[\"t_since_last_fight_opp\"]))\n",
    "    feat_df[\"total_fights_diff\"] = (feat_df[\"total_fights\"] - \n",
    "                                    feat_df[\"total_fights_opp\"])\n",
    "    feat_df[\"total_fights_sqrt_diff\"] = (np.sqrt(feat_df[\"total_fights\"]) - \n",
    "                                        np.sqrt(feat_df[\"total_fights_opp\"]))\n",
    "    feat_df[\"total_ufc_fights_diff\"] = (feat_df[\"total_ufc_fights\"] - \n",
    "                                        feat_df[\"total_ufc_fights_opp\"])\n",
    "    feat_df[\"total_ufc_fights_sqrt_diff\"] = (np.sqrt(feat_df[\"total_ufc_fights\"]) - \n",
    "                                                np.sqrt(feat_df[\"total_ufc_fights_opp\"]))\n",
    "    return feat_df\n",
    "\n",
    "simple_feat_df = get_simple_features(elo_feat_df)\n",
    "print(simple_feat_df.shape, elo_feat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fight_id', 'FighterID_espn', 'OpponentID_espn', 'Date', 'is_ufc',\n",
       "       'dummy', 'total_fights', 'total_fights_opp', 'total_ufc_fights',\n",
       "       'total_ufc_fights_opp', 't_since_last_fight', 't_since_last_fight_opp',\n",
       "       't_since_first_fight', 't_since_first_fight_opp',\n",
       "       't_since_last_fight_diff', 't_since_last_fight_log_diff',\n",
       "       'total_fights_diff', 'total_fights_sqrt_diff', 'total_ufc_fights_diff',\n",
       "       'total_ufc_fights_sqrt_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_feat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pred_elo_PC_0',\n",
       " 'pred_elo_PC_1',\n",
       " 'pred_elo_PC_2',\n",
       " 'pred_elo_PC_3',\n",
       " 'pred_elo_PC_4',\n",
       " 'pred_elo_PC_5',\n",
       " 'pred_elo_PC_6',\n",
       " 'pred_elo_PC_7',\n",
       " 'pred_elo_PC_8',\n",
       " 'pred_elo_PC_9',\n",
       " 'pred_elo_PC_10',\n",
       " 'pred_elo_PC_11',\n",
       " 'pred_elo_PC_12',\n",
       " 'pred_elo_PC_13',\n",
       " 'pred_elo_signed_inverse_fight_time',\n",
       " 'pred_elo_win_target',\n",
       " 'pred_elo_win_target_finish',\n",
       " 'age_diff',\n",
       " 'log_reach_diff',\n",
       " 'weight_diff',\n",
       " 'height_diff',\n",
       " 'log_t_since_prev_fight_diff',\n",
       " 'log_t_since_first_fight_diff',\n",
       " 'total_fights_diff',\n",
       " 'usa_diff',\n",
       " 'russia_diff',\n",
       " 'stance_diff']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_ml_df = elo_feat_df.merge(\n",
    "    simple_feat_df, \n",
    "    how=\"left\",\n",
    "    on=[\"FighterID_espn\", \"OpponentID_espn\", \"Date\"],\n",
    "    suffixes=(\"_legacy\", \"\"),\n",
    ")\n",
    "\n",
    "feat_ml_df[\"age_diff\"] = (feat_ml_df[\"DOB\"] - feat_ml_df[\"DOB_opp\"]).dt.days / 365\n",
    "feat_ml_df[\"age_diff\"] = feat_ml_df[\"age_diff\"].fillna(0)\n",
    "\n",
    "feat_ml_df[\"log_reach_diff\"] = (\n",
    "    np.log(feat_ml_df[\"ReachInches\"]) - np.log(feat_ml_df[\"ReachInches_opp\"])\n",
    ").fillna(0)\n",
    "feat_ml_df[\"weight_diff\"] = (\n",
    "    feat_ml_df[\"min_weight\"] - feat_ml_df[\"min_weight_opp\"]\n",
    ").fillna(0)\n",
    "feat_ml_df[\"height_diff\"] = (\n",
    "    feat_ml_df[\"HeightInches\"] - feat_ml_df[\"HeightInches_opp\"]\n",
    ").fillna(0)\n",
    "\n",
    "feat_ml_df[\"t_since_first_fight_diff\"] = (\n",
    "    feat_ml_df[\"t_since_first_fight\"] - feat_ml_df[\"t_since_first_fight_opp\"]\n",
    ").fillna(0)\n",
    "feat_ml_df[\"log_t_since_first_fight_diff\"] = (\n",
    "    np.log(1 + feat_ml_df[\"t_since_first_fight\"]) - \n",
    "    np.log(1 + feat_ml_df[\"t_since_first_fight_opp\"])\n",
    ").fillna(0)\n",
    "\n",
    "feat_ml_df[\"log_t_since_prev_fight_diff\"] = (\n",
    "    np.log(1 + feat_ml_df[\"t_since_prev_fight\"]) -\n",
    "    np.log(1 + feat_ml_df[\"t_since_prev_fight_opp\"])\n",
    ").fillna(0)\n",
    "\n",
    "# whether or not the fighter is from the USA\n",
    "feat_ml_df[\"usa_diff\"] = (\n",
    "    feat_ml_df[\"Country\"].str.strip().str.lower().str.contains(\"usa\") -\n",
    "    feat_ml_df[\"Country_opp\"].str.strip().str.lower().str.contains(\"usa\")\n",
    ").fillna(0)\n",
    "\n",
    "feat_ml_df[\"russia_diff\"] = (\n",
    "    feat_ml_df[\"Country\"].str.strip().str.lower().str.contains(\"russia\") -\n",
    "    feat_ml_df[\"Country_opp\"].str.strip().str.lower().str.contains(\"russia\")\n",
    ").fillna(0)\n",
    "\n",
    "stance_fighter_clean = feat_ml_df[\"Stance\"].fillna(\"orthodox\").str.strip().str.lower()\n",
    "stance_fighter_clean.loc[~stance_fighter_clean.isin([\"southpaw\", \"switch\"])] = \"orthodox\"\n",
    "stance_opp_clean = feat_ml_df[\"Stance_opp\"].fillna(\"orthodox\").str.strip().str.lower()\n",
    "stance_opp_clean.loc[~stance_opp_clean.isin([\"southpaw\", \"switch\"])] = \"orthodox\"\n",
    "\n",
    "# advantage to fighter with the weirder stance\n",
    "feat_ml_df[\"stance_diff\"] = (\n",
    "    (stance_fighter_clean == \"southpaw\") & (stance_opp_clean == \"orthodox\") |\n",
    "    (stance_fighter_clean == \"switch\") & (stance_opp_clean == \"orthodox\")\n",
    ").astype(int) - (\n",
    "    (stance_fighter_clean == \"orthodox\") & (stance_opp_clean == \"southpaw\") |\n",
    "    (stance_fighter_clean == \"orthodox\") & (stance_opp_clean == \"switch\")\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# number of professional fights by fighters on that team, at that time\n",
    "# feat_ml_df[\"team_count_diff\"] = (\n",
    "#     feat_ml_df.groupby(\"Team\")[\"dummy\"].cumsum() -\n",
    "#     feat_ml_df.groupby(\"Team_opp\")[\"dummy\"].cumsum()\n",
    "# ).fillna(0)\n",
    "\n",
    "real_elo_target_cols = [\n",
    "#     \"fighter_result_time_left\", \n",
    "#     \"ml_logit_mvmt\",\n",
    "#     \"ordinal_fighter_result\",\n",
    "#     \"submission_fighter_result\",\n",
    "#     \"tko_ko_fighter_result\",\n",
    "#     \"decision_fighter_result\",\n",
    "    \"signed_inverse_fight_time\",\n",
    "    # \"finish_fighter_result\",\n",
    "    # *[col for col in stat_pca_df.columns \n",
    "    #   if col not in [\"FighterID_espn\", \"OpponentID_espn\", \"Date\"]],\n",
    "]\n",
    "\n",
    "feat_cols = [\n",
    "    *[f\"pred_elo_PC_{i}\" for i in range(n_pca)],\n",
    "\n",
    "    *[\"pred_elo_\"+c for c in [*diff_elo_target_cols, \n",
    "                               *real_elo_target_cols, \n",
    "                               *binary_elo_target_cols]],\n",
    "    \n",
    "    # \"t_since_last_fight_log_diff\", \n",
    "#     \"fights_per_day_diff\",\n",
    "#     \"t_since_last_fight_diff\",\n",
    "#     \"total_fights_sqrt_diff\", \n",
    "#     \"total_ufc_fights_diff\",\n",
    "    \n",
    "    \"age_diff\", \n",
    "#     \"log_age_diff\",\n",
    "#     \"reach_diff\", \n",
    "    \"log_reach_diff\",\n",
    "    \"weight_diff\", \n",
    "#     \"log_weight_diff\",\n",
    "    \"height_diff\",\n",
    "#     \"log_height_diff\",\n",
    "#     \"ml_logit_mvmt\",\n",
    "    \"log_t_since_prev_fight_diff\",\n",
    "    \"log_t_since_first_fight_diff\",\n",
    "    \"total_fights_diff\",\n",
    "#     \"quad_log_t_since_first_fight_diff\",\n",
    "    \"usa_diff\",\n",
    "    \"russia_diff\",\n",
    "    \"stance_diff\",\n",
    "    # \"team_count_diff\",\n",
    "]\n",
    "\n",
    "# new_feat_cols = [*feat_cols, \"ml_logit\"]\n",
    "feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pred_elo_PC_0', 'pred_elo_PC_1', 'pred_elo_PC_2', 'pred_elo_PC_3',\n",
       "       'pred_elo_PC_4', 'pred_elo_PC_5', 'pred_elo_PC_6', 'pred_elo_PC_7',\n",
       "       'pred_elo_PC_8', 'pred_elo_PC_9', 'pred_elo_PC_10', 'pred_elo_PC_11',\n",
       "       'pred_elo_PC_12', 'pred_elo_PC_13',\n",
       "       'pred_elo_signed_inverse_fight_time', 'pred_elo_win_target',\n",
       "       'pred_elo_win_target_finish'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_ml_df.columns[feat_ml_df.columns.str.contains(\"pred_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_elo_PC_0                         133102\n",
       "pred_elo_PC_1                         133102\n",
       "pred_elo_PC_2                         133102\n",
       "pred_elo_PC_3                         133102\n",
       "pred_elo_PC_4                         133102\n",
       "pred_elo_PC_5                         133102\n",
       "pred_elo_PC_6                         133102\n",
       "pred_elo_PC_7                         133102\n",
       "pred_elo_PC_8                         133102\n",
       "pred_elo_PC_9                         133102\n",
       "pred_elo_PC_10                        133102\n",
       "pred_elo_PC_11                        133102\n",
       "pred_elo_PC_12                        133102\n",
       "pred_elo_PC_13                        133102\n",
       "pred_elo_signed_inverse_fight_time    133102\n",
       "pred_elo_win_target                   133102\n",
       "pred_elo_win_target_finish            133102\n",
       "age_diff                              133102\n",
       "log_reach_diff                        133102\n",
       "weight_diff                           133102\n",
       "height_diff                           133102\n",
       "log_t_since_prev_fight_diff           133102\n",
       "log_t_since_first_fight_diff          133102\n",
       "total_fights_diff                     133102\n",
       "usa_diff                              133102\n",
       "russia_diff                           133102\n",
       "stance_diff                           133102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see how much data we have for each feature\n",
    "feat_ml_df[feat_cols].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_elo_PC_0                         66551\n",
      "pred_elo_PC_1                         66551\n",
      "pred_elo_PC_2                         66551\n",
      "pred_elo_PC_3                         66551\n",
      "pred_elo_PC_4                         66551\n",
      "pred_elo_PC_5                         66551\n",
      "pred_elo_PC_6                         66551\n",
      "pred_elo_PC_7                         66551\n",
      "pred_elo_PC_8                         66551\n",
      "pred_elo_PC_9                         66551\n",
      "pred_elo_PC_10                        66551\n",
      "pred_elo_PC_11                        66551\n",
      "pred_elo_PC_12                        66551\n",
      "pred_elo_PC_13                        66551\n",
      "pred_elo_signed_inverse_fight_time    66551\n",
      "pred_elo_win_target                   66551\n",
      "pred_elo_win_target_finish            66551\n",
      "age_diff                              66551\n",
      "log_reach_diff                        66551\n",
      "weight_diff                           66551\n",
      "height_diff                           66551\n",
      "log_t_since_prev_fight_diff           66551\n",
      "log_t_since_first_fight_diff          66551\n",
      "total_fights_diff                     66551\n",
      "usa_diff                              66551\n",
      "russia_diff                           66551\n",
      "stance_diff                           66551\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(66551, 387)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_ml_df = feat_ml_df.drop_duplicates(subset=[\"fight_id\"])\n",
    "print(feat_ml_df[feat_cols].notnull().sum())\n",
    "feat_ml_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation - opening line\n",
    "\n",
    "Note that this isn't realistic. Don't get your hopes up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fighter_implied_col = \"p_fighter_open_implied\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.mma_log_reg_stan import SimpleSymmetricModel\n",
    "\n",
    "mod = SimpleSymmetricModel(\n",
    "    feat_cols=feat_cols, target_col=\"win_target\", \n",
    "    p_fighter_implied_col=p_fighter_implied_col,\n",
    "    beta_prior_std=1.0, mcmc=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on date range: 2007-07-07 2020-12-31\n",
      "Initial log joint probability = -24862\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5872.92    0.00535449       1.11391      0.7951      0.7951       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5872.92   0.000216476      0.169985           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-01-16\n",
      "Initial log joint probability = -20231.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5880.85      0.010173      0.679012           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5880.85   0.000346604      0.155043      0.6577      0.6577       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-01-20\n",
      "Initial log joint probability = -24909.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5888.73    0.00108716      0.740088           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5888.73   0.000105623      0.032905           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-01-23\n",
      "Initial log joint probability = -23942.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5896.95     0.0220777       3.98002           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -5896.94    9.9095e-05      0.116868      0.9542      0.9542       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-01-30\n",
      "Initial log joint probability = -21647.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5904.67    0.00314756      0.980171           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5904.67   9.42141e-05     0.0576695           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-05\n",
      "Initial log joint probability = -22275.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5905.27     0.0048839        1.7107           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5905.26   0.000410246      0.154881      0.8783      0.8783       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-06\n",
      "Initial log joint probability = -23642.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -5914.6    0.00118269      0.435095      0.8907      0.8907       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -5914.6   0.000238368     0.0867092           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-12\n",
      "Initial log joint probability = -28023.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5918.99    0.00144109       5.16073      0.5693      0.5693       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5918.98    0.00076515      0.127428           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-13\n",
      "Initial log joint probability = -23112.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5923.95   0.000529994       0.60318           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5923.95   0.000167059      0.210584           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-19\n",
      "Initial log joint probability = -19963.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5926.56   0.000744619      0.381381      0.8475      0.8475       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -5926.56   0.000434956      0.104516           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-20\n",
      "Initial log joint probability = -23369.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5935.95    0.00221244      0.534949      0.9074      0.9074       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5935.95    0.00026799     0.0853476           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-23\n",
      "Initial log joint probability = -25657.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -5936     0.0174815       6.56554           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      25      -5935.99   6.55323e-05      0.167478      0.5334      0.5334       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-26\n",
      "Initial log joint probability = -21618.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5936.85    0.00197346       1.43265           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -5936.85   0.000576691     0.0861846           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-27\n",
      "Initial log joint probability = -20129.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5942.49    0.00220792       1.32253      0.2439           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5942.49    0.00289397      0.100379           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-05\n",
      "Initial log joint probability = -32378.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5943.08   0.000653981      0.419891           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -5943.08   0.000354207     0.0876885           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-06\n",
      "Initial log joint probability = -23582.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5953.76    0.00191003       2.84034           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5953.76   0.000699632      0.152145           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-11\n",
      "Initial log joint probability = -22701.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5954.67    0.00182824      0.792256           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5954.67    7.9785e-05      0.062415      0.4654           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-12\n",
      "Initial log joint probability = -20068.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5956.61   0.000386048      0.235176           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5956.61    0.00014589     0.0365308           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-13\n",
      "Initial log joint probability = -26912.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5963.31    0.00331449       11.1146      0.4009      0.4009       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      25      -5963.27   0.000296854      0.038091           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-18\n",
      "Initial log joint probability = -19674\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5967.27    0.00170058      0.476529           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5967.27   0.000160685     0.0803905      0.8967      0.8967       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-19\n",
      "Initial log joint probability = -27389.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5977.32    0.00224528      0.342738      0.9726      0.9726       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5977.32   0.000206655     0.0750872           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-20\n",
      "Initial log joint probability = -18785.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -5989.4   0.000107103     0.0416731           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-26\n",
      "Initial log joint probability = -19529.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5991.84    0.00580949       1.18767           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5991.84   0.000368936     0.0873777           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-27\n",
      "Initial log joint probability = -27375.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5998.18    0.00643372      0.849712           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5998.18   0.000150271     0.0409464           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-01\n",
      "Initial log joint probability = -25359.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6002.75   0.000532338      0.667919      0.6536      0.6536       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6002.75   0.000244806     0.0707067      0.9939      0.9939       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-02\n",
      "Initial log joint probability = -21493\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6010.32     0.0012049      0.560189           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6010.32   0.000543659      0.125749      0.8088      0.8088       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-07\n",
      "Initial log joint probability = -21142.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6012.5    0.00245297       1.58189       0.484       0.484       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -6012.5   0.000315185     0.0358209           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-09\n",
      "Initial log joint probability = -23218.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6019.03   0.000473881      0.207949           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6019.03   0.000326931     0.0746948           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-10\n",
      "Initial log joint probability = -22864.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6027.54   0.000702162      0.535692      0.8751      0.8751       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6027.54   0.000130404     0.0476348           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-14\n",
      "Initial log joint probability = -25077.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6028.16    0.00107541       1.64574      0.6443      0.6443       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6028.16   0.000272828      0.107183           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-16\n",
      "Initial log joint probability = -24106.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6038.1     0.0219057       10.0925           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6038.08   0.000155511      0.101232       0.865       0.865       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-17\n",
      "Initial log joint probability = -20349.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6045.09    0.00127322       1.17555      0.8797      0.8797       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6045.09   0.000247688      0.128878           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-21\n",
      "Initial log joint probability = -19975\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6045.79    0.00376556       1.74473           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6045.79   0.000175278     0.0264591           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-23\n",
      "Initial log joint probability = -19309.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6058.82    0.00155654       1.00659           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6058.82   0.000309323      0.111688      0.8004      0.8004       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-24\n",
      "Initial log joint probability = -27682.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6069.48     0.0132964       3.04468           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6069.47   0.000290166     0.0716325           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-28\n",
      "Initial log joint probability = -16902.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6073.02   0.000596687      0.972472      0.5779      0.5779       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6073.02   0.000611736     0.0701111           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-29\n",
      "Initial log joint probability = -27076.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6076.28    0.00027134       0.26123           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6076.28   0.000121187     0.0179486           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-30\n",
      "Initial log joint probability = -22386.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6078.9     0.0033383      0.644746           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -6078.9   7.74913e-05     0.0399017      0.4156      0.9787       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-01\n",
      "Initial log joint probability = -21996.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6086.51   0.000936199      0.802569           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6086.51   0.000123015      0.141502      0.5783      0.5783       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-06\n",
      "Initial log joint probability = -25962.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6093.5    0.00309699       2.13801      0.4137      0.9725       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23       -6093.5   4.64135e-05      0.139111      0.6811      0.6811       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-07\n",
      "Initial log joint probability = -19371.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6102.08    0.00138859       2.76757      0.6711      0.6711       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6102.08   0.000159412     0.0976743      0.4559       0.899       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-08\n",
      "Initial log joint probability = -23255.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6109.85   0.000702675      0.952951      0.8795      0.8795       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6109.85   0.000325269     0.0907518           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-14\n",
      "Initial log joint probability = -20784.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6111.66    0.00715127       1.33186           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6111.66   0.000119984     0.0879981      0.3803           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-15\n",
      "Initial log joint probability = -21723.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6118.03   0.000823752       0.34761           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6118.03   0.000300353      0.113335           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-21\n",
      "Initial log joint probability = -22662.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6133.3    0.00343167       0.67575           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -6133.3   0.000187525      0.216903      0.8873      0.8873       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-22\n",
      "Initial log joint probability = -21709\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6141.47    0.00117663      0.737378           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6141.47   0.000118908      0.135864      0.9775      0.9775       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-28\n",
      "Initial log joint probability = -24985.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6142.68     0.0326775       2.44368           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6142.68   0.000382074      0.181386      0.8864      0.8864       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-29\n",
      "Initial log joint probability = -23746.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6144.15   0.000610924       1.42887      0.7468      0.7468       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6144.15   0.000269539      0.117841           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-04\n",
      "Initial log joint probability = -18950.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6148.11    0.00376925       1.75725           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6148.11   0.000311105      0.134701           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-05\n",
      "Initial log joint probability = -25153\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6159.48    0.00138908      0.431876      0.8979      0.8979       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6159.48    0.00029169     0.0653118           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-10\n",
      "Initial log joint probability = -22960.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6164.63   0.000984008      0.323129           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6164.63   8.40109e-05     0.0578756      0.8082      0.8082       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-11\n",
      "Initial log joint probability = -28998\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6171.58    0.00224145      0.548061           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6171.58   0.000168285      0.058838      0.9062      0.9062       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-12\n",
      "Initial log joint probability = -22492.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6181.04    0.00117355      0.534168           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6181.04   0.000141183      0.100824       0.867       0.867       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-17\n",
      "Initial log joint probability = -23310.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6188.87     0.0163634      0.992976           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6188.87   0.000166524     0.0755686           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-18\n",
      "Initial log joint probability = -21001\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6190.87    0.00141798       1.68045      0.5066      0.5066       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6190.87   0.000215481     0.0596848           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-19\n",
      "Initial log joint probability = -23845.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6203.04   0.000988038      0.395739           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6203.04    0.00011927      0.105112      0.6044      0.6044       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-24\n",
      "Initial log joint probability = -18205\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6207.26    0.00197042      0.493051           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6207.26   0.000267665     0.0917057           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-25\n",
      "Initial log joint probability = -19540.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6222.85   0.000491282      0.370636           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6222.85   0.000525088      0.101217       0.811       0.811       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-26\n",
      "Initial log joint probability = -22505.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6235.18   0.000295329      0.125618           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-02\n",
      "Initial log joint probability = -22521.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      18      -6238.22   0.000464642      0.133562           1           1       20   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-03\n",
      "Initial log joint probability = -24192.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6238.83   0.000657607      0.384505           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6238.83   8.11477e-05      0.108994       0.475           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-04\n",
      "Initial log joint probability = -26592.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -6239   0.000869163      0.467487           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20         -6239   0.000157486      0.147426      0.7239      0.7239       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-10\n",
      "Initial log joint probability = -24804.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6245.22    0.00386807       1.33695           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6245.22    0.00108477     0.0250595           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-16\n",
      "Initial log joint probability = -32312.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6254.2     0.0116553       2.06834           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6254.19   0.000271362     0.0740518           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-17\n",
      "Initial log joint probability = -28572.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6261.57   0.000863749      0.323963           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6261.57   0.000134634     0.0651428           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-18\n",
      "Initial log joint probability = -22001.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6263.35   0.000500466      0.592683           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6263.35    0.00014877     0.0563205           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-24\n",
      "Initial log joint probability = -23813.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6274.73    0.00019296     0.0843419           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-25\n",
      "Initial log joint probability = -22623.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6276.3    0.00670275       1.24899           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6276.29    0.00017011      0.106411      0.9148      0.9148       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-30\n",
      "Initial log joint probability = -24304.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6282.21    0.00428013       4.17632           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23       -6282.2   8.98365e-05      0.171909      0.6134      0.6134       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-31\n",
      "Initial log joint probability = -26498.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6293.32    0.00258044      0.748475      0.7951      0.7951       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6293.32   0.000713823     0.0909438           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-01\n",
      "Initial log joint probability = -21546.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6294.63     0.0116802       2.03434           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6294.63   0.000348401     0.0535114           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-06\n",
      "Initial log joint probability = -18807.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6298.07     0.0038805       1.93179           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6298.07   0.000243626      0.051589           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-07\n",
      "Initial log joint probability = -24917\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6305.04   0.000932176      0.826436      0.7349      0.7349       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6305.04   4.80656e-05        0.1048      0.5452      0.5452       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-13\n",
      "Initial log joint probability = -19409.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6311.86    0.00376315       1.25953      0.5131           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6311.86   0.000372584      0.186318      0.9507      0.9507       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-14\n",
      "Initial log joint probability = -29260.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6315.24    0.00141785       2.04388       0.562       0.562       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6315.24   0.000271042      0.184376           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-19\n",
      "Initial log joint probability = -20779.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6317.61    0.00411731      0.708348           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6317.61   0.000264134     0.0832257       0.765       0.765       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-20\n",
      "Initial log joint probability = -23475.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6322.27     0.0143938       9.04651           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      25      -6322.24   8.24651e-05     0.0505858           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-21\n",
      "Initial log joint probability = -20115.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6330.9   0.000398373      0.134706           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-27\n",
      "Initial log joint probability = -26226\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6347.27    0.00155131       3.00647      0.6138      0.6138       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6347.27   0.000135012     0.0302268           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-28\n",
      "Initial log joint probability = -21738.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6355.37     0.0577061       7.64525           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6355.36   0.000314541      0.104952      0.3777      0.9592       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-29\n",
      "Initial log joint probability = -29784.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6355.5    0.00153726      0.562175      0.9756      0.9756       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20       -6355.5   0.000194159      0.117555      0.8986      0.8986       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-31\n",
      "Initial log joint probability = -24500.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6357.34   0.000758605       1.88951      0.5552      0.5552       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6357.34   0.000647497      0.170519           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-04\n",
      "Initial log joint probability = -22844.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6367.08      0.001113       1.12538      0.6368      0.6368       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6367.08   0.000205659     0.0287126           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-05\n",
      "Initial log joint probability = -24139.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6369.59     0.0052778       8.04717           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6369.57    0.00025383     0.0678734      0.4728      0.9187       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-07\n",
      "Initial log joint probability = -27322.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6373.94     0.0181458       4.53226           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6373.94   0.000127713      0.139768      0.8024      0.8024       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-11\n",
      "Initial log joint probability = -21151.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6379.83   0.000984812      0.610626           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6379.83    0.00020423     0.0575292           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-14\n",
      "Initial log joint probability = -21568.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6382.51    0.00102427       0.96968           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6382.51   0.000356505      0.130358           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-16\n",
      "Initial log joint probability = -24981.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6383.69    0.00883664       11.0434           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6383.64   0.000141073     0.0907356           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-17\n",
      "Initial log joint probability = -26105.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6385.92   0.000665602       1.85561      0.5301      0.5301       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6385.92   0.000723634      0.144434           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-18\n",
      "Initial log joint probability = -29154.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6402.66   0.000717754      0.374334      0.8193      0.8193       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6402.66   0.000353778     0.0747765           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-21\n",
      "Initial log joint probability = -20566.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6405.77    0.00677314       5.12599           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6405.76   0.000219886     0.0756168           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-24\n",
      "Initial log joint probability = -25723.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6407.4     0.0710774       5.31021           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6407.38   0.000443647     0.0384376      0.8689      0.8689       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-25\n",
      "Initial log joint probability = -27262.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6417.01    0.00526869       7.13796      0.5653      0.5653       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21         -6417   0.000207828      0.164371           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-28\n",
      "Initial log joint probability = -22469.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6419.69    0.00154355       1.31751           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6419.69   0.000196328     0.0866104           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-30\n",
      "Initial log joint probability = -32072.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6424.43    0.00314977       4.57769           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6424.43   3.58567e-05     0.0229834      0.2799      0.9277       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-01\n",
      "Initial log joint probability = -20894.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6432.37    0.00278132       2.62738           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6432.37   0.000187675     0.0330041           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-02\n",
      "Initial log joint probability = -21701.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6441.69   0.000348242      0.308771      0.8914      0.8914       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6441.69   0.000154311       0.12303           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-05\n",
      "Initial log joint probability = -21999.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6444.82     0.0083677       4.27518           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6444.81    0.00012464     0.0559521      0.7655      0.7655       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-09\n",
      "Initial log joint probability = -26000.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6449.96    0.00172875       1.91806           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6449.95   0.000104057      0.128495           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-12\n",
      "Initial log joint probability = -22326.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6451.3   0.000572784      0.664165           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -6451.3   0.000111044      0.117012           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-16\n",
      "Initial log joint probability = -21814.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6467.1    0.00770869       4.59053      0.3775      0.3775       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6467.09   0.000225556      0.112298      0.9428      0.9428       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-17\n",
      "Initial log joint probability = -22510.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6469.53   0.000280023     0.0795199           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-19\n",
      "Initial log joint probability = -26134.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6472.79    0.00127879       1.87474       0.989       0.989       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6472.79   0.000418439      0.133084           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-22\n",
      "Initial log joint probability = -24981.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6475.28    0.00403261        1.9772           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6475.28   0.000237751      0.150048           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-23\n",
      "Initial log joint probability = -22277.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6495.64     0.0127663        6.0869           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6495.63   0.000233903       0.07626           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-26\n",
      "Initial log joint probability = -30335.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6496.01    0.00612118       2.56989           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6496.01   0.000244585     0.0416231           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-27\n",
      "Initial log joint probability = -25019.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6503.09    0.00102736      0.510566           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6503.09    0.00010081      0.190816      0.5729      0.5729       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-29\n",
      "Initial log joint probability = -27598\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6507.58    0.00837973       2.53576           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6507.58   0.000391696      0.121675           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-30\n",
      "Initial log joint probability = -32363\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6516.81    0.00189505       1.48283      0.7043      0.7043       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6516.81   0.000209493     0.0489333           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-02\n",
      "Initial log joint probability = -24953.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6520.46   0.000185973     0.0995475      0.8887      0.8887       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-05\n",
      "Initial log joint probability = -29899.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6527.72     0.0180498       6.61856           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23       -6527.7   0.000230671      0.145336      0.7686      0.7686       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-06\n",
      "Initial log joint probability = -23481.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6538.46    0.00269131       1.42524           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6538.46   0.000144945      0.152065      0.3447           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-07\n",
      "Initial log joint probability = -32115\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6538.97     0.0483071       1.69048           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6538.97   0.000247557     0.0741301      0.7863      0.7863       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-12\n",
      "Initial log joint probability = -23765.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6543.25     0.0183814      0.629259           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6543.25   0.000205907       0.17284      0.8128      0.8128       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-13\n",
      "Initial log joint probability = -28029\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6550.24     0.0012893      0.344477           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6550.24   0.000290283     0.0749597           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-14\n",
      "Initial log joint probability = -26944.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6555.55    0.00418025      0.642325           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6555.55   0.000395153     0.0799132           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-19\n",
      "Initial log joint probability = -32578.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6559.75    0.00178021       1.23942           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6559.75   0.000168863      0.100181           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-20\n",
      "Initial log joint probability = -21651.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6566.33   0.000873824       1.47454      0.5646      0.5646       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6566.33   0.000240441      0.124564           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-21\n",
      "Initial log joint probability = -33319.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6568.19     0.0031126       2.08662           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6568.19   8.14009e-05     0.0163196           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-27\n",
      "Initial log joint probability = -23581.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6568.53    0.00136266       0.58288       0.778       0.778       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6568.53    0.00070485      0.157223           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-03\n",
      "Initial log joint probability = -26414.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6576.71    0.00233951       5.86801      0.5653      0.5653       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6576.71   7.57107e-05     0.0810487      0.4823           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-04\n",
      "Initial log joint probability = -24494.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6586.33    0.00908819       3.60316           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6586.33   0.000168975      0.131369           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-10\n",
      "Initial log joint probability = -24317.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6594.81    0.00136687       1.52049      0.4525      0.4525       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6594.81    0.00309133      0.138041           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-11\n",
      "Initial log joint probability = -28105.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6610.34    0.00873622       2.09601           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6610.34   0.000229728      0.210506      0.5648      0.5648       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-17\n",
      "Initial log joint probability = -24005.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6614.29    0.00399641       1.48387           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6614.28   0.000959615     0.0867056      0.6764      0.6764       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-18\n",
      "Initial log joint probability = -30609.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6625.16    0.00571831       4.08977           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6625.16    7.5992e-05     0.0638323           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-19\n",
      "Initial log joint probability = -25146.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6626.24    0.00553425       1.55055      0.8565      0.8565       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6626.24   0.000119921       0.10219      0.8497      0.8497       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-30\n",
      "Initial log joint probability = -25918\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6626.79   0.000695105      0.599721           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6626.79   7.29046e-05      0.070213      0.4661      0.9764       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-12\n",
      "Initial log joint probability = -20758.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6629.89    0.00865918       3.97089           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6629.88    0.00010549      0.028019           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-14\n",
      "Initial log joint probability = -26250.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6632.37    0.00041683      0.436313           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6632.37   0.000391707     0.0914361           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-15\n",
      "Initial log joint probability = -21264.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6642.85   0.000905397      0.627359           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6642.85   0.000483419      0.138768           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-21\n",
      "Initial log joint probability = -27142.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6647.17    0.00207705       1.78106           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6647.17   0.000324494      0.144305           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-22\n",
      "Initial log joint probability = -28384.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6655.08   0.000278262      0.254375           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6655.08   0.000154632      0.139054           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-28\n",
      "Initial log joint probability = -20601\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6661.37    0.00233573       1.77454           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6661.37   0.000153447      0.113409      0.9627      0.9627       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-29\n",
      "Initial log joint probability = -23781.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6669.61   0.000425683      0.242984           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6669.61   0.000196423      0.110228      0.9576      0.9576       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-03\n",
      "Initial log joint probability = -26052.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6670.53     0.0049287       1.77208           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6670.53   0.000211676     0.0823554           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-04\n",
      "Initial log joint probability = -22105.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6673.08   0.000427503      0.177076           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6673.08   0.000106114     0.0929593           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-05\n",
      "Initial log joint probability = -26042\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6677.32     0.0020381       1.04986           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6677.32   0.000105645      0.113136      0.4889           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-06\n",
      "Initial log joint probability = -19464.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6680.71    0.00924821       1.52459           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6680.71   0.000543639     0.0516411           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-11\n",
      "Initial log joint probability = -26611.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6683.79    0.00452508       6.66893       0.264       0.264       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6683.77   0.000520725     0.0474555           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-12\n",
      "Initial log joint probability = -35149.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6691.52    0.00665552        4.9239           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6691.51   0.000290264     0.0815342           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-18\n",
      "Initial log joint probability = -24205.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6694.35     0.0137218      0.590808           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6694.35   0.000352921      0.152345           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-19\n",
      "Initial log joint probability = -27214\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6708.39   0.000465982      0.507646      0.8346      0.8346       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6708.39   0.000166857     0.0752454           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-23\n",
      "Initial log joint probability = -31610.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6708.63     0.0039622       1.90296           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6708.63   0.000209505     0.0835617           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-25\n",
      "Initial log joint probability = -27331.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6718.66    0.00491792       1.79472       0.915       0.915       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6718.66   7.89613e-05      0.108207      0.8884      0.8884       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-26\n",
      "Initial log joint probability = -29097.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6731.83      0.036906       6.89411           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6731.81   0.000191541     0.0663515           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-27\n",
      "Initial log joint probability = -25196\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6732.17    0.00109367       1.60884      0.4133      0.4133       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6732.17    0.00228048      0.189398           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-04\n",
      "Initial log joint probability = -25628.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6737.7      0.149399       5.84673           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6737.69   0.000179399      0.143044           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-05\n",
      "Initial log joint probability = -23218.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6748.33   0.000927684      0.698219      0.9736      0.9736       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6748.33   9.95763e-05     0.0431313           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-09\n",
      "Initial log joint probability = -20929.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6751.64    0.00237701       2.55341      0.8452      0.8452       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6751.64   0.000459976     0.0685262           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-11\n",
      "Initial log joint probability = -21601.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6760.59   0.000537729      0.973461           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6760.59   0.000796808      0.108166           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-12\n",
      "Initial log joint probability = -25086\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6772.59    0.00509713       1.08703      0.8178      0.8178       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6772.59   0.000149085      0.155975           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-17\n",
      "Initial log joint probability = -19916.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6775.02     0.0171002       2.90087           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6775.02   0.000527199     0.0265425           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-18\n",
      "Initial log joint probability = -18363.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6780.94    0.00110896      0.244857      0.8787      0.8787       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6780.94   0.000157858      0.132909      0.8299      0.8299       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-19\n",
      "Initial log joint probability = -24318.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6791.07    0.00793657       1.92153           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6791.06   0.000109165      0.100303      0.3415      0.9774       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-25\n",
      "Initial log joint probability = -22819.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6800.15   0.000599607        1.2977           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6800.15   0.000100464     0.0713438      0.2948      0.9757       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-26\n",
      "Initial log joint probability = -27409.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6808.4    0.00208734      0.483372           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -6808.4   0.000178852      0.120218           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-27\n",
      "Initial log joint probability = -31942.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6811.73    0.00475688       1.92711           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6811.73   0.000119263     0.0834404           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-01\n",
      "Initial log joint probability = -24071.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6817.35   0.000269911      0.298041      0.9155      0.9155       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6817.35   0.000127889      0.083027           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-02\n",
      "Initial log joint probability = -25472.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6826.41    0.00128026       1.79504      0.7168      0.7168       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6826.41   0.000282255      0.062226           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-08\n",
      "Initial log joint probability = -27745.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6828.75     0.0610916       2.33051           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6828.74   0.000635785      0.102891      0.5007      0.9712       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-09\n",
      "Initial log joint probability = -24467.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6837.08    0.00188627       1.02231           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6837.07   0.000371648      0.152231           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-15\n",
      "Initial log joint probability = -35679.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6846.27     0.0106842       3.97168           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6846.26   0.000229797      0.101815           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-16\n",
      "Initial log joint probability = -28232.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6855.18     0.0030006       1.73875           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6855.18   0.000109085     0.0591448           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-20\n",
      "Initial log joint probability = -21981.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6861.63    0.00342478       1.55864           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6861.63   0.000138507      0.142976      0.9905      0.9905       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-22\n",
      "Initial log joint probability = -22496.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6863.49    0.00656765       1.94599           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6863.49   0.000187693      0.151586      0.4328           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-23\n",
      "Initial log joint probability = -30808.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6880.93    0.00147428      0.543651           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6880.93    0.00032073      0.148357           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-24\n",
      "Initial log joint probability = -22752.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6882.13   0.000650977      0.353606           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6882.13   0.000234094      0.129349           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-28\n",
      "Initial log joint probability = -20897.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6885.83     0.0014626       1.51935      0.9982      0.9982       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6885.83   0.000266653       0.11797           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-30\n",
      "Initial log joint probability = -21944.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6891.89     0.0218151       4.50896           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6891.88   5.07261e-05     0.0494665      0.3613      0.9589       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-06\n",
      "Initial log joint probability = -28399.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6911.16   0.000838342      0.619554      0.8235      0.8235       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6911.16   0.000196942      0.124094           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-07\n",
      "Initial log joint probability = -23122.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6923.13   0.000119042      0.164789      0.8992      0.8992       20   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-11\n",
      "Initial log joint probability = -25638.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6928.19    0.00191235       2.53145           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6928.19   0.000110432     0.0864915           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-13\n",
      "Initial log joint probability = -27435.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6936.75     0.0396285       6.95958           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6936.73   0.000968537     0.0545021      0.8342      0.8342       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-14\n",
      "Initial log joint probability = -23621.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6945.24   0.000729428      0.262121      0.4806      0.9878       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6945.24   0.000310355     0.0539706           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-20\n",
      "Initial log joint probability = -27407.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6951.86     0.0120685        3.0463      0.4719           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6951.85   0.000203727      0.109693      0.6322      0.6322       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-21\n",
      "Initial log joint probability = -26318.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6957.81     0.0320983       1.60024           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6957.81   0.000609961      0.198128      0.6638      0.6638       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-22\n",
      "Initial log joint probability = -24118.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6957.94   0.000634753      0.361486      0.9941      0.9941       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6957.94   0.000224903       0.14704           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-27\n",
      "Initial log joint probability = -31720.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6959.37    0.00123821      0.320862           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6959.37   0.000196091     0.0706451           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-28\n",
      "Initial log joint probability = -32901.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6964.52    0.00121625      0.456048           1           1       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6964.52   8.95098e-05     0.0663192      0.7585      0.7585       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-03\n",
      "Initial log joint probability = -32888.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6969.81     0.0109122        3.6734           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6969.81   0.000175859     0.0655349           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-04\n",
      "Initial log joint probability = -26766.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6975.91    0.00209373       1.01922           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6975.91   0.000169429      0.121264           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-09\n",
      "Initial log joint probability = -24831.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6979.75    0.00468172      0.981392           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6979.75   0.000102499      0.219764      0.5129      0.5129       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-10\n",
      "Initial log joint probability = -29808\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6988.62   0.000793808       1.03655       0.725       0.725       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6988.62    0.00025148      0.204634      0.9358      0.9358       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-11\n",
      "Initial log joint probability = -28917.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6992.78    0.00376719       1.58605      0.9366      0.9366       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6992.78   8.82816e-05      0.132655      0.7862      0.7862       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-17\n",
      "Initial log joint probability = -25320.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6999.81      0.012885       1.77199           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -6999.8   0.000207403      0.130097           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-18\n",
      "Initial log joint probability = -26864.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7011.36    0.00507799        7.0499           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7011.36    0.00011336      0.167094           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-24\n",
      "Initial log joint probability = -23497\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7025.04    0.00768978       3.62578           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7025.04   6.52061e-05      0.181818      0.6456      0.6456       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-25\n",
      "Initial log joint probability = -29099.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7037.04    0.00157571       3.89674      0.6478      0.6478       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7037.04   0.000125984     0.0743331      0.4185      0.9452       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-26\n",
      "Initial log joint probability = -17901.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7038.33   0.000436178      0.275041           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7038.33   0.000195623      0.162402           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-01\n",
      "Initial log joint probability = -25028.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7043.33    0.00346549        4.9945      0.5487      0.5487       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7043.33   0.000257081     0.0984784           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-02\n",
      "Initial log joint probability = -27054.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7053.86      0.037109       3.09333           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7053.86   0.000283462       0.22904      0.6459      0.6459       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-03\n",
      "Initial log joint probability = -33484\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7054.04    0.00625826       5.89654           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7054.03   0.000146575      0.127775      0.7736      0.7736       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-08\n",
      "Initial log joint probability = -20509.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7057.91   0.000694017      0.533545           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7057.91   0.000109736      0.177475      0.8382      0.8382       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-09\n",
      "Initial log joint probability = -28040.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7064.87     0.0037449       2.38524           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7064.87   0.000798261      0.106312           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-14\n",
      "Initial log joint probability = -24970.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7066.83   0.000583105       1.70917           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7066.83   0.000151397      0.160138      0.3683           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-15\n",
      "Initial log joint probability = -29779.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7068.02     0.0115013      0.897634           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7068.02   0.000216706      0.108757      0.7983      0.7983       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-16\n",
      "Initial log joint probability = -30270.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7075.9   0.000620653      0.300458           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20       -7075.9    0.00018721      0.121557           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-20\n",
      "Initial log joint probability = -25785\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7079.97    0.00109467       0.89117           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7079.97   6.61795e-05      0.150918      0.6238      0.6238       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-22\n",
      "Initial log joint probability = -26951.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7094.1     0.0176342       6.75034           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7094.09   0.000112162     0.0642404      0.7043      0.7043       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-23\n",
      "Initial log joint probability = -25800.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7112.02   0.000717951      0.426989           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7112.02   0.000349804      0.274721      0.9685      0.9685       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-26\n",
      "Initial log joint probability = -22295.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7115.26    0.00280216       2.11959      0.7046      0.7046       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7115.26   0.000450122      0.163268           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-29\n",
      "Initial log joint probability = -23536.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7122.6    0.00141612       1.52952           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -7122.6   0.000675289     0.0760193           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-30\n",
      "Initial log joint probability = -28143\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7128.15    0.00251681       2.15643           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7128.15   0.000265405     0.0989282           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-02\n",
      "Initial log joint probability = -22611.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7130.79    0.00100885      0.547983      0.9982      0.9982       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7130.79   0.000203164      0.105568           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-05\n",
      "Initial log joint probability = -24439\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7140.39   0.000435499      0.460071           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7140.39   0.000223784     0.0816842           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-06\n",
      "Initial log joint probability = -40369.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7145.38    0.00948226       2.59234           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7145.38    0.00023681      0.141815           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-09\n",
      "Initial log joint probability = -27554.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7147.62     0.0121524      0.618533           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7147.62   0.000111788      0.159594      0.9603      0.9603       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-12\n",
      "Initial log joint probability = -29440.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7152.27   0.000470436      0.356074           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7152.27   6.34794e-05      0.157651      0.6461      0.6461       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-13\n",
      "Initial log joint probability = -24197.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7175.8    0.00121592      0.988563           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -7175.8   5.94759e-05     0.0435265      0.3302       0.991       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-16\n",
      "Initial log joint probability = -33237.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7179.96    0.00953554       29.6483      0.4648      0.4648       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7179.75   0.000293641      0.120033      0.9089      0.9089       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-19\n",
      "Initial log joint probability = -27482.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7182.28    0.00300445      0.485672      0.9779      0.9779       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7182.28   0.000205257     0.0941703           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-20\n",
      "Initial log joint probability = -25827.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7199.15    0.00580137        2.2651      0.5913      0.5913       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7199.15    0.00482152      0.106956           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-23\n",
      "Initial log joint probability = -25935.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7203.26    0.00668615      0.910656           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7203.26   0.000126214      0.057167           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-26\n",
      "Initial log joint probability = -28713.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7208.51    0.00194959      0.856782           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7208.51   0.000442984       0.11388           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-30\n",
      "Initial log joint probability = -30548\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7212.28     0.0237379       4.33874           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7212.28   0.000116599      0.136234      0.4583           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-02\n",
      "Initial log joint probability = -24268.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7212.88   0.000275017       1.11934      0.4798      0.4798       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7212.88    0.00016162      0.124948           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-03\n",
      "Initial log joint probability = -23313.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7219.19   0.000197351      0.156017           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7219.19   0.000133174     0.0917957           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-06\n",
      "Initial log joint probability = -25201.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7222.55     0.0019828       1.80175      0.5086      0.5086       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7222.55   0.000581656     0.0848773           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-09\n",
      "Initial log joint probability = -24976.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7228.35   0.000221037      0.134625           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-10\n",
      "Initial log joint probability = -35813.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7239.19     0.0106641       3.37087           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7239.19   0.000314307      0.199531           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-13\n",
      "Initial log joint probability = -29179.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7241.49   0.000818715      0.778046      0.7903      0.7903       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7241.49   0.000167061     0.0629628           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-16\n",
      "Initial log joint probability = -22459\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7243.97    0.00178642       1.81736      0.8556      0.8556       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7243.97    0.00026781      0.210489           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-17\n",
      "Initial log joint probability = -23082.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7258.08    0.00163809       1.24363           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7258.08   0.000421338      0.167296      0.8026      0.8026       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-20\n",
      "Initial log joint probability = -25124\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7260.44    0.00039246      0.393078      0.5965      0.5965       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7260.44    0.00025272     0.0512284           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-23\n",
      "Initial log joint probability = -31189.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7273.8    0.00195345       1.04622           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -7273.8   8.46159e-05     0.0951028      0.4191       0.965       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-27\n",
      "Initial log joint probability = -29810.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7275.28    0.00341104       1.35134           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7275.28   0.000233549     0.0522804      0.9401      0.9401       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-28\n",
      "Initial log joint probability = -30070.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7279.43    0.00776238       2.03392           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7279.43   0.000110404      0.110833      0.9705      0.9705       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-29\n",
      "Initial log joint probability = -23643.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7281.55   0.000500896        1.0253      0.5554      0.5554       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7281.55   0.000412695      0.112349           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-30\n",
      "Initial log joint probability = -28068.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7285.88   0.000506764       1.32959      0.5792      0.5792       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7285.88   0.000337166     0.0942164      0.9803      0.9803       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-01\n",
      "Initial log joint probability = -24721\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7299.38    0.00452647      0.574621           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7299.38   0.000336637     0.0879563           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-07\n",
      "Initial log joint probability = -24587.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7301.57   0.000238453      0.568904      0.7829      0.7829       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7301.57   0.000140694      0.133268           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-08\n",
      "Initial log joint probability = -25201.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7301.68    0.00327583      0.732747           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7301.68   5.16508e-05     0.0345079      0.3654      0.9989       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-12\n",
      "Initial log joint probability = -30344.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7303.3     0.0122937       4.83763           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7303.29   9.50381e-05     0.0961007      0.6684      0.6684       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-14\n",
      "Initial log joint probability = -37255.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7310.14     0.0061766       3.65871           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7310.14   0.000118608     0.0373661           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-15\n",
      "Initial log joint probability = -26301.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7315.36   0.000129121      0.234299       0.913       0.913       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7315.36   0.000121928     0.0769807           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-19\n",
      "Initial log joint probability = -24584.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7315.82    0.00167154      0.557978           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7315.82   0.000884641      0.149264           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-20\n",
      "Initial log joint probability = -25810.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7318.1     0.0022133      0.469355           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -7318.1   6.02818e-05      0.145525       0.702       0.702       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-21\n",
      "Initial log joint probability = -26625\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7322.69    0.00125955      0.552235           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7322.69   7.48359e-05      0.212373      0.5441      0.5441       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-22\n",
      "Initial log joint probability = -31177\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7328.61   0.000370944      0.349812           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7328.61   0.000629984       0.15266           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-23\n",
      "Initial log joint probability = -31173.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7331.79    0.00170972       1.01045           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7331.79   4.91456e-05      0.122272      0.6358      0.6358       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-28\n",
      "Initial log joint probability = -30778.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -7332    0.00295358       10.1361      0.5709      0.5709       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7331.99   9.14967e-05     0.0907151      0.5035           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-29\n",
      "Initial log joint probability = -30978.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7346.3    0.00400056       4.06592      0.7556      0.7556       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23       -7346.3    9.0005e-05      0.125928       0.476           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-03\n",
      "Initial log joint probability = -31214.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7346.77    0.00930225       2.18822           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7346.77   0.000480804     0.0636676           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-04\n",
      "Initial log joint probability = -28079\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7352.9    0.00196211       4.79093      0.6231      0.6231       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7352.89    0.00108349      0.267229      0.9882      0.9882       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-05\n",
      "Initial log joint probability = -22430.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7357.02     0.0112878       1.01689      0.8966      0.8966       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7357.02   0.000134992      0.113017           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-10\n",
      "Initial log joint probability = -23218.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7358.32   0.000847156       2.80045      0.6159      0.6159       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7358.32   0.000178527     0.0536929           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-12\n",
      "Initial log joint probability = -23773.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7374.89    0.00254725       1.97225           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7374.89   0.000322554      0.225597      0.7616      0.7616       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-16\n",
      "Initial log joint probability = -23372.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7379.42    0.00031258      0.615467       0.609       0.609       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7379.42   0.000193329     0.0441374           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-17\n",
      "Initial log joint probability = -25822.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7379.61    0.00522238       1.88018           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7379.61   0.000221552     0.0611404           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-18\n",
      "Initial log joint probability = -29673.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7389.73    0.00189135      0.104966       0.908       0.908       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-19\n",
      "Initial log joint probability = -30215.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      14      -7397.96   0.000182358     0.0822061           1           1       15   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-20\n",
      "Initial log joint probability = -24128.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7400.56    0.00463847       1.36609           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7400.56    0.00102953     0.0748917      0.9474      0.9474       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-25\n",
      "Initial log joint probability = -25393.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7407.53    0.00123533      0.448505           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7407.53   6.43998e-05      0.224457      0.4951      0.4951       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-26\n",
      "Initial log joint probability = -29589.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7407.63    0.00161791       1.00271           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7407.63   0.000729034      0.163922           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-03\n",
      "Initial log joint probability = -28929.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7418.51    0.00275955      0.728852      0.9434      0.9434       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7418.51   0.000539789      0.170673           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-08\n",
      "Initial log joint probability = -34205.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7419.67   0.000432465      0.794739           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7419.67   0.000134826      0.115669      0.3339      0.8981       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-09\n",
      "Initial log joint probability = -25422\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7432.81    0.00984442       1.10886           1           1       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7432.81    5.6881e-05     0.0594155      0.4539      0.9426       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-10\n",
      "Initial log joint probability = -27481.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7438.55    0.00293529      0.701951           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7438.55   4.97239e-05     0.0573491      0.4349      0.9042       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-12\n",
      "Initial log joint probability = -29563.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7438.71    0.00383278      0.862361           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7438.71   0.000101737      0.195296      0.5418      0.5418       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-17\n",
      "Initial log joint probability = -25416.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7449.52     0.0344464       8.75168           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7449.51    0.00026939      0.183088      0.8813      0.8813       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-18\n",
      "Initial log joint probability = -25585.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7449.72    0.00104636      0.375133      0.9097      0.9097       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7449.72   0.000310282       0.11182      0.7426      0.7426       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-31\n",
      "Initial log joint probability = -36185.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7456.79     0.0948887       4.02695           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7456.78   0.000730767      0.103511      0.9368      0.9368       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-06\n",
      "Initial log joint probability = -27585.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -7458    0.00273126       4.99426      0.5392      0.5392       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7457.99   0.000643061     0.0659779           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-13\n",
      "Initial log joint probability = -29110\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7461.42    0.00276539       1.68097           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7461.42   0.000214914     0.0752509           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-14\n",
      "Initial log joint probability = -28160.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7467.56    0.00102272       1.15842      0.9636      0.9636       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7467.56   0.000130856       0.07624           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-18\n",
      "Initial log joint probability = -28068.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7470.56    0.00905865        4.9129           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7470.56   0.000274198      0.173083           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-20\n",
      "Initial log joint probability = -27035.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7470.8    0.00151387      0.319451           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20       -7470.8   0.000198182       0.10067           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-21\n",
      "Initial log joint probability = -27774.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7481.2    0.00225823       2.42705      0.9042      0.9042       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -7481.2   0.000791689     0.0871672           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-27\n",
      "Initial log joint probability = -24826.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7484.8     0.0150689       4.27306           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7484.79   0.000270926      0.143576           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-28\n",
      "Initial log joint probability = -28635.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7486.54    0.00438068       1.98587           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7486.54    0.00017794      0.111331           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-03\n",
      "Initial log joint probability = -26841.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7486.63    0.00107433      0.916049           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7486.63   8.83566e-05     0.0890906      0.4471      0.9184       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-04\n",
      "Initial log joint probability = -28318.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7501.93    0.00341374       2.06948      0.3837      0.3837       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7501.93   0.000242614      0.190122           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-10\n",
      "Initial log joint probability = -27349.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7502.57   0.000810832      0.683547           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7502.57   0.000424836      0.149035           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-11\n",
      "Initial log joint probability = -40603.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7505.02      0.011248       3.45147           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7505.02   0.000247464       0.19018       0.752       0.752       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-17\n",
      "Initial log joint probability = -26448.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7510.97    0.00529765       3.00212           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7510.97   0.000799188      0.139708      0.8939      0.8939       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-18\n",
      "Initial log joint probability = -31047.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7516.69     0.0184956       2.42768           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7516.69   0.000226865     0.0181253           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-24\n",
      "Initial log joint probability = -31344.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7521.37    0.00202646       1.95379           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7521.37   0.000192945      0.117412           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-25\n",
      "Initial log joint probability = -27718.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7536.39   0.000666917      0.625882           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7536.39   4.85844e-05     0.0438856      0.4087      0.9759       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-03\n",
      "Initial log joint probability = -22909.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7539.49   0.000586367      0.591037           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7539.49   0.000286265      0.174476           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-04\n",
      "Initial log joint probability = -36596.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7546.61     0.0002623      0.243188           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7546.61   0.000160726     0.0816083           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-10\n",
      "Initial log joint probability = -31890.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7554.68     0.0852491       5.77769           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7554.67   7.59647e-05     0.0528191      0.8858      0.8858       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-11\n",
      "Initial log joint probability = -25555.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7564.7     0.0018739      0.420626           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -7564.7   0.000164414     0.0838515           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-15\n",
      "Initial log joint probability = -27189.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7567.78    0.00107441      0.514364           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7567.78   0.000394191      0.126953           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-17\n",
      "Initial log joint probability = -26063.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7572.2    0.00282638      0.758849           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -7572.2   0.000637942     0.0954079      0.8605      0.8605       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-18\n",
      "Initial log joint probability = -24037.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7582.33      0.001586       2.36989           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7582.33   0.000269946      0.216837           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-24\n",
      "Initial log joint probability = -28197.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7591.89    0.00385475      0.803621           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7591.89   0.000153746      0.117311      0.7447      0.7447       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-25\n",
      "Initial log joint probability = -29975.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7601.18    0.00120016      0.470078           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7601.18   0.000121099     0.0980308      0.9058      0.9058       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-31\n",
      "Initial log joint probability = -32225.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -7613    0.00554039        2.1214           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22         -7613    0.00028657      0.103536           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-04-01\n",
      "Initial log joint probability = -31194.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7619.88     0.0037356       1.26654           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7619.88   0.000432799      0.111971           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-04-07\n",
      "Initial log joint probability = -24630.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7625.73    0.00348363       1.98051           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7625.73   0.000494969      0.189247           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-04-08\n",
      "Initial log joint probability = -26582.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7633.64    0.00311683       1.20475           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7633.64   5.10123e-05      0.038135      0.2985           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "from model_selection.cross_val_pipeline import TimeSeriesCrossVal\n",
    "\n",
    "tscv = TimeSeriesCrossVal(min_test_date=pd.to_datetime(\"2021-01-01\"), \n",
    "                          n_dates_per_fold=1, \n",
    "                          p_fighter_implied_col=p_fighter_implied_col)\n",
    "preds_df = tscv.get_cross_val_preds(\n",
    "    mod, \n",
    "    feat_ml_df.dropna(subset=[\n",
    "        *feat_cols, \"win_target\", p_fighter_implied_col,\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:      0.6872931833223032\n",
      "Moneyline accuracy:  0.6671078755790867\n"
     ]
    }
   ],
   "source": [
    "mod_pred = preds_df[\"y_pred\"].round()\n",
    "ml_pred = preds_df[p_fighter_implied_col].round()\n",
    "print(\"Model accuracy:     \", (mod_pred == preds_df[\"win_target\"]).mean())\n",
    "print(\"Moneyline accuracy: \", (ml_pred == preds_df[\"win_target\"]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model log loss    : 0.5842127950970498\n",
      "Moneyline log loss: 0.6093059101142347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "xce = log_loss(y_true=preds_df[\"win_target\"], y_pred=preds_df[\"y_pred\"])\n",
    "xce_ml = log_loss(y_true=preds_df[\"win_target\"], y_pred=preds_df[p_fighter_implied_col])\n",
    "\n",
    "print(f\"model log loss    : {xce}\")\n",
    "print(f\"Moneyline log loss: {xce_ml}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pred_elo_PC_0', 0.1269276657442376),\n",
       " ('pred_elo_PC_1', -0.0060779356340361764),\n",
       " ('pred_elo_PC_2', 0.011396100675195442),\n",
       " ('pred_elo_PC_3', 0.014741346710217623),\n",
       " ('pred_elo_PC_4', 0.026884834619379475),\n",
       " ('pred_elo_PC_5', -0.01686114268373371),\n",
       " ('pred_elo_PC_6', 0.015741835399085725),\n",
       " ('pred_elo_PC_7', -0.027053962689694015),\n",
       " ('pred_elo_PC_8', 0.0032869915426520574),\n",
       " ('pred_elo_PC_9', 0.01832624650175581),\n",
       " ('pred_elo_PC_10', 0.019744290474764985),\n",
       " ('pred_elo_PC_11', -0.011536334311571061),\n",
       " ('pred_elo_PC_12', -0.014025429396221),\n",
       " ('pred_elo_PC_13', 0.04503660514625441),\n",
       " ('pred_elo_signed_inverse_fight_time', -0.06808258223329923),\n",
       " ('pred_elo_win_target', 0.41005977844272135),\n",
       " ('pred_elo_win_target_finish', -0.40541751884452154),\n",
       " ('age_diff', 0.24531001387040274),\n",
       " ('log_reach_diff', 0.04894448398653868),\n",
       " ('weight_diff', 0.009503161351021834),\n",
       " ('height_diff', 0.02505917614708333),\n",
       " ('log_t_since_prev_fight_diff', -0.16908633222917077),\n",
       " ('log_t_since_first_fight_diff', 0.23753290770026536),\n",
       " ('total_fights_diff', 0.0004177492943652384),\n",
       " ('usa_diff', -0.04651886194922355),\n",
       " ('russia_diff', 0.07060077730907126),\n",
       " ('stance_diff', 0.07584423764441922)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(mod.feat_cols, mod.fit['beta']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"week\"] = preds_df[\"Date\"].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_ml_col = \"FighterOpen\"\n",
    "opponent_ml_col = \"OpponentOpen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall winnings\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ufc winnings\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-ufc winnings\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model_selection.metrics import MultiKellyPM\n",
    "\n",
    "kwargs = {\n",
    "    \"max_bankroll_fraction\": 0.05,\n",
    "    \"groupby_col\": \"week\",\n",
    "    \"fighter_ml_col\": fighter_ml_col,\n",
    "    \"opponent_ml_col\": opponent_ml_col,\n",
    "}\n",
    "\n",
    "print(\"overall winnings\")\n",
    "pm = MultiKellyPM(preds_df, **kwargs)\n",
    "event_return_df = pm.get_all_returns()\n",
    "pm.plot_diagnostics(event_return_df, x_col=\"week\")\n",
    "\n",
    "print(\"ufc winnings\")\n",
    "pm = MultiKellyPM(preds_df.query(\"is_ufc == 1\"), **kwargs)\n",
    "event_return_df = pm.get_all_returns()\n",
    "pm.plot_diagnostics(event_return_df, x_col=\"week\")\n",
    "\n",
    "print(\"non-ufc winnings\")\n",
    "pm = MultiKellyPM(preds_df.query(\"is_ufc == 0\"), **kwargs)\n",
    "event_return_df = pm.get_all_returns()\n",
    "pm.plot_diagnostics(event_return_df, x_col=\"week\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation - BetMGM, DraftKings, BetFair\n",
    "\n",
    "I think something's fishy here, this can't be right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16250, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "match_id               0.000000\n",
       "EventHref              0.000000\n",
       "DraftKings_fighter     0.765046\n",
       "BetMGM_fighter         0.792862\n",
       "Caesars_fighter        0.786954\n",
       "BetRivers_fighter      0.863877\n",
       "FanDuel_fighter        0.764554\n",
       "PointsBet_fighter      0.904000\n",
       "Unibet_fighter         0.813908\n",
       "BetWay_fighter         0.658954\n",
       "5D_fighter             0.086154\n",
       "Ref_fighter            0.018338\n",
       "FighterID_bfo          0.000000\n",
       "Bet365_fighter         0.902031\n",
       "DraftKings_opponent    0.765046\n",
       "BetMGM_opponent        0.792862\n",
       "Caesars_opponent       0.786954\n",
       "BetRivers_opponent     0.863877\n",
       "FanDuel_opponent       0.764554\n",
       "PointsBet_opponent     0.904000\n",
       "Unibet_opponent        0.813908\n",
       "BetWay_opponent        0.658954\n",
       "5D_opponent            0.086154\n",
       "Ref_opponent           0.018338\n",
       "OpponentID_bfo         0.000000\n",
       "Bet365_opponent        0.902031\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_df = base_db_interface.read(\"clean_bfo_close_data\")\n",
    "# double the data\n",
    "fighter_cols = [c for c in close_df.columns if c.endswith(\"_fighter\")]\n",
    "opponent_cols = [c[:-len(\"_fighter\")] + \"_opponent\" for c in fighter_cols]\n",
    "for col in fighter_cols + opponent_cols:\n",
    "    close_df[col] = close_df[col].str.replace(\"▲\", \"\")\\\n",
    "        .str.replace(\"▼\", \"\")\\\n",
    "        .astype(float)\n",
    "    \n",
    "close_df_complement = close_df.rename(columns={\n",
    "    \"FighterID\": \"OpponentID\",\n",
    "    \"OpponentID\": \"FighterID\",\n",
    "    **{f: o for f, o in zip(fighter_cols, opponent_cols)},\n",
    "    **{o: f for f, o in zip(fighter_cols, opponent_cols)},\n",
    "})\n",
    "close_df = pd.concat([close_df, close_df_complement], axis=0)\\\n",
    "    .drop_duplicates(subset=[\"FighterID\", \"OpponentID\", \"EventHref\"])\\\n",
    "    .dropna(subset=[\"FighterID\", \"OpponentID\", \"EventHref\"])\\\n",
    "    .rename(columns={\"FighterID\": \"FighterID_bfo\", \"OpponentID\": \"OpponentID_bfo\"})\\\n",
    "    .drop(columns=[\"FighterName\", \"OpponentName\"])\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "print(close_df.shape)\n",
    "close_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122872            Calvin-Kattar-717\n",
       "122873                Wu-Yanan-8993\n",
       "122874             Justin-Tafa-9315\n",
       "122875           Jacob-Kilburn-8472\n",
       "122876           Ramazan-Emeev-7452\n",
       "                    ...            \n",
       "132966    Christian-Rodriquez-15110\n",
       "132967      Gerald-Meerschaert-3628\n",
       "132971        Cynthia-Calvillo-6940\n",
       "132980       Magomed-Umalatov-11254\n",
       "132981            David-Zawada-5347\n",
       "Name: FighterID_bfo, Length: 3022, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df[\"FighterID_bfo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fight_id_legacy    0.000000\n",
       "Date               0.000000\n",
       "FighterResult      0.000000\n",
       "Decision           0.000000\n",
       "Rnd                0.000000\n",
       "                     ...   \n",
       "Unibet_opponent    0.573461\n",
       "BetWay_opponent    0.269689\n",
       "5D_opponent        0.425215\n",
       "Ref_opponent       0.271013\n",
       "Bet365_opponent    0.795169\n",
       "Length: 413, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_preds_df = preds_df.merge(\n",
    "    close_df,\n",
    "    how=\"left\",\n",
    "    on=[\"FighterID_bfo\", \"OpponentID_bfo\", \"EventHref\"],\n",
    ")\n",
    "aug_preds_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DraftKings_fighter</th>\n",
       "      <th>BetMGM_fighter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16245</th>\n",
       "      <td>-365.0</td>\n",
       "      <td>-450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16246</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16247</th>\n",
       "      <td>-435.0</td>\n",
       "      <td>-450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16248</th>\n",
       "      <td>575.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16249</th>\n",
       "      <td>-900.0</td>\n",
       "      <td>-1200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DraftKings_fighter  BetMGM_fighter\n",
       "0                     NaN             NaN\n",
       "1                     NaN             NaN\n",
       "2                     NaN             NaN\n",
       "3                     NaN             NaN\n",
       "4                     NaN             NaN\n",
       "...                   ...             ...\n",
       "16245              -365.0          -450.0\n",
       "16246                 NaN          -450.0\n",
       "16247              -435.0          -450.0\n",
       "16248               575.0           600.0\n",
       "16249              -900.0         -1200.0\n",
       "\n",
       "[16250 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_df[[\"DraftKings_fighter\", \"BetMGM_fighter\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122872    115.0\n",
       "122873   -240.0\n",
       "122874   -105.0\n",
       "122875    225.0\n",
       "122876   -210.0\n",
       "          ...  \n",
       "132966    210.0\n",
       "132967    250.0\n",
       "132971    275.0\n",
       "132980   -900.0\n",
       "132981    125.0\n",
       "Name: FighterOpen, Length: 3022, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df[fighter_ml_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall winnings\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ufc winnings\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-ufc winnings\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "market = \"DraftKings\"\n",
    "# market = \"BetMGM\"\n",
    "\n",
    "kwargs = {\n",
    "    \"max_bankroll_fraction\": 1,\n",
    "    \"groupby_col\": \"week\",\n",
    "    \"fighter_ml_col\": f\"{market}_fighter\",\n",
    "    \"opponent_ml_col\": f\"{market}_opponent\",\n",
    "}\n",
    "\n",
    "temp_preds_df = aug_preds_df.dropna(subset=[\n",
    "    f\"{market}_fighter\", f\"{market}_opponent\"\n",
    "])\n",
    "temp_preds_df\n",
    "\n",
    "print(\"overall winnings\")\n",
    "pm = MultiKellyPM(temp_preds_df, **kwargs)\n",
    "event_return_df = pm.get_all_returns()\n",
    "pm.plot_diagnostics(event_return_df, x_col=\"week\")\n",
    "\n",
    "print(\"ufc winnings\")\n",
    "pm = MultiKellyPM(temp_preds_df.query(\"is_ufc == 1\"), **kwargs)\n",
    "event_return_df = pm.get_all_returns()\n",
    "pm.plot_diagnostics(event_return_df, x_col=\"week\")\n",
    "\n",
    "print(\"non-ufc winnings\")\n",
    "pm = MultiKellyPM(temp_preds_df.query(\"is_ufc == 0\"), **kwargs)\n",
    "event_return_df = pm.get_all_returns()\n",
    "pm.plot_diagnostics(event_return_df, x_col=\"week\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for upcoming fights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>pred_elo_PC_0</th>\n",
       "      <th>pred_elo_PC_1</th>\n",
       "      <th>pred_elo_PC_2</th>\n",
       "      <th>pred_elo_PC_3</th>\n",
       "      <th>pred_elo_PC_4</th>\n",
       "      <th>pred_elo_PC_5</th>\n",
       "      <th>pred_elo_PC_6</th>\n",
       "      <th>pred_elo_PC_7</th>\n",
       "      <th>...</th>\n",
       "      <th>age_diff</th>\n",
       "      <th>log_reach_diff</th>\n",
       "      <th>weight_diff</th>\n",
       "      <th>height_diff</th>\n",
       "      <th>log_t_since_prev_fight_diff</th>\n",
       "      <th>log_t_since_first_fight_diff</th>\n",
       "      <th>total_fights_diff</th>\n",
       "      <th>usa_diff</th>\n",
       "      <th>russia_diff</th>\n",
       "      <th>stance_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132984</th>\n",
       "      <td>4863327</td>\n",
       "      <td>3949555</td>\n",
       "      <td>-0.195705</td>\n",
       "      <td>-0.249167</td>\n",
       "      <td>-0.068994</td>\n",
       "      <td>0.682357</td>\n",
       "      <td>0.265850</td>\n",
       "      <td>0.332739</td>\n",
       "      <td>-0.606089</td>\n",
       "      <td>0.157302</td>\n",
       "      <td>...</td>\n",
       "      <td>7.317808</td>\n",
       "      <td>0.081126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.528675</td>\n",
       "      <td>-0.510659</td>\n",
       "      <td>-7</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132985</th>\n",
       "      <td>4397782</td>\n",
       "      <td>4040197</td>\n",
       "      <td>0.112259</td>\n",
       "      <td>0.714654</td>\n",
       "      <td>0.967333</td>\n",
       "      <td>-1.279557</td>\n",
       "      <td>0.390686</td>\n",
       "      <td>-0.224637</td>\n",
       "      <td>0.238147</td>\n",
       "      <td>0.725284</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295890</td>\n",
       "      <td>0.036368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084218</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132986</th>\n",
       "      <td>4232775</td>\n",
       "      <td>3994033</td>\n",
       "      <td>0.202585</td>\n",
       "      <td>0.976380</td>\n",
       "      <td>0.029361</td>\n",
       "      <td>-1.416281</td>\n",
       "      <td>-0.196303</td>\n",
       "      <td>-0.420252</td>\n",
       "      <td>0.437974</td>\n",
       "      <td>-0.305062</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.369863</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.354646</td>\n",
       "      <td>-0.046496</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132987</th>\n",
       "      <td>4076472</td>\n",
       "      <td>4063667</td>\n",
       "      <td>0.210980</td>\n",
       "      <td>0.391183</td>\n",
       "      <td>-0.089732</td>\n",
       "      <td>-0.591662</td>\n",
       "      <td>-0.648010</td>\n",
       "      <td>0.036722</td>\n",
       "      <td>0.744049</td>\n",
       "      <td>-0.196450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.950685</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.507671</td>\n",
       "      <td>0.142094</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132988</th>\n",
       "      <td>3045734</td>\n",
       "      <td>3961293</td>\n",
       "      <td>-0.381281</td>\n",
       "      <td>-0.505066</td>\n",
       "      <td>0.555358</td>\n",
       "      <td>0.363368</td>\n",
       "      <td>0.224523</td>\n",
       "      <td>0.700904</td>\n",
       "      <td>0.680059</td>\n",
       "      <td>-0.225259</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.624658</td>\n",
       "      <td>-0.030305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.619535</td>\n",
       "      <td>0.358149</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132989</th>\n",
       "      <td>2335674</td>\n",
       "      <td>4690549</td>\n",
       "      <td>0.285680</td>\n",
       "      <td>-0.398737</td>\n",
       "      <td>0.437694</td>\n",
       "      <td>-1.458451</td>\n",
       "      <td>-0.138322</td>\n",
       "      <td>0.162732</td>\n",
       "      <td>-0.757358</td>\n",
       "      <td>-0.317639</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.665753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110348</td>\n",
       "      <td>0.809855</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132991</th>\n",
       "      <td>2594871</td>\n",
       "      <td>4227265</td>\n",
       "      <td>-0.194510</td>\n",
       "      <td>0.650643</td>\n",
       "      <td>-0.265063</td>\n",
       "      <td>-0.548014</td>\n",
       "      <td>0.247813</td>\n",
       "      <td>0.141773</td>\n",
       "      <td>0.096254</td>\n",
       "      <td>-1.325625</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.021918</td>\n",
       "      <td>0.061036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.375433</td>\n",
       "      <td>-0.061522</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132993</th>\n",
       "      <td>3900088</td>\n",
       "      <td>2526299</td>\n",
       "      <td>0.345742</td>\n",
       "      <td>0.411075</td>\n",
       "      <td>-0.050783</td>\n",
       "      <td>0.761484</td>\n",
       "      <td>-0.134104</td>\n",
       "      <td>-1.021289</td>\n",
       "      <td>-1.008232</td>\n",
       "      <td>0.382047</td>\n",
       "      <td>...</td>\n",
       "      <td>2.882192</td>\n",
       "      <td>-0.068993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.164626</td>\n",
       "      <td>-0.320020</td>\n",
       "      <td>-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132996</th>\n",
       "      <td>3902098</td>\n",
       "      <td>2614933</td>\n",
       "      <td>-0.981286</td>\n",
       "      <td>-0.950759</td>\n",
       "      <td>-0.842446</td>\n",
       "      <td>0.633129</td>\n",
       "      <td>-0.954096</td>\n",
       "      <td>-0.628756</td>\n",
       "      <td>0.892606</td>\n",
       "      <td>-0.476728</td>\n",
       "      <td>...</td>\n",
       "      <td>2.136986</td>\n",
       "      <td>0.014389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.533062</td>\n",
       "      <td>-0.133283</td>\n",
       "      <td>-10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132997</th>\n",
       "      <td>4394200</td>\n",
       "      <td>4963343</td>\n",
       "      <td>0.321315</td>\n",
       "      <td>0.165845</td>\n",
       "      <td>-0.302548</td>\n",
       "      <td>0.084098</td>\n",
       "      <td>0.106047</td>\n",
       "      <td>0.583619</td>\n",
       "      <td>-0.376468</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.315068</td>\n",
       "      <td>0.038915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.018780</td>\n",
       "      <td>0.409856</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132999</th>\n",
       "      <td>4089026</td>\n",
       "      <td>4816066</td>\n",
       "      <td>-1.073514</td>\n",
       "      <td>-0.620703</td>\n",
       "      <td>0.211283</td>\n",
       "      <td>-0.816519</td>\n",
       "      <td>0.877023</td>\n",
       "      <td>-0.425521</td>\n",
       "      <td>0.448058</td>\n",
       "      <td>0.218753</td>\n",
       "      <td>...</td>\n",
       "      <td>2.512329</td>\n",
       "      <td>-0.007905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.142372</td>\n",
       "      <td>0.183711</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133003</th>\n",
       "      <td>4239928</td>\n",
       "      <td>3020090</td>\n",
       "      <td>0.088705</td>\n",
       "      <td>0.837004</td>\n",
       "      <td>-0.081885</td>\n",
       "      <td>0.039529</td>\n",
       "      <td>-0.063510</td>\n",
       "      <td>-0.524971</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>-0.584603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391781</td>\n",
       "      <td>0.029853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.942802</td>\n",
       "      <td>-0.174199</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133004</th>\n",
       "      <td>2512055</td>\n",
       "      <td>2335754</td>\n",
       "      <td>0.532863</td>\n",
       "      <td>0.326385</td>\n",
       "      <td>0.068641</td>\n",
       "      <td>-0.647781</td>\n",
       "      <td>-0.200518</td>\n",
       "      <td>-0.350859</td>\n",
       "      <td>0.444590</td>\n",
       "      <td>-0.384626</td>\n",
       "      <td>...</td>\n",
       "      <td>3.835616</td>\n",
       "      <td>-0.026317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.442064</td>\n",
       "      <td>-0.259292</td>\n",
       "      <td>-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133010</th>\n",
       "      <td>4418784</td>\n",
       "      <td>4292349</td>\n",
       "      <td>-0.058534</td>\n",
       "      <td>0.294277</td>\n",
       "      <td>-0.205873</td>\n",
       "      <td>0.369073</td>\n",
       "      <td>1.105809</td>\n",
       "      <td>0.260411</td>\n",
       "      <td>0.249523</td>\n",
       "      <td>0.678917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206614</td>\n",
       "      <td>-0.514944</td>\n",
       "      <td>-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133011</th>\n",
       "      <td>3151289</td>\n",
       "      <td>3922491</td>\n",
       "      <td>-0.599303</td>\n",
       "      <td>1.475839</td>\n",
       "      <td>-0.967742</td>\n",
       "      <td>0.014702</td>\n",
       "      <td>0.082234</td>\n",
       "      <td>0.185902</td>\n",
       "      <td>-0.429443</td>\n",
       "      <td>0.737151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.253860</td>\n",
       "      <td>0.069939</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133012</th>\n",
       "      <td>2504643</td>\n",
       "      <td>4333158</td>\n",
       "      <td>0.096802</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>-0.012390</td>\n",
       "      <td>-0.223778</td>\n",
       "      <td>-0.185530</td>\n",
       "      <td>0.124228</td>\n",
       "      <td>-0.563981</td>\n",
       "      <td>-0.172217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153586</td>\n",
       "      <td>0.205259</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133013</th>\n",
       "      <td>3970873</td>\n",
       "      <td>4688408</td>\n",
       "      <td>0.064634</td>\n",
       "      <td>-0.146394</td>\n",
       "      <td>-0.327473</td>\n",
       "      <td>-0.314480</td>\n",
       "      <td>0.571793</td>\n",
       "      <td>-0.969727</td>\n",
       "      <td>-0.644147</td>\n",
       "      <td>-0.022577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889154</td>\n",
       "      <td>0.555333</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133014</th>\n",
       "      <td>5060394</td>\n",
       "      <td>4324623</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>-0.173635</td>\n",
       "      <td>-0.246236</td>\n",
       "      <td>0.611450</td>\n",
       "      <td>0.029376</td>\n",
       "      <td>-0.293469</td>\n",
       "      <td>-0.144704</td>\n",
       "      <td>0.112844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.497977</td>\n",
       "      <td>-0.736978</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133016</th>\n",
       "      <td>3922557</td>\n",
       "      <td>4217395</td>\n",
       "      <td>0.811043</td>\n",
       "      <td>-0.521314</td>\n",
       "      <td>0.688678</td>\n",
       "      <td>-0.772041</td>\n",
       "      <td>-0.924842</td>\n",
       "      <td>0.167326</td>\n",
       "      <td>0.041051</td>\n",
       "      <td>-0.088420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664368</td>\n",
       "      <td>0.064518</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133017</th>\n",
       "      <td>3309918</td>\n",
       "      <td>4277049</td>\n",
       "      <td>0.266692</td>\n",
       "      <td>-0.070910</td>\n",
       "      <td>-0.008271</td>\n",
       "      <td>0.098454</td>\n",
       "      <td>1.143072</td>\n",
       "      <td>-0.191985</td>\n",
       "      <td>0.049392</td>\n",
       "      <td>-0.488933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244263</td>\n",
       "      <td>0.361569</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133019</th>\n",
       "      <td>3894823</td>\n",
       "      <td>2502364</td>\n",
       "      <td>0.130970</td>\n",
       "      <td>-0.318741</td>\n",
       "      <td>0.264974</td>\n",
       "      <td>-0.204758</td>\n",
       "      <td>-0.554714</td>\n",
       "      <td>0.351630</td>\n",
       "      <td>1.418354</td>\n",
       "      <td>-0.401714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053653</td>\n",
       "      <td>-0.222785</td>\n",
       "      <td>-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133020</th>\n",
       "      <td>4339130</td>\n",
       "      <td>2503659</td>\n",
       "      <td>0.593418</td>\n",
       "      <td>0.810061</td>\n",
       "      <td>-1.324708</td>\n",
       "      <td>1.662906</td>\n",
       "      <td>-1.107296</td>\n",
       "      <td>0.308445</td>\n",
       "      <td>-0.269646</td>\n",
       "      <td>0.517220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.164308</td>\n",
       "      <td>-1.262711</td>\n",
       "      <td>-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133021</th>\n",
       "      <td>3089069</td>\n",
       "      <td>3030256</td>\n",
       "      <td>-0.657081</td>\n",
       "      <td>-0.592595</td>\n",
       "      <td>-0.228173</td>\n",
       "      <td>0.164238</td>\n",
       "      <td>0.157888</td>\n",
       "      <td>-0.295335</td>\n",
       "      <td>-1.117541</td>\n",
       "      <td>0.123758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.594022</td>\n",
       "      <td>-0.262904</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133022</th>\n",
       "      <td>4024488</td>\n",
       "      <td>5080935</td>\n",
       "      <td>-0.163086</td>\n",
       "      <td>0.291715</td>\n",
       "      <td>0.040737</td>\n",
       "      <td>-0.177596</td>\n",
       "      <td>-0.124726</td>\n",
       "      <td>-0.038337</td>\n",
       "      <td>0.315883</td>\n",
       "      <td>-0.280897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027292</td>\n",
       "      <td>0.355801</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133025</th>\n",
       "      <td>4815974</td>\n",
       "      <td>4389093</td>\n",
       "      <td>-0.657956</td>\n",
       "      <td>-0.746681</td>\n",
       "      <td>0.398674</td>\n",
       "      <td>0.335451</td>\n",
       "      <td>-0.073774</td>\n",
       "      <td>0.162743</td>\n",
       "      <td>0.178847</td>\n",
       "      <td>0.537192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712317</td>\n",
       "      <td>-0.901612</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133034</th>\n",
       "      <td>4375156</td>\n",
       "      <td>4686725</td>\n",
       "      <td>-0.019820</td>\n",
       "      <td>0.556889</td>\n",
       "      <td>0.191263</td>\n",
       "      <td>0.706798</td>\n",
       "      <td>-0.076375</td>\n",
       "      <td>0.164163</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.554404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.050603</td>\n",
       "      <td>-0.027378</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133035</th>\n",
       "      <td>4835137</td>\n",
       "      <td>4012999</td>\n",
       "      <td>-0.243549</td>\n",
       "      <td>0.132756</td>\n",
       "      <td>0.828913</td>\n",
       "      <td>0.262290</td>\n",
       "      <td>1.633730</td>\n",
       "      <td>-0.290362</td>\n",
       "      <td>0.412471</td>\n",
       "      <td>-0.497415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349184</td>\n",
       "      <td>-0.104183</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133036</th>\n",
       "      <td>2558075</td>\n",
       "      <td>4903365</td>\n",
       "      <td>0.147911</td>\n",
       "      <td>0.056638</td>\n",
       "      <td>0.130269</td>\n",
       "      <td>-1.129835</td>\n",
       "      <td>-0.065689</td>\n",
       "      <td>0.484352</td>\n",
       "      <td>0.012530</td>\n",
       "      <td>0.163817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121890</td>\n",
       "      <td>1.049269</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133037</th>\n",
       "      <td>4251462</td>\n",
       "      <td>2517186</td>\n",
       "      <td>0.165704</td>\n",
       "      <td>0.569984</td>\n",
       "      <td>-0.608713</td>\n",
       "      <td>-0.955094</td>\n",
       "      <td>0.774204</td>\n",
       "      <td>-0.695898</td>\n",
       "      <td>0.266996</td>\n",
       "      <td>0.132750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.835501</td>\n",
       "      <td>-0.461602</td>\n",
       "      <td>-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133039</th>\n",
       "      <td>4914568</td>\n",
       "      <td>4702563</td>\n",
       "      <td>0.219062</td>\n",
       "      <td>0.759179</td>\n",
       "      <td>-0.001518</td>\n",
       "      <td>0.400720</td>\n",
       "      <td>-0.156865</td>\n",
       "      <td>0.096837</td>\n",
       "      <td>0.471451</td>\n",
       "      <td>-0.102770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285991</td>\n",
       "      <td>-0.706106</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133040</th>\n",
       "      <td>4227055</td>\n",
       "      <td>4034272</td>\n",
       "      <td>0.457317</td>\n",
       "      <td>0.834310</td>\n",
       "      <td>-0.451403</td>\n",
       "      <td>0.590604</td>\n",
       "      <td>0.782637</td>\n",
       "      <td>-0.339107</td>\n",
       "      <td>-0.273679</td>\n",
       "      <td>0.292134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173272</td>\n",
       "      <td>0.208359</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133041</th>\n",
       "      <td>2988175</td>\n",
       "      <td>4406574</td>\n",
       "      <td>-0.043845</td>\n",
       "      <td>0.520167</td>\n",
       "      <td>0.217524</td>\n",
       "      <td>-0.965000</td>\n",
       "      <td>0.505374</td>\n",
       "      <td>-0.239545</td>\n",
       "      <td>-0.556433</td>\n",
       "      <td>-0.638585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.113944</td>\n",
       "      <td>0.503882</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133042</th>\n",
       "      <td>4426250</td>\n",
       "      <td>4684474</td>\n",
       "      <td>0.019640</td>\n",
       "      <td>-0.775182</td>\n",
       "      <td>0.577893</td>\n",
       "      <td>0.159711</td>\n",
       "      <td>-0.244184</td>\n",
       "      <td>-0.093082</td>\n",
       "      <td>1.441984</td>\n",
       "      <td>-0.586338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.835501</td>\n",
       "      <td>0.438607</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133043</th>\n",
       "      <td>4875506</td>\n",
       "      <td>4788300</td>\n",
       "      <td>-0.003243</td>\n",
       "      <td>-0.289146</td>\n",
       "      <td>0.241639</td>\n",
       "      <td>-0.335586</td>\n",
       "      <td>-0.151699</td>\n",
       "      <td>0.480890</td>\n",
       "      <td>0.339751</td>\n",
       "      <td>-0.014289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.027292</td>\n",
       "      <td>0.908553</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133046</th>\n",
       "      <td>4419372</td>\n",
       "      <td>3028863</td>\n",
       "      <td>0.882613</td>\n",
       "      <td>-0.245899</td>\n",
       "      <td>-0.084419</td>\n",
       "      <td>-1.801159</td>\n",
       "      <td>-0.421756</td>\n",
       "      <td>-0.629837</td>\n",
       "      <td>-0.266369</td>\n",
       "      <td>0.771705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232059</td>\n",
       "      <td>-0.546031</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133054</th>\n",
       "      <td>2951202</td>\n",
       "      <td>4081024</td>\n",
       "      <td>-0.122876</td>\n",
       "      <td>0.344964</td>\n",
       "      <td>-0.207511</td>\n",
       "      <td>-0.455348</td>\n",
       "      <td>0.505773</td>\n",
       "      <td>0.014431</td>\n",
       "      <td>-0.273535</td>\n",
       "      <td>0.666618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.221724</td>\n",
       "      <td>0.486626</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133055</th>\n",
       "      <td>4379258</td>\n",
       "      <td>4289516</td>\n",
       "      <td>0.313306</td>\n",
       "      <td>1.668011</td>\n",
       "      <td>0.238057</td>\n",
       "      <td>-0.932895</td>\n",
       "      <td>-0.193452</td>\n",
       "      <td>0.208198</td>\n",
       "      <td>0.587217</td>\n",
       "      <td>-0.659940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.671047</td>\n",
       "      <td>-0.198674</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133056</th>\n",
       "      <td>2504169</td>\n",
       "      <td>3085551</td>\n",
       "      <td>-0.175675</td>\n",
       "      <td>-0.268599</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.566623</td>\n",
       "      <td>0.537921</td>\n",
       "      <td>1.281252</td>\n",
       "      <td>0.577633</td>\n",
       "      <td>0.793715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117873</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133057</th>\n",
       "      <td>4032401</td>\n",
       "      <td>4421978</td>\n",
       "      <td>-0.377505</td>\n",
       "      <td>-1.312164</td>\n",
       "      <td>0.367624</td>\n",
       "      <td>-0.307423</td>\n",
       "      <td>-0.478049</td>\n",
       "      <td>-1.443996</td>\n",
       "      <td>0.521851</td>\n",
       "      <td>0.346934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.667093</td>\n",
       "      <td>0.184483</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133058</th>\n",
       "      <td>3953381</td>\n",
       "      <td>4245092</td>\n",
       "      <td>0.023338</td>\n",
       "      <td>-0.670303</td>\n",
       "      <td>-0.277535</td>\n",
       "      <td>-0.608048</td>\n",
       "      <td>0.641021</td>\n",
       "      <td>-0.186049</td>\n",
       "      <td>-0.890652</td>\n",
       "      <td>0.148667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.046213</td>\n",
       "      <td>-0.025136</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133059</th>\n",
       "      <td>3031559</td>\n",
       "      <td>3023388</td>\n",
       "      <td>0.630170</td>\n",
       "      <td>-0.044230</td>\n",
       "      <td>0.160650</td>\n",
       "      <td>-0.172191</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.184488</td>\n",
       "      <td>-0.466574</td>\n",
       "      <td>0.109992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.713478</td>\n",
       "      <td>0.247692</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133060</th>\n",
       "      <td>4245094</td>\n",
       "      <td>3971496</td>\n",
       "      <td>0.203367</td>\n",
       "      <td>-0.219879</td>\n",
       "      <td>-1.728134</td>\n",
       "      <td>0.602505</td>\n",
       "      <td>-0.470242</td>\n",
       "      <td>1.383190</td>\n",
       "      <td>-0.217612</td>\n",
       "      <td>0.632655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608110</td>\n",
       "      <td>-0.406027</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133065</th>\n",
       "      <td>5074126</td>\n",
       "      <td>4783385</td>\n",
       "      <td>-0.056904</td>\n",
       "      <td>-0.278366</td>\n",
       "      <td>0.242566</td>\n",
       "      <td>-0.321009</td>\n",
       "      <td>-0.185009</td>\n",
       "      <td>-0.059651</td>\n",
       "      <td>0.153842</td>\n",
       "      <td>0.123760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.519636</td>\n",
       "      <td>0.412738</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133066</th>\n",
       "      <td>4321051</td>\n",
       "      <td>5076593</td>\n",
       "      <td>-0.479688</td>\n",
       "      <td>-0.066555</td>\n",
       "      <td>0.989041</td>\n",
       "      <td>-0.253741</td>\n",
       "      <td>-0.123955</td>\n",
       "      <td>-0.148609</td>\n",
       "      <td>0.038582</td>\n",
       "      <td>0.302530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272779</td>\n",
       "      <td>0.096828</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133068</th>\n",
       "      <td>3913473</td>\n",
       "      <td>4684776</td>\n",
       "      <td>0.763423</td>\n",
       "      <td>0.183209</td>\n",
       "      <td>0.384434</td>\n",
       "      <td>-0.633261</td>\n",
       "      <td>0.194807</td>\n",
       "      <td>-0.317664</td>\n",
       "      <td>0.031905</td>\n",
       "      <td>0.013964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.216808</td>\n",
       "      <td>-0.180734</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133071</th>\n",
       "      <td>4275487</td>\n",
       "      <td>3024395</td>\n",
       "      <td>-0.625163</td>\n",
       "      <td>0.289565</td>\n",
       "      <td>0.255464</td>\n",
       "      <td>0.268661</td>\n",
       "      <td>-0.186597</td>\n",
       "      <td>-0.654163</td>\n",
       "      <td>-0.229661</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.027786</td>\n",
       "      <td>0.216503</td>\n",
       "      <td>-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133073</th>\n",
       "      <td>4687003</td>\n",
       "      <td>4881997</td>\n",
       "      <td>0.382454</td>\n",
       "      <td>-0.412174</td>\n",
       "      <td>0.419772</td>\n",
       "      <td>-0.704622</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>-0.067649</td>\n",
       "      <td>-0.587148</td>\n",
       "      <td>0.320651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.175009</td>\n",
       "      <td>-0.234475</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133078</th>\n",
       "      <td>4306125</td>\n",
       "      <td>4815998</td>\n",
       "      <td>0.430175</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>0.020797</td>\n",
       "      <td>0.122686</td>\n",
       "      <td>-0.342395</td>\n",
       "      <td>0.482577</td>\n",
       "      <td>1.142052</td>\n",
       "      <td>0.185939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.758530</td>\n",
       "      <td>0.615629</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133079</th>\n",
       "      <td>3115931</td>\n",
       "      <td>4021217</td>\n",
       "      <td>0.479946</td>\n",
       "      <td>1.099809</td>\n",
       "      <td>1.654416</td>\n",
       "      <td>-0.171943</td>\n",
       "      <td>0.203370</td>\n",
       "      <td>1.725225</td>\n",
       "      <td>-0.698627</td>\n",
       "      <td>0.767611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.328504</td>\n",
       "      <td>0.284359</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133080</th>\n",
       "      <td>3146944</td>\n",
       "      <td>2512976</td>\n",
       "      <td>0.619807</td>\n",
       "      <td>0.528609</td>\n",
       "      <td>0.260285</td>\n",
       "      <td>0.360597</td>\n",
       "      <td>-0.528526</td>\n",
       "      <td>-0.009197</td>\n",
       "      <td>0.713280</td>\n",
       "      <td>-0.306213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.935573</td>\n",
       "      <td>-0.479448</td>\n",
       "      <td>-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133081</th>\n",
       "      <td>4873640</td>\n",
       "      <td>4410084</td>\n",
       "      <td>0.019379</td>\n",
       "      <td>-0.697238</td>\n",
       "      <td>0.692133</td>\n",
       "      <td>-1.162415</td>\n",
       "      <td>0.314892</td>\n",
       "      <td>0.196571</td>\n",
       "      <td>0.023354</td>\n",
       "      <td>0.602986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.316037</td>\n",
       "      <td>-0.031966</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133082</th>\n",
       "      <td>4426312</td>\n",
       "      <td>4738092</td>\n",
       "      <td>-0.071143</td>\n",
       "      <td>-0.105174</td>\n",
       "      <td>0.226470</td>\n",
       "      <td>0.139899</td>\n",
       "      <td>0.096431</td>\n",
       "      <td>-0.010048</td>\n",
       "      <td>0.792512</td>\n",
       "      <td>-0.672556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984344</td>\n",
       "      <td>0.624639</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133084</th>\n",
       "      <td>3090893</td>\n",
       "      <td>4046059</td>\n",
       "      <td>-0.514279</td>\n",
       "      <td>0.045537</td>\n",
       "      <td>0.456830</td>\n",
       "      <td>-0.824749</td>\n",
       "      <td>-0.339423</td>\n",
       "      <td>0.332397</td>\n",
       "      <td>-0.178514</td>\n",
       "      <td>0.678643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.005953</td>\n",
       "      <td>0.332274</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133085</th>\n",
       "      <td>3088232</td>\n",
       "      <td>2500946</td>\n",
       "      <td>-0.363337</td>\n",
       "      <td>-0.168818</td>\n",
       "      <td>-1.722193</td>\n",
       "      <td>1.532001</td>\n",
       "      <td>0.190395</td>\n",
       "      <td>-1.475967</td>\n",
       "      <td>0.117545</td>\n",
       "      <td>-0.439120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.239779</td>\n",
       "      <td>-0.431805</td>\n",
       "      <td>-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133088</th>\n",
       "      <td>2335666</td>\n",
       "      <td>2504639</td>\n",
       "      <td>-0.262384</td>\n",
       "      <td>-0.043037</td>\n",
       "      <td>-0.112755</td>\n",
       "      <td>1.874633</td>\n",
       "      <td>-0.728907</td>\n",
       "      <td>1.372556</td>\n",
       "      <td>-1.303580</td>\n",
       "      <td>0.125084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226773</td>\n",
       "      <td>0.120628</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133089</th>\n",
       "      <td>4668069</td>\n",
       "      <td>3155846</td>\n",
       "      <td>-0.308709</td>\n",
       "      <td>-0.837457</td>\n",
       "      <td>0.404753</td>\n",
       "      <td>-0.200344</td>\n",
       "      <td>0.464319</td>\n",
       "      <td>0.783454</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>-0.674187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024015</td>\n",
       "      <td>-0.134321</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133092</th>\n",
       "      <td>4695736</td>\n",
       "      <td>4873642</td>\n",
       "      <td>0.640564</td>\n",
       "      <td>0.827686</td>\n",
       "      <td>0.150212</td>\n",
       "      <td>-0.497430</td>\n",
       "      <td>0.427796</td>\n",
       "      <td>-0.325431</td>\n",
       "      <td>-0.407120</td>\n",
       "      <td>-0.088253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482098</td>\n",
       "      <td>0.346808</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133098</th>\n",
       "      <td>2516131</td>\n",
       "      <td>2951361</td>\n",
       "      <td>0.443042</td>\n",
       "      <td>-0.700990</td>\n",
       "      <td>0.176203</td>\n",
       "      <td>-1.212771</td>\n",
       "      <td>-0.458434</td>\n",
       "      <td>-0.098586</td>\n",
       "      <td>1.531828</td>\n",
       "      <td>-0.365694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079714</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133100</th>\n",
       "      <td>2560746</td>\n",
       "      <td>3027545</td>\n",
       "      <td>-0.415478</td>\n",
       "      <td>-0.020843</td>\n",
       "      <td>0.940490</td>\n",
       "      <td>-0.412782</td>\n",
       "      <td>0.128540</td>\n",
       "      <td>0.924691</td>\n",
       "      <td>-0.142310</td>\n",
       "      <td>-0.718087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710743</td>\n",
       "      <td>0.269782</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FighterID_espn OpponentID_espn  pred_elo_PC_0  pred_elo_PC_1  \\\n",
       "132984        4863327         3949555      -0.195705      -0.249167   \n",
       "132985        4397782         4040197       0.112259       0.714654   \n",
       "132986        4232775         3994033       0.202585       0.976380   \n",
       "132987        4076472         4063667       0.210980       0.391183   \n",
       "132988        3045734         3961293      -0.381281      -0.505066   \n",
       "132989        2335674         4690549       0.285680      -0.398737   \n",
       "132991        2594871         4227265      -0.194510       0.650643   \n",
       "132993        3900088         2526299       0.345742       0.411075   \n",
       "132996        3902098         2614933      -0.981286      -0.950759   \n",
       "132997        4394200         4963343       0.321315       0.165845   \n",
       "132999        4089026         4816066      -1.073514      -0.620703   \n",
       "133003        4239928         3020090       0.088705       0.837004   \n",
       "133004        2512055         2335754       0.532863       0.326385   \n",
       "133010        4418784         4292349      -0.058534       0.294277   \n",
       "133011        3151289         3922491      -0.599303       1.475839   \n",
       "133012        2504643         4333158       0.096802       0.010190   \n",
       "133013        3970873         4688408       0.064634      -0.146394   \n",
       "133014        5060394         4324623       0.002017      -0.173635   \n",
       "133016        3922557         4217395       0.811043      -0.521314   \n",
       "133017        3309918         4277049       0.266692      -0.070910   \n",
       "133019        3894823         2502364       0.130970      -0.318741   \n",
       "133020        4339130         2503659       0.593418       0.810061   \n",
       "133021        3089069         3030256      -0.657081      -0.592595   \n",
       "133022        4024488         5080935      -0.163086       0.291715   \n",
       "133025        4815974         4389093      -0.657956      -0.746681   \n",
       "133034        4375156         4686725      -0.019820       0.556889   \n",
       "133035        4835137         4012999      -0.243549       0.132756   \n",
       "133036        2558075         4903365       0.147911       0.056638   \n",
       "133037        4251462         2517186       0.165704       0.569984   \n",
       "133039        4914568         4702563       0.219062       0.759179   \n",
       "133040        4227055         4034272       0.457317       0.834310   \n",
       "133041        2988175         4406574      -0.043845       0.520167   \n",
       "133042        4426250         4684474       0.019640      -0.775182   \n",
       "133043        4875506         4788300      -0.003243      -0.289146   \n",
       "133046        4419372         3028863       0.882613      -0.245899   \n",
       "133054        2951202         4081024      -0.122876       0.344964   \n",
       "133055        4379258         4289516       0.313306       1.668011   \n",
       "133056        2504169         3085551      -0.175675      -0.268599   \n",
       "133057        4032401         4421978      -0.377505      -1.312164   \n",
       "133058        3953381         4245092       0.023338      -0.670303   \n",
       "133059        3031559         3023388       0.630170      -0.044230   \n",
       "133060        4245094         3971496       0.203367      -0.219879   \n",
       "133065        5074126         4783385      -0.056904      -0.278366   \n",
       "133066        4321051         5076593      -0.479688      -0.066555   \n",
       "133068        3913473         4684776       0.763423       0.183209   \n",
       "133071        4275487         3024395      -0.625163       0.289565   \n",
       "133073        4687003         4881997       0.382454      -0.412174   \n",
       "133078        4306125         4815998       0.430175      -0.010858   \n",
       "133079        3115931         4021217       0.479946       1.099809   \n",
       "133080        3146944         2512976       0.619807       0.528609   \n",
       "133081        4873640         4410084       0.019379      -0.697238   \n",
       "133082        4426312         4738092      -0.071143      -0.105174   \n",
       "133084        3090893         4046059      -0.514279       0.045537   \n",
       "133085        3088232         2500946      -0.363337      -0.168818   \n",
       "133088        2335666         2504639      -0.262384      -0.043037   \n",
       "133089        4668069         3155846      -0.308709      -0.837457   \n",
       "133092        4695736         4873642       0.640564       0.827686   \n",
       "133098        2516131         2951361       0.443042      -0.700990   \n",
       "133100        2560746         3027545      -0.415478      -0.020843   \n",
       "\n",
       "        pred_elo_PC_2  pred_elo_PC_3  pred_elo_PC_4  pred_elo_PC_5  \\\n",
       "132984      -0.068994       0.682357       0.265850       0.332739   \n",
       "132985       0.967333      -1.279557       0.390686      -0.224637   \n",
       "132986       0.029361      -1.416281      -0.196303      -0.420252   \n",
       "132987      -0.089732      -0.591662      -0.648010       0.036722   \n",
       "132988       0.555358       0.363368       0.224523       0.700904   \n",
       "132989       0.437694      -1.458451      -0.138322       0.162732   \n",
       "132991      -0.265063      -0.548014       0.247813       0.141773   \n",
       "132993      -0.050783       0.761484      -0.134104      -1.021289   \n",
       "132996      -0.842446       0.633129      -0.954096      -0.628756   \n",
       "132997      -0.302548       0.084098       0.106047       0.583619   \n",
       "132999       0.211283      -0.816519       0.877023      -0.425521   \n",
       "133003      -0.081885       0.039529      -0.063510      -0.524971   \n",
       "133004       0.068641      -0.647781      -0.200518      -0.350859   \n",
       "133010      -0.205873       0.369073       1.105809       0.260411   \n",
       "133011      -0.967742       0.014702       0.082234       0.185902   \n",
       "133012      -0.012390      -0.223778      -0.185530       0.124228   \n",
       "133013      -0.327473      -0.314480       0.571793      -0.969727   \n",
       "133014      -0.246236       0.611450       0.029376      -0.293469   \n",
       "133016       0.688678      -0.772041      -0.924842       0.167326   \n",
       "133017      -0.008271       0.098454       1.143072      -0.191985   \n",
       "133019       0.264974      -0.204758      -0.554714       0.351630   \n",
       "133020      -1.324708       1.662906      -1.107296       0.308445   \n",
       "133021      -0.228173       0.164238       0.157888      -0.295335   \n",
       "133022       0.040737      -0.177596      -0.124726      -0.038337   \n",
       "133025       0.398674       0.335451      -0.073774       0.162743   \n",
       "133034       0.191263       0.706798      -0.076375       0.164163   \n",
       "133035       0.828913       0.262290       1.633730      -0.290362   \n",
       "133036       0.130269      -1.129835      -0.065689       0.484352   \n",
       "133037      -0.608713      -0.955094       0.774204      -0.695898   \n",
       "133039      -0.001518       0.400720      -0.156865       0.096837   \n",
       "133040      -0.451403       0.590604       0.782637      -0.339107   \n",
       "133041       0.217524      -0.965000       0.505374      -0.239545   \n",
       "133042       0.577893       0.159711      -0.244184      -0.093082   \n",
       "133043       0.241639      -0.335586      -0.151699       0.480890   \n",
       "133046      -0.084419      -1.801159      -0.421756      -0.629837   \n",
       "133054      -0.207511      -0.455348       0.505773       0.014431   \n",
       "133055       0.238057      -0.932895      -0.193452       0.208198   \n",
       "133056       0.608406       0.566623       0.537921       1.281252   \n",
       "133057       0.367624      -0.307423      -0.478049      -1.443996   \n",
       "133058      -0.277535      -0.608048       0.641021      -0.186049   \n",
       "133059       0.160650      -0.172191       0.131000       0.184488   \n",
       "133060      -1.728134       0.602505      -0.470242       1.383190   \n",
       "133065       0.242566      -0.321009      -0.185009      -0.059651   \n",
       "133066       0.989041      -0.253741      -0.123955      -0.148609   \n",
       "133068       0.384434      -0.633261       0.194807      -0.317664   \n",
       "133071       0.255464       0.268661      -0.186597      -0.654163   \n",
       "133073       0.419772      -0.704622       0.018410      -0.067649   \n",
       "133078       0.020797       0.122686      -0.342395       0.482577   \n",
       "133079       1.654416      -0.171943       0.203370       1.725225   \n",
       "133080       0.260285       0.360597      -0.528526      -0.009197   \n",
       "133081       0.692133      -1.162415       0.314892       0.196571   \n",
       "133082       0.226470       0.139899       0.096431      -0.010048   \n",
       "133084       0.456830      -0.824749      -0.339423       0.332397   \n",
       "133085      -1.722193       1.532001       0.190395      -1.475967   \n",
       "133088      -0.112755       1.874633      -0.728907       1.372556   \n",
       "133089       0.404753      -0.200344       0.464319       0.783454   \n",
       "133092       0.150212      -0.497430       0.427796      -0.325431   \n",
       "133098       0.176203      -1.212771      -0.458434      -0.098586   \n",
       "133100       0.940490      -0.412782       0.128540       0.924691   \n",
       "\n",
       "        pred_elo_PC_6  pred_elo_PC_7  ...   age_diff  log_reach_diff  \\\n",
       "132984      -0.606089       0.157302  ...   7.317808        0.081126   \n",
       "132985       0.238147       0.725284  ...   1.295890        0.036368   \n",
       "132986       0.437974      -0.305062  ...  -2.369863        0.006645   \n",
       "132987       0.744049      -0.196450  ...  -0.950685        0.013793   \n",
       "132988       0.680059      -0.225259  ...  -4.624658       -0.030305   \n",
       "132989      -0.757358      -0.317639  ... -12.665753        0.000000   \n",
       "132991       0.096254      -1.325625  ...  -1.021918        0.061036   \n",
       "132993      -1.008232       0.382047  ...   2.882192       -0.068993   \n",
       "132996       0.892606      -0.476728  ...   2.136986        0.014389   \n",
       "132997      -0.376468       0.366369  ...  -6.315068        0.038915   \n",
       "132999       0.448058       0.218753  ...   2.512329       -0.007905   \n",
       "133003       0.013639      -0.584603  ...  -0.391781        0.029853   \n",
       "133004       0.444590      -0.384626  ...   3.835616       -0.026317   \n",
       "133010       0.249523       0.678917  ...   0.000000        0.000000   \n",
       "133011      -0.429443       0.737151  ...   0.000000        0.000000   \n",
       "133012      -0.563981      -0.172217  ...   0.000000        0.000000   \n",
       "133013      -0.644147      -0.022577  ...   0.000000        0.000000   \n",
       "133014      -0.144704       0.112844  ...   0.000000        0.000000   \n",
       "133016       0.041051      -0.088420  ...   0.000000        0.000000   \n",
       "133017       0.049392      -0.488933  ...   0.000000        0.000000   \n",
       "133019       1.418354      -0.401714  ...   0.000000        0.000000   \n",
       "133020      -0.269646       0.517220  ...   0.000000        0.000000   \n",
       "133021      -1.117541       0.123758  ...   0.000000        0.000000   \n",
       "133022       0.315883      -0.280897  ...   0.000000        0.000000   \n",
       "133025       0.178847       0.537192  ...   0.000000        0.000000   \n",
       "133034       0.268000       0.554404  ...   0.000000        0.000000   \n",
       "133035       0.412471      -0.497415  ...   0.000000        0.000000   \n",
       "133036       0.012530       0.163817  ...   0.000000        0.000000   \n",
       "133037       0.266996       0.132750  ...   0.000000        0.000000   \n",
       "133039       0.471451      -0.102770  ...   0.000000        0.000000   \n",
       "133040      -0.273679       0.292134  ...   0.000000        0.000000   \n",
       "133041      -0.556433      -0.638585  ...   0.000000        0.000000   \n",
       "133042       1.441984      -0.586338  ...   0.000000        0.000000   \n",
       "133043       0.339751      -0.014289  ...   0.000000        0.000000   \n",
       "133046      -0.266369       0.771705  ...   0.000000        0.000000   \n",
       "133054      -0.273535       0.666618  ...   0.000000        0.000000   \n",
       "133055       0.587217      -0.659940  ...   0.000000        0.000000   \n",
       "133056       0.577633       0.793715  ...   0.000000        0.000000   \n",
       "133057       0.521851       0.346934  ...   0.000000        0.000000   \n",
       "133058      -0.890652       0.148667  ...   0.000000        0.000000   \n",
       "133059      -0.466574       0.109992  ...   0.000000        0.000000   \n",
       "133060      -0.217612       0.632655  ...   0.000000        0.000000   \n",
       "133065       0.153842       0.123760  ...   0.000000        0.000000   \n",
       "133066       0.038582       0.302530  ...   0.000000        0.000000   \n",
       "133068       0.031905       0.013964  ...   0.000000        0.000000   \n",
       "133071      -0.229661       0.006536  ...   0.000000        0.000000   \n",
       "133073      -0.587148       0.320651  ...   0.000000        0.000000   \n",
       "133078       1.142052       0.185939  ...   0.000000        0.000000   \n",
       "133079      -0.698627       0.767611  ...   0.000000        0.000000   \n",
       "133080       0.713280      -0.306213  ...   0.000000        0.000000   \n",
       "133081       0.023354       0.602986  ...   0.000000        0.000000   \n",
       "133082       0.792512      -0.672556  ...   0.000000        0.000000   \n",
       "133084      -0.178514       0.678643  ...   0.000000        0.000000   \n",
       "133085       0.117545      -0.439120  ...   0.000000        0.000000   \n",
       "133088      -1.303580       0.125084  ...   0.000000        0.000000   \n",
       "133089       0.113100      -0.674187  ...   0.000000        0.000000   \n",
       "133092      -0.407120      -0.088253  ...   0.000000        0.000000   \n",
       "133098       1.531828      -0.365694  ...   0.000000        0.000000   \n",
       "133100      -0.142310      -0.718087  ...   0.000000        0.000000   \n",
       "\n",
       "        weight_diff  height_diff  log_t_since_prev_fight_diff  \\\n",
       "132984          0.0          4.0                    -0.528675   \n",
       "132985          0.0          0.0                     0.084218   \n",
       "132986          0.0          1.0                     0.354646   \n",
       "132987          0.0          3.0                     0.507671   \n",
       "132988          0.0         -3.0                     0.619535   \n",
       "132989          0.0          0.0                     0.110348   \n",
       "132991          0.0          5.0                    -0.375433   \n",
       "132993          0.0         -1.0                    -1.164626   \n",
       "132996          0.0         -3.0                    -0.533062   \n",
       "132997          0.0          4.0                     0.018780   \n",
       "132999          0.0          2.0                     0.142372   \n",
       "133003          0.0          3.0                     0.942802   \n",
       "133004          0.0         -1.0                     0.442064   \n",
       "133010          0.0          0.0                     0.206614   \n",
       "133011          0.0          0.0                    -0.253860   \n",
       "133012          0.0          0.0                     0.153586   \n",
       "133013          0.0          0.0                     0.889154   \n",
       "133014          0.0          0.0                    -0.497977   \n",
       "133016          0.0          0.0                     0.664368   \n",
       "133017          0.0          0.0                     0.244263   \n",
       "133019          0.0          0.0                     0.053653   \n",
       "133020          0.0          0.0                    -1.164308   \n",
       "133021          0.0          0.0                    -0.594022   \n",
       "133022          0.0          0.0                     0.027292   \n",
       "133025          0.0          0.0                    -0.712317   \n",
       "133034          0.0          0.0                    -1.050603   \n",
       "133035          0.0          0.0                     0.349184   \n",
       "133036          0.0          0.0                     0.121890   \n",
       "133037          0.0          0.0                    -0.835501   \n",
       "133039          0.0          0.0                     0.285991   \n",
       "133040          0.0          0.0                     0.173272   \n",
       "133041          0.0          0.0                    -0.113944   \n",
       "133042          0.0          0.0                     0.835501   \n",
       "133043          0.0          0.0                    -0.027292   \n",
       "133046          0.0          0.0                    -0.232059   \n",
       "133054          0.0          0.0                    -0.221724   \n",
       "133055          0.0          0.0                    -0.671047   \n",
       "133056          0.0          0.0                     0.000000   \n",
       "133057          0.0          0.0                     1.667093   \n",
       "133058          0.0          0.0                    -0.046213   \n",
       "133059          0.0          0.0                    -1.713478   \n",
       "133060          0.0          0.0                     0.608110   \n",
       "133065          0.0          0.0                    -0.519636   \n",
       "133066          0.0          0.0                    -0.272779   \n",
       "133068          0.0          0.0                    -0.216808   \n",
       "133071          0.0          0.0                     1.027786   \n",
       "133073          0.0          0.0                    -0.175009   \n",
       "133078          0.0          0.0                     0.758530   \n",
       "133079          0.0          0.0                    -0.328504   \n",
       "133080          0.0          0.0                    -0.935573   \n",
       "133081          0.0          0.0                    -0.316037   \n",
       "133082          0.0          0.0                     0.984344   \n",
       "133084          0.0          0.0                     1.005953   \n",
       "133085          0.0          0.0                    -0.239779   \n",
       "133088          0.0          0.0                     0.226773   \n",
       "133089          0.0          0.0                     0.024015   \n",
       "133092          0.0          0.0                     0.482098   \n",
       "133098          0.0          0.0                     0.000000   \n",
       "133100          0.0          0.0                     0.710743   \n",
       "\n",
       "        log_t_since_first_fight_diff  total_fights_diff  usa_diff  \\\n",
       "132984                     -0.510659                 -7        -1   \n",
       "132985                     -0.146069                 -5         0   \n",
       "132986                     -0.046496                  3         0   \n",
       "132987                      0.142094                 -3         0   \n",
       "132988                      0.358149                  4        -1   \n",
       "132989                      0.809855                 39         1   \n",
       "132991                     -0.061522                 13         1   \n",
       "132993                     -0.320020                -12         1   \n",
       "132996                     -0.133283                -10        -1   \n",
       "132997                      0.409856                  3         0   \n",
       "132999                      0.183711                  9         0   \n",
       "133003                     -0.174199                 -3         1   \n",
       "133004                     -0.259292                -12         0   \n",
       "133010                     -0.514944                -10         0   \n",
       "133011                      0.069939                  5         0   \n",
       "133012                      0.205259                 -3         0   \n",
       "133013                      0.555333                 -1         0   \n",
       "133014                     -0.736978                 -6         0   \n",
       "133016                      0.064518                  3         0   \n",
       "133017                      0.361569                  3         0   \n",
       "133019                     -0.222785                -19         0   \n",
       "133020                     -1.262711                -26         0   \n",
       "133021                     -0.262904                 -1         0   \n",
       "133022                      0.355801                 -7         0   \n",
       "133025                     -0.901612                 -7         0   \n",
       "133034                     -0.027378                 -2         0   \n",
       "133035                     -0.104183                 -9         0   \n",
       "133036                      1.049269                 21         0   \n",
       "133037                     -0.461602                -23         0   \n",
       "133039                     -0.706106                 -3         0   \n",
       "133040                      0.208359                 -1         0   \n",
       "133041                      0.503882                  9         0   \n",
       "133042                      0.438607                 -1         0   \n",
       "133043                      0.908553                  5         0   \n",
       "133046                     -0.546031                 -1         0   \n",
       "133054                      0.486626                 24         0   \n",
       "133055                     -0.198674                 -1         0   \n",
       "133056                      0.117873                 16         0   \n",
       "133057                      0.184483                -14         0   \n",
       "133058                     -0.025136                 -1         0   \n",
       "133059                      0.247692                  7         0   \n",
       "133060                     -0.406027                 -7         0   \n",
       "133065                      0.412738                  2         0   \n",
       "133066                      0.096828                 11         0   \n",
       "133068                     -0.180734                  2         0   \n",
       "133071                      0.216503                -13         0   \n",
       "133073                     -0.234475                  3         0   \n",
       "133078                      0.615629                  4         0   \n",
       "133079                      0.284359                 12         0   \n",
       "133080                     -0.479448                -26         0   \n",
       "133081                     -0.031966                  3         0   \n",
       "133082                      0.624639                  9         0   \n",
       "133084                      0.332274                  7         0   \n",
       "133085                     -0.431805                -17         0   \n",
       "133088                      0.120628                 11         0   \n",
       "133089                     -0.134321                 -7         0   \n",
       "133092                      0.346808                -14         0   \n",
       "133098                      0.079714                 10         0   \n",
       "133100                      0.269782                  1         0   \n",
       "\n",
       "        russia_diff  stance_diff  \n",
       "132984            0            1  \n",
       "132985            0            0  \n",
       "132986            0           -1  \n",
       "132987            0            0  \n",
       "132988            0            0  \n",
       "132989            0            0  \n",
       "132991           -1           -1  \n",
       "132993            0            0  \n",
       "132996            0            1  \n",
       "132997            0            0  \n",
       "132999            0            0  \n",
       "133003            0            1  \n",
       "133004            0            1  \n",
       "133010            0            0  \n",
       "133011            0            0  \n",
       "133012            0            0  \n",
       "133013            0            0  \n",
       "133014            0            0  \n",
       "133016            0            0  \n",
       "133017            0            0  \n",
       "133019            0            0  \n",
       "133020            0            0  \n",
       "133021            0            0  \n",
       "133022            0            0  \n",
       "133025            0            0  \n",
       "133034            0            0  \n",
       "133035            0            0  \n",
       "133036            0            0  \n",
       "133037            0            0  \n",
       "133039            0            0  \n",
       "133040            0            0  \n",
       "133041            0            0  \n",
       "133042            0            0  \n",
       "133043            0            0  \n",
       "133046            0            0  \n",
       "133054            0            0  \n",
       "133055            0            0  \n",
       "133056            0            0  \n",
       "133057            0            0  \n",
       "133058            0            0  \n",
       "133059            0            0  \n",
       "133060            0            0  \n",
       "133065            0            0  \n",
       "133066            0            0  \n",
       "133068            0            0  \n",
       "133071            0            0  \n",
       "133073            0            0  \n",
       "133078            0            0  \n",
       "133079            0            0  \n",
       "133080            0            0  \n",
       "133081            0            0  \n",
       "133082            0            0  \n",
       "133084            0            0  \n",
       "133085            0            0  \n",
       "133088            0            0  \n",
       "133089            0            0  \n",
       "133092            0            0  \n",
       "133098            0            0  \n",
       "133100            0            0  \n",
       "\n",
       "[59 rows x 29 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feat_ml_df.query(\"Date == '2023-04-15'\")[[\"FighterName\", \"OpponentName\"]]\n",
    "feat_ml_df.query(\"is_upcoming == 1\")[[\"FighterID_espn\", \"OpponentID_espn\", *feat_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12915, 387), (13, 387))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from wrangle.clean_bfo_data import parse_american_odds\n",
    "\n",
    "train_df = feat_ml_df.query(\"is_upcoming == 0\")\\\n",
    "    .dropna(subset=[\n",
    "        *feat_cols, \"win_target\", p_fighter_implied_col\n",
    "    ], how=\"any\")\n",
    "test_df = feat_ml_df.query(\"Date == '2023-04-15'\").copy()\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -34433.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.75682574, 0.41568308, 0.55236191, 0.53309491, 0.20654615,\n",
       "       0.27623798, 0.53562018, 0.60768639, 0.50246826, 0.56842175,\n",
       "       0.39721932, 0.41095475, 0.79942643])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7634.21     0.0025949       4.42508      0.6432      0.6432       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7634.21    0.00038426      0.192341           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "mod = SimpleSymmetricModel(\n",
    "    feat_cols=feat_cols, target_col=\"win_target\", \n",
    "    p_fighter_implied_col=p_fighter_implied_col,\n",
    "    beta_prior_std=1.0, mcmc=False\n",
    ")\n",
    "\n",
    "y_pred = mod.fit_predict(train_df, test_df, feat_cols)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterName</th>\n",
       "      <th>OpponentName</th>\n",
       "      <th>FighterOpen</th>\n",
       "      <th>OpponentOpen</th>\n",
       "      <th>p_fighter_open_implied</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132984</th>\n",
       "      <td>daniel zellhuber</td>\n",
       "      <td>lando vannata</td>\n",
       "      <td>-175</td>\n",
       "      <td>+150</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.756826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132985</th>\n",
       "      <td>joselyne edwards</td>\n",
       "      <td>lucie pudilova</td>\n",
       "      <td>+150</td>\n",
       "      <td>-175</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.415683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132986</th>\n",
       "      <td>tanner boser</td>\n",
       "      <td>ion curelaba</td>\n",
       "      <td>-160</td>\n",
       "      <td>+140</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.552362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132987</th>\n",
       "      <td>bill algeo</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>-139</td>\n",
       "      <td>+119</td>\n",
       "      <td>0.560185</td>\n",
       "      <td>0.533095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132988</th>\n",
       "      <td>pedro munhoz</td>\n",
       "      <td>chris gutierrez</td>\n",
       "      <td>+200</td>\n",
       "      <td>-235</td>\n",
       "      <td>0.322115</td>\n",
       "      <td>0.206546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132989</th>\n",
       "      <td>clay guida</td>\n",
       "      <td>rafa garcia</td>\n",
       "      <td>+140</td>\n",
       "      <td>-160</td>\n",
       "      <td>0.403727</td>\n",
       "      <td>0.276238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132991</th>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>azamat murzakanov</td>\n",
       "      <td>-200</td>\n",
       "      <td>+170</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.535620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132993</th>\n",
       "      <td>billy quarantillo</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>-155</td>\n",
       "      <td>+135</td>\n",
       "      <td>0.588212</td>\n",
       "      <td>0.607686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132996</th>\n",
       "      <td>arnold allen</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>+125</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.428884</td>\n",
       "      <td>0.502468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132997</th>\n",
       "      <td>bruna brasil</td>\n",
       "      <td>denise gomes</td>\n",
       "      <td>-160</td>\n",
       "      <td>+140</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.568422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132999</th>\n",
       "      <td>gillian robertson</td>\n",
       "      <td>piera rodriguez</td>\n",
       "      <td>+115</td>\n",
       "      <td>-135</td>\n",
       "      <td>0.447406</td>\n",
       "      <td>0.397219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133003</th>\n",
       "      <td>brandon royval</td>\n",
       "      <td>matheus nicolau</td>\n",
       "      <td>+125</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.428884</td>\n",
       "      <td>0.410955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133004</th>\n",
       "      <td>zak cummings</td>\n",
       "      <td>ed herman</td>\n",
       "      <td>-250</td>\n",
       "      <td>+210</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.799426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FighterName       OpponentName FighterOpen OpponentOpen  \\\n",
       "132984   daniel zellhuber      lando vannata        -175         +150   \n",
       "132985   joselyne edwards     lucie pudilova        +150         -175   \n",
       "132986       tanner boser       ion curelaba        -160         +140   \n",
       "132987         bill algeo           tj brown        -139         +119   \n",
       "132988       pedro munhoz    chris gutierrez        +200         -235   \n",
       "132989         clay guida        rafa garcia        +140         -160   \n",
       "132991      dustin jacoby  azamat murzakanov        -200         +170   \n",
       "132993  billy quarantillo      edson barboza        -155         +135   \n",
       "132996       arnold allen       max holloway        +125         -145   \n",
       "132997       bruna brasil       denise gomes        -160         +140   \n",
       "132999  gillian robertson    piera rodriguez        +115         -135   \n",
       "133003     brandon royval    matheus nicolau        +125         -145   \n",
       "133004       zak cummings          ed herman        -250         +210   \n",
       "\n",
       "        p_fighter_open_implied    y_pred  \n",
       "132984                0.614035  0.756826  \n",
       "132985                0.385965  0.415683  \n",
       "132986                0.596273  0.552362  \n",
       "132987                0.560185  0.533095  \n",
       "132988                0.322115  0.206546  \n",
       "132989                0.403727  0.276238  \n",
       "132991                0.642857  0.535620  \n",
       "132993                0.588212  0.607686  \n",
       "132996                0.428884  0.502468  \n",
       "132997                0.596273  0.568422  \n",
       "132999                0.447406  0.397219  \n",
       "133003                0.428884  0.410955  \n",
       "133004                0.688889  0.799426  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = test_df.assign(y_pred = y_pred)\n",
    "preds_df[[\"FighterName\", \"OpponentName\", \n",
    "          \"FighterOpen\", \"OpponentOpen\", \n",
    "          p_fighter_implied_col, \"y_pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterName</th>\n",
       "      <th>OpponentName</th>\n",
       "      <th>DraftKings_fighter</th>\n",
       "      <th>DraftKings_opponent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daniel zellhuber</td>\n",
       "      <td>lando vannata</td>\n",
       "      <td>-130</td>\n",
       "      <td>+110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joselyne edwards</td>\n",
       "      <td>lucie pudilova</td>\n",
       "      <td>+115</td>\n",
       "      <td>-135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tanner boser</td>\n",
       "      <td>ion curelaba</td>\n",
       "      <td>+110</td>\n",
       "      <td>-130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bill algeo</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>-190</td>\n",
       "      <td>+160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pedro munhoz</td>\n",
       "      <td>chris gutierrez</td>\n",
       "      <td>+170</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clay guida</td>\n",
       "      <td>rafa garcia</td>\n",
       "      <td>+215</td>\n",
       "      <td>-255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>azamat murzakanov</td>\n",
       "      <td>-150</td>\n",
       "      <td>+130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>billy quarantillo</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>-170</td>\n",
       "      <td>+145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arnold allen</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>+140</td>\n",
       "      <td>-165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bruna brasil</td>\n",
       "      <td>denise gomes</td>\n",
       "      <td>-150</td>\n",
       "      <td>+130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gillian robertson</td>\n",
       "      <td>piera rodriguez</td>\n",
       "      <td>-125</td>\n",
       "      <td>+105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>brandon royval</td>\n",
       "      <td>matheus nicolau</td>\n",
       "      <td>+170</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zak cummings</td>\n",
       "      <td>ed herman</td>\n",
       "      <td>-225</td>\n",
       "      <td>+190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FighterName       OpponentName DraftKings_fighter  \\\n",
       "0    daniel zellhuber      lando vannata               -130   \n",
       "1    joselyne edwards     lucie pudilova               +115   \n",
       "2        tanner boser       ion curelaba               +110   \n",
       "3          bill algeo           tj brown               -190   \n",
       "4        pedro munhoz    chris gutierrez               +170   \n",
       "5          clay guida        rafa garcia               +215   \n",
       "6       dustin jacoby  azamat murzakanov               -150   \n",
       "7   billy quarantillo      edson barboza               -170   \n",
       "8        arnold allen       max holloway               +140   \n",
       "9        bruna brasil       denise gomes               -150   \n",
       "10  gillian robertson    piera rodriguez               -125   \n",
       "11     brandon royval    matheus nicolau               +170   \n",
       "12       zak cummings          ed herman               -225   \n",
       "\n",
       "   DraftKings_opponent  \n",
       "0                 +110  \n",
       "1                 -135  \n",
       "2                 -130  \n",
       "3                 +160  \n",
       "4                 -200  \n",
       "5                 -255  \n",
       "6                 +130  \n",
       "7                 +145  \n",
       "8                 -165  \n",
       "9                 +130  \n",
       "10                +105  \n",
       "11                -200  \n",
       "12                +190  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df = pd.DataFrame([['daniel zellhuber', 'lando vannata', \"-130\", \"+110\"],\n",
    "['joselyne edwards', 'lucie pudilova', \"+115\", \"-135\"],\n",
    "['tanner boser', 'ion curelaba', \"+110\", \"-130\"],\n",
    "['bill algeo', 'tj brown', \"-190\", \"+160\"],\n",
    "['pedro munhoz', 'chris gutierrez', \"+170\", \"-200\"],\n",
    "['clay guida', 'rafa garcia', \"+215\", \"-255\"],\n",
    "['dustin jacoby', 'azamat murzakanov', \"-150\", \"+130\"],\n",
    "['billy quarantillo', 'edson barboza', \"-170\", \"+145\"],\n",
    "['arnold allen', 'max holloway', \"+140\", \"-165\"],\n",
    "['bruna brasil', 'denise gomes', \"-150\", \"+130\"],\n",
    "['gillian robertson', 'piera rodriguez', \"-125\", \"+105\"],\n",
    "['brandon royval', 'matheus nicolau', \"+170\", \"-200\"],\n",
    "['zak cummings', 'ed herman', \"-225\", \"+190\"]], \n",
    "columns=[\"FighterName\", \"OpponentName\", \"DraftKings_fighter\", \"DraftKings_opponent\"])\n",
    "ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight_id_legacy</th>\n",
       "      <th>Date</th>\n",
       "      <th>FighterResult</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Rnd</th>\n",
       "      <th>Time</th>\n",
       "      <th>Event</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>TSL</th>\n",
       "      <th>...</th>\n",
       "      <th>height_diff</th>\n",
       "      <th>t_since_first_fight_diff</th>\n",
       "      <th>log_t_since_first_fight_diff</th>\n",
       "      <th>log_t_since_prev_fight_diff</th>\n",
       "      <th>usa_diff</th>\n",
       "      <th>russia_diff</th>\n",
       "      <th>stance_diff</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>DraftKings_fighter</th>\n",
       "      <th>DraftKings_opponent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-15_3949555_4863327</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3949555</td>\n",
       "      <td>4863327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1596</td>\n",
       "      <td>-0.510659</td>\n",
       "      <td>-0.528675</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.756826</td>\n",
       "      <td>-130</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-15_4040197_4397782</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4040197</td>\n",
       "      <td>4397782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-455</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>0.084218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415683</td>\n",
       "      <td>115</td>\n",
       "      <td>-135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-15_3994033_4232775</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3994033</td>\n",
       "      <td>4232775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-183</td>\n",
       "      <td>-0.046496</td>\n",
       "      <td>0.354646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.552362</td>\n",
       "      <td>110</td>\n",
       "      <td>-130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-15_4063667_4076472</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4063667</td>\n",
       "      <td>4076472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>526</td>\n",
       "      <td>0.142094</td>\n",
       "      <td>0.507671</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533095</td>\n",
       "      <td>-190</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-15_3045734_3961293</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3961293</td>\n",
       "      <td>3045734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1547</td>\n",
       "      <td>0.358149</td>\n",
       "      <td>0.619535</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.206546</td>\n",
       "      <td>170</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-04-15_2335674_4690549</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4690549</td>\n",
       "      <td>2335674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3870</td>\n",
       "      <td>0.809855</td>\n",
       "      <td>0.110348</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.276238</td>\n",
       "      <td>215</td>\n",
       "      <td>-255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-04-15_2594871_4227265</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4227265</td>\n",
       "      <td>2594871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-287</td>\n",
       "      <td>-0.061522</td>\n",
       "      <td>-0.375433</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.535620</td>\n",
       "      <td>-150</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-04-15_2526299_3900088</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>2526299</td>\n",
       "      <td>3900088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1400</td>\n",
       "      <td>-0.320020</td>\n",
       "      <td>-1.164626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607686</td>\n",
       "      <td>-170</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-04-15_2614933_3902098</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>2614933</td>\n",
       "      <td>3902098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-574</td>\n",
       "      <td>-0.133283</td>\n",
       "      <td>-0.533062</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502468</td>\n",
       "      <td>140</td>\n",
       "      <td>-165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-04-15_4394200_4963343</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4963343</td>\n",
       "      <td>4394200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1036</td>\n",
       "      <td>0.409856</td>\n",
       "      <td>0.018780</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.568422</td>\n",
       "      <td>-150</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-04-15_4089026_4816066</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4816066</td>\n",
       "      <td>4089026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>435</td>\n",
       "      <td>0.183711</td>\n",
       "      <td>0.142372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.397219</td>\n",
       "      <td>-125</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-04-15_3020090_4239928</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3020090</td>\n",
       "      <td>4239928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-741</td>\n",
       "      <td>-0.174199</td>\n",
       "      <td>0.942802</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.410955</td>\n",
       "      <td>170</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-04-15_2335754_2512055</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>2335754</td>\n",
       "      <td>2512055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1663</td>\n",
       "      <td>-0.259292</td>\n",
       "      <td>0.442064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799426</td>\n",
       "      <td>-225</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 390 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               fight_id_legacy       Date FighterResult Decision Rnd Time  \\\n",
       "0   2023-04-15_3949555_4863327 2023-04-15          None     None   -    -   \n",
       "1   2023-04-15_4040197_4397782 2023-04-15          None     None   -    -   \n",
       "2   2023-04-15_3994033_4232775 2023-04-15          None     None   -    -   \n",
       "3   2023-04-15_4063667_4076472 2023-04-15          None     None   -    -   \n",
       "4   2023-04-15_3045734_3961293 2023-04-15          None     None   -    -   \n",
       "5   2023-04-15_2335674_4690549 2023-04-15          None     None   -    -   \n",
       "6   2023-04-15_2594871_4227265 2023-04-15          None     None   -    -   \n",
       "7   2023-04-15_2526299_3900088 2023-04-15          None     None   -    -   \n",
       "8   2023-04-15_2614933_3902098 2023-04-15          None     None   -    -   \n",
       "9   2023-04-15_4394200_4963343 2023-04-15          None     None   -    -   \n",
       "10  2023-04-15_4089026_4816066 2023-04-15          None     None   -    -   \n",
       "11  2023-04-15_3020090_4239928 2023-04-15          None     None   -    -   \n",
       "12  2023-04-15_2335754_2512055 2023-04-15          None     None   -    -   \n",
       "\n",
       "                                  Event OpponentID_espn FighterID_espn  TSL  \\\n",
       "0   UFC Fight Night: Holloway vs. Allen         3949555        4863327  NaN   \n",
       "1   UFC Fight Night: Holloway vs. Allen         4040197        4397782  NaN   \n",
       "2   UFC Fight Night: Holloway vs. Allen         3994033        4232775  NaN   \n",
       "3   UFC Fight Night: Holloway vs. Allen         4063667        4076472  NaN   \n",
       "4   UFC Fight Night: Holloway vs. Allen         3961293        3045734  NaN   \n",
       "5   UFC Fight Night: Holloway vs. Allen         4690549        2335674  NaN   \n",
       "6   UFC Fight Night: Holloway vs. Allen         4227265        2594871  NaN   \n",
       "7   UFC Fight Night: Holloway vs. Allen         2526299        3900088  NaN   \n",
       "8   UFC Fight Night: Holloway vs. Allen         2614933        3902098  NaN   \n",
       "9   UFC Fight Night: Holloway vs. Allen         4963343        4394200  NaN   \n",
       "10  UFC Fight Night: Holloway vs. Allen         4816066        4089026  NaN   \n",
       "11  UFC Fight Night: Holloway vs. Allen         3020090        4239928  NaN   \n",
       "12  UFC Fight Night: Holloway vs. Allen         2335754        2512055  NaN   \n",
       "\n",
       "    ...  height_diff  t_since_first_fight_diff  log_t_since_first_fight_diff  \\\n",
       "0   ...          4.0                     -1596                     -0.510659   \n",
       "1   ...          0.0                      -455                     -0.146069   \n",
       "2   ...          1.0                      -183                     -0.046496   \n",
       "3   ...          3.0                       526                      0.142094   \n",
       "4   ...         -3.0                      1547                      0.358149   \n",
       "5   ...          0.0                      3870                      0.809855   \n",
       "6   ...          5.0                      -287                     -0.061522   \n",
       "7   ...         -1.0                     -1400                     -0.320020   \n",
       "8   ...         -3.0                      -574                     -0.133283   \n",
       "9   ...          4.0                      1036                      0.409856   \n",
       "10  ...          2.0                       435                      0.183711   \n",
       "11  ...          3.0                      -741                     -0.174199   \n",
       "12  ...         -1.0                     -1663                     -0.259292   \n",
       "\n",
       "    log_t_since_prev_fight_diff  usa_diff  russia_diff  stance_diff    y_pred  \\\n",
       "0                     -0.528675        -1            0            1  0.756826   \n",
       "1                      0.084218         0            0            0  0.415683   \n",
       "2                      0.354646         0            0           -1  0.552362   \n",
       "3                      0.507671         0            0            0  0.533095   \n",
       "4                      0.619535        -1            0            0  0.206546   \n",
       "5                      0.110348         1            0            0  0.276238   \n",
       "6                     -0.375433         1           -1           -1  0.535620   \n",
       "7                     -1.164626         1            0            0  0.607686   \n",
       "8                     -0.533062        -1            0            1  0.502468   \n",
       "9                      0.018780         0            0            0  0.568422   \n",
       "10                     0.142372         0            0            0  0.397219   \n",
       "11                     0.942802         1            0            1  0.410955   \n",
       "12                     0.442064         0            0            1  0.799426   \n",
       "\n",
       "    DraftKings_fighter  DraftKings_opponent  \n",
       "0                 -130                  110  \n",
       "1                  115                 -135  \n",
       "2                  110                 -130  \n",
       "3                 -190                  160  \n",
       "4                  170                 -200  \n",
       "5                  215                 -255  \n",
       "6                 -150                  130  \n",
       "7                 -170                  145  \n",
       "8                  140                 -165  \n",
       "9                 -150                  130  \n",
       "10                -125                  105  \n",
       "11                 170                 -200  \n",
       "12                -225                  190  \n",
       "\n",
       "[13 rows x 390 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_preds_df = preds_df.merge(\n",
    "    ml_df,\n",
    "    on=[\"FighterName\", \"OpponentName\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "aug_preds_df[\"DraftKings_fighter\"] = aug_preds_df[\"DraftKings_fighter\"].astype(int)\n",
    "aug_preds_df[\"DraftKings_opponent\"] = aug_preds_df[\"DraftKings_opponent\"].astype(int)\n",
    "aug_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterName</th>\n",
       "      <th>fighter_bet</th>\n",
       "      <th>OpponentName</th>\n",
       "      <th>opponent_bet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daniel zellhuber</td>\n",
       "      <td>0.040064</td>\n",
       "      <td>lando vannata</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joselyne edwards</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>lucie pudilova</td>\n",
       "      <td>0.002104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tanner boser</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>ion curelaba</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bill algeo</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>0.012156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pedro munhoz</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>chris gutierrez</td>\n",
       "      <td>0.034578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clay guida</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>rafa garcia</td>\n",
       "      <td>0.001760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>azamat murzakanov</td>\n",
       "      <td>0.004760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>billy quarantillo</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arnold allen</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bruna brasil</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>denise gomes</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gillian robertson</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>piera rodriguez</td>\n",
       "      <td>0.020407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>brandon royval</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>matheus nicolau</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zak cummings</td>\n",
       "      <td>0.031649</td>\n",
       "      <td>ed herman</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FighterName  fighter_bet       OpponentName  opponent_bet\n",
       "0    daniel zellhuber     0.040064      lando vannata      0.000000\n",
       "1    joselyne edwards     0.000000     lucie pudilova      0.002104\n",
       "2        tanner boser     0.013220       ion curelaba      0.000000\n",
       "3          bill algeo     0.000000           tj brown      0.012156\n",
       "4        pedro munhoz     0.000000    chris gutierrez      0.034578\n",
       "5          clay guida     0.000000        rafa garcia      0.001760\n",
       "6       dustin jacoby     0.000000  azamat murzakanov      0.004760\n",
       "7   billy quarantillo     0.000000      edson barboza      0.000000\n",
       "8        arnold allen     0.013372       max holloway      0.000000\n",
       "9        bruna brasil     0.000000       denise gomes      0.000000\n",
       "10  gillian robertson     0.000000    piera rodriguez      0.020407\n",
       "11     brandon royval     0.005860    matheus nicolau      0.000000\n",
       "12       zak cummings     0.031649          ed herman      0.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_selection.metrics import MultiKellyPM\n",
    "\n",
    "pm = MultiKellyPM(aug_preds_df, max_bankroll_fraction=0.05,\n",
    "                  fighter_ml_col=\"DraftKings_fighter\",\n",
    "                    opponent_ml_col=\"DraftKings_opponent\",\n",
    "                  parse_ml=True)\n",
    "pw = pm.get_portfolio_weights().merge(preds_df[[\"FighterID_espn\", \"OpponentID_espn\", \"FighterName\", \"OpponentName\"]])\n",
    "pw[[\"FighterName\", \"fighter_bet\", \"OpponentName\", \"opponent_bet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['DraftKings_fighter', 'DraftKings_opponent'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/john/play/sports/EXPERIMENTS/2023-04-10_base_template.ipynb Cell 53\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/john/play/sports/EXPERIMENTS/2023-04-10_base_template.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m pw[[\u001b[39m\"\u001b[39;49m\u001b[39mFighterName\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfighter_bet\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mDraftKings_fighter\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mOpponentName\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mopponent_bet\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mDraftKings_opponent\u001b[39;49m\u001b[39m\"\u001b[39;49m]]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/john/play/sports/EXPERIMENTS/2023-04-10_base_template.ipynb#Y103sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m a[\u001b[39m\"\u001b[39m\u001b[39mfighter_bet\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\u001b[39m*\u001b[39ma[\u001b[39m\"\u001b[39m\u001b[39mfighter_bet\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/john/play/sports/EXPERIMENTS/2023-04-10_base_template.ipynb#Y103sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m a[\u001b[39m\"\u001b[39m\u001b[39mopponent_bet\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\u001b[39m*\u001b[39ma[\u001b[39m\"\u001b[39m\u001b[39mopponent_bet\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sports_pystan2/lib/python3.9/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sports_pystan2/lib/python3.9/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sports_pystan2/lib/python3.9/site-packages/pandas/core/indexes/base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['DraftKings_fighter', 'DraftKings_opponent'] not in index\""
     ]
    }
   ],
   "source": [
    "a = pw[[\"FighterName\", \"fighter_bet\", \"DraftKings_fighter\", \"OpponentName\", \"opponent_bet\", \"DraftKings_opponent\"]].copy()\n",
    "a[\"fighter_bet\"] = 100*a[\"fighter_bet\"]\n",
    "a[\"opponent_bet\"] = 100*a[\"opponent_bet\"]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sports_pystan2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a237f2fbfa4eeeaf420965c4b3f40ac3440be1ed8d868d43cc135fc4be38fee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
