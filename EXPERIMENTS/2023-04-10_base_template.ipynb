{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting some quick picks for 2023-04-08\n",
    "\n",
    "http://ufcstats.com/event-details/3dc3022232b79c7a\n",
    "\n",
    "https://www.bestfightodds.com/events/ufc-287-2760\n",
    "\n",
    "Unfortunately I forgot to run the full script prior to this, so it's a bit jank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/john/play/sports/') # add parent directory to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 248)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>FighterResult</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Rnd</th>\n",
       "      <th>Time</th>\n",
       "      <th>Event</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>TSL</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_weight</th>\n",
       "      <th>FighterID_espn_opp</th>\n",
       "      <th>n_career_fights_opp</th>\n",
       "      <th>n_ufc_fights_opp</th>\n",
       "      <th>t_since_first_fight_opp</th>\n",
       "      <th>t_since_prev_fight_opp</th>\n",
       "      <th>total_ufc_cage_time_opp</th>\n",
       "      <th>min_weight_opp</th>\n",
       "      <th>max_weight_opp</th>\n",
       "      <th>prev_weight_opp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>1991-09-26</td>\n",
       "      <td>L</td>\n",
       "      <td>TKO (Injury)</td>\n",
       "      <td>1</td>\n",
       "      <td>4:42</td>\n",
       "      <td>Desafio: Jiu-Jitsu vs. Luta Livre</td>\n",
       "      <td>2354059</td>\n",
       "      <td>2558095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2354059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>1991-09-26</td>\n",
       "      <td>W</td>\n",
       "      <td>TKO (Injury)</td>\n",
       "      <td>1</td>\n",
       "      <td>4:42</td>\n",
       "      <td>Desafio: Jiu-Jitsu vs. Luta Livre</td>\n",
       "      <td>2558095</td>\n",
       "      <td>2354059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2558095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>W</td>\n",
       "      <td>Submission (Rear Naked Choke)</td>\n",
       "      <td>1</td>\n",
       "      <td>7:03</td>\n",
       "      <td>Desafio: Gracie Vale Tudo</td>\n",
       "      <td>2501396</td>\n",
       "      <td>2354119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2501396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>L</td>\n",
       "      <td>Submission (Rear Naked Choke)</td>\n",
       "      <td>1</td>\n",
       "      <td>7:03</td>\n",
       "      <td>Desafio: Gracie Vale Tudo</td>\n",
       "      <td>2354119</td>\n",
       "      <td>2501396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2354119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993-08-29_2354132_3107994</td>\n",
       "      <td>1993-08-29</td>\n",
       "      <td>W</td>\n",
       "      <td>Submission (Strikes)</td>\n",
       "      <td>1</td>\n",
       "      <td>2:46</td>\n",
       "      <td>CP X CB: Capoeira vs. Chute Boxe</td>\n",
       "      <td>3107994</td>\n",
       "      <td>2354132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3107994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fight_id       Date FighterResult  \\\n",
       "0  1991-09-26_2354059_2558095 1991-09-26             L   \n",
       "1  1991-09-26_2354059_2558095 1991-09-26             W   \n",
       "2  1992-01-01_2354119_2501396 1992-01-01             W   \n",
       "3  1992-01-01_2354119_2501396 1992-01-01             L   \n",
       "4  1993-08-29_2354132_3107994 1993-08-29             W   \n",
       "\n",
       "                        Decision Rnd  Time                              Event  \\\n",
       "0                   TKO (Injury)   1  4:42  Desafio: Jiu-Jitsu vs. Luta Livre   \n",
       "1                   TKO (Injury)   1  4:42  Desafio: Jiu-Jitsu vs. Luta Livre   \n",
       "2  Submission (Rear Naked Choke)   1  7:03          Desafio: Gracie Vale Tudo   \n",
       "3  Submission (Rear Naked Choke)   1  7:03          Desafio: Gracie Vale Tudo   \n",
       "4           Submission (Strikes)   1  2:46   CP X CB: Capoeira vs. Chute Boxe   \n",
       "\n",
       "  OpponentID_espn FighterID_espn  TSL  ...  prev_weight  FighterID_espn_opp  \\\n",
       "0         2354059        2558095  NaN  ...          NaN             2354059   \n",
       "1         2558095        2354059  NaN  ...          NaN             2558095   \n",
       "2         2501396        2354119  NaN  ...          NaN             2501396   \n",
       "3         2354119        2501396  NaN  ...          NaN             2354119   \n",
       "4         3107994        2354132  NaN  ...          NaN             3107994   \n",
       "\n",
       "   n_career_fights_opp n_ufc_fights_opp  t_since_first_fight_opp  \\\n",
       "0                    0                0                        0   \n",
       "1                    0                0                        0   \n",
       "2                    0                0                        0   \n",
       "3                    0                0                        0   \n",
       "4                    0                0                        0   \n",
       "\n",
       "   t_since_prev_fight_opp  total_ufc_cage_time_opp  min_weight_opp  \\\n",
       "0                     NaN                      0.0           185.0   \n",
       "1                     NaN                      0.0             NaN   \n",
       "2                     NaN                      0.0           185.0   \n",
       "3                     NaN                      0.0           170.0   \n",
       "4                     NaN                      0.0             NaN   \n",
       "\n",
       "   max_weight_opp  prev_weight_opp  \n",
       "0           185.0              NaN  \n",
       "1             NaN              NaN  \n",
       "2           185.0              NaN  \n",
       "3           170.0              NaN  \n",
       "4             NaN              NaN  \n",
       "\n",
       "[5 rows x 248 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from db import base_db_interface\n",
    "\n",
    "raw_df = base_db_interface.read(\"bfo_espn_ufc_features\")\n",
    "for dt_col in [\"Date\", \"DOB\", \"DOB_opp\"]:\n",
    "    raw_df[dt_col] = pd.to_datetime(raw_df[dt_col])\n",
    "raw_df[[\"FighterOpen\", \"OpponentOpen\"]] = raw_df[[\"FighterOpen\", \"OpponentOpen\"]]\\\n",
    "    .astype(float)\n",
    "\n",
    "raw_df = raw_df.drop_duplicates(subset=[\"FighterID_espn\", \"OpponentID_espn\", \"fight_id\"])\n",
    "raw_df[\"FighterID_espn\"] = raw_df[\"FighterID_espn\"].fillna(\"unknown\")\n",
    "raw_df[\"OpponentID_espn\"] = raw_df[\"OpponentID_espn\"].fillna(\"unknown\")\n",
    "print(raw_df.shape)\n",
    "raw_df.head() # show the first 5 rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awful, Ugly, Stinky, No-Good Hack\n",
    "\n",
    "Necessary in order to get data for the upcoming fights. The join is very difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 17)\n",
      "(30, 19)\n",
      "(30, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>EventHref</th>\n",
       "      <th>Date</th>\n",
       "      <th>FighterID_bfo</th>\n",
       "      <th>OpponentID_bfo</th>\n",
       "      <th>FighterName</th>\n",
       "      <th>OpponentName</th>\n",
       "      <th>FighterOpen</th>\n",
       "      <th>OpponentOpen</th>\n",
       "      <th>FighterCloseLeft</th>\n",
       "      <th>...</th>\n",
       "      <th>BioName_opp</th>\n",
       "      <th>FighterID_espn_opp</th>\n",
       "      <th>Country_opp</th>\n",
       "      <th>WT Class_opp</th>\n",
       "      <th>Team_opp</th>\n",
       "      <th>Nickname_opp</th>\n",
       "      <th>ReachInches_opp</th>\n",
       "      <th>WeightPounds_opp</th>\n",
       "      <th>HeightInches_opp</th>\n",
       "      <th>DOB_opp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Aaron-Phillips-4905</td>\n",
       "      <td>Gaston-Bolanos-6991</td>\n",
       "      <td>aaron phillips</td>\n",
       "      <td>gaston bolanos</td>\n",
       "      <td>+140</td>\n",
       "      <td>-160</td>\n",
       "      <td>+150</td>\n",
       "      <td>...</td>\n",
       "      <td>gaston bolaños</td>\n",
       "      <td>4393818</td>\n",
       "      <td>USA</td>\n",
       "      <td>Bantamweight</td>\n",
       "      <td>Combat Sports Academy</td>\n",
       "      <td>The Dreamkiller</td>\n",
       "      <td>69.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1992-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Arnold-Allen-4218</td>\n",
       "      <td>Max-Holloway-3090</td>\n",
       "      <td>arnold allen</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>+125</td>\n",
       "      <td>-145</td>\n",
       "      <td>+145</td>\n",
       "      <td>...</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>2614933</td>\n",
       "      <td>USA</td>\n",
       "      <td>Featherweight</td>\n",
       "      <td>Gracie Technics</td>\n",
       "      <td>Blessed</td>\n",
       "      <td>69.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1991-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Azamat-Murzakanov-7264</td>\n",
       "      <td>Dustin-Jacoby-2939</td>\n",
       "      <td>azamat murzakanov</td>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>+170</td>\n",
       "      <td>-200</td>\n",
       "      <td>+125</td>\n",
       "      <td>...</td>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>2594871</td>\n",
       "      <td>USA</td>\n",
       "      <td>Light Heavyweight</td>\n",
       "      <td>FactoryX Muay Thai</td>\n",
       "      <td>The Hanyak</td>\n",
       "      <td>76.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1988-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Bill-Algeo-9171</td>\n",
       "      <td>Tj-Brown-10260</td>\n",
       "      <td>bill algeo</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>-139</td>\n",
       "      <td>+119</td>\n",
       "      <td>-210</td>\n",
       "      <td>...</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>4063667</td>\n",
       "      <td>USA</td>\n",
       "      <td>Featherweight</td>\n",
       "      <td>Westside Fight Team</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>72.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1990-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Billy-Quarantillo-4159</td>\n",
       "      <td>Edson-Barboza-2099</td>\n",
       "      <td>billy quarantillo</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>-155</td>\n",
       "      <td>+135</td>\n",
       "      <td>-190</td>\n",
       "      <td>...</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>2526299</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Featherweight</td>\n",
       "      <td>American Top Team</td>\n",
       "      <td>Junior</td>\n",
       "      <td>75.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1986-01-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Event  \\\n",
       "0  UFC Fight Night: Holloway vs. Allen   \n",
       "1  UFC Fight Night: Holloway vs. Allen   \n",
       "2  UFC Fight Night: Holloway vs. Allen   \n",
       "3  UFC Fight Night: Holloway vs. Allen   \n",
       "4  UFC Fight Night: Holloway vs. Allen   \n",
       "\n",
       "                                        EventHref       Date  \\\n",
       "0  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "1  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "2  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "3  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "4  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "\n",
       "            FighterID_bfo       OpponentID_bfo        FighterName  \\\n",
       "0     Aaron-Phillips-4905  Gaston-Bolanos-6991     aaron phillips   \n",
       "1       Arnold-Allen-4218    Max-Holloway-3090       arnold allen   \n",
       "2  Azamat-Murzakanov-7264   Dustin-Jacoby-2939  azamat murzakanov   \n",
       "3         Bill-Algeo-9171       Tj-Brown-10260         bill algeo   \n",
       "4  Billy-Quarantillo-4159   Edson-Barboza-2099  billy quarantillo   \n",
       "\n",
       "     OpponentName FighterOpen OpponentOpen FighterCloseLeft  ...  \\\n",
       "0  gaston bolanos        +140         -160             +150  ...   \n",
       "1    max holloway        +125         -145             +145  ...   \n",
       "2   dustin jacoby        +170         -200             +125  ...   \n",
       "3        tj brown        -139         +119             -210  ...   \n",
       "4   edson barboza        -155         +135             -190  ...   \n",
       "\n",
       "      BioName_opp FighterID_espn_opp Country_opp       WT Class_opp  \\\n",
       "0  gaston bolaños            4393818         USA       Bantamweight   \n",
       "1    max holloway            2614933         USA      Featherweight   \n",
       "2   dustin jacoby            2594871         USA  Light Heavyweight   \n",
       "3        tj brown            4063667         USA      Featherweight   \n",
       "4   edson barboza            2526299      Brazil      Featherweight   \n",
       "\n",
       "                Team_opp     Nickname_opp  ReachInches_opp WeightPounds_opp  \\\n",
       "0  Combat Sports Academy  The Dreamkiller             69.0            135.0   \n",
       "1        Gracie Technics          Blessed             69.0            146.0   \n",
       "2     FactoryX Muay Thai       The Hanyak             76.0            206.0   \n",
       "3    Westside Fight Team         Downtown             72.0            145.0   \n",
       "4      American Top Team           Junior             75.0            145.0   \n",
       "\n",
       "  HeightInches_opp    DOB_opp  \n",
       "0             67.0 1992-09-14  \n",
       "1             71.0 1991-12-04  \n",
       "2             75.0 1988-04-04  \n",
       "3             69.0 1990-05-22  \n",
       "4             71.0 1986-01-21  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wrangle.clean_espn_data import EspnDataCleaner\n",
    "\n",
    "# Get odds for upcoming fight\n",
    "bfo_df = base_db_interface.read(\"clean_fighter_odds_data\")\n",
    "bfo_df[\"Date\"] = pd.to_datetime(bfo_df[\"Date\"])\n",
    "bfo_to_espn_map = base_db_interface.read(\"bfo_to_espn_map\")\n",
    "upcoming_bfo_df = bfo_df.query(\"EventHref == \\\n",
    "                               '/events/ufc-fight-night-holloway-vs-allen-2796'\")\n",
    "upcoming_bfo_df = upcoming_bfo_df.rename(\n",
    "    columns={\"FighterID\": \"FighterID_bfo\", \"OpponentID\": \"OpponentID_bfo\"}\n",
    ")\n",
    "print(upcoming_bfo_df.shape)\n",
    "upcoming_bfo_df = upcoming_bfo_df.merge(\n",
    "    bfo_to_espn_map[[\"FighterID_bfo\", \"FighterID_espn\"]].drop_duplicates(),\n",
    "    on=[\"FighterID_bfo\"],\n",
    "    how=\"left\"\n",
    ").merge(\n",
    "    bfo_to_espn_map[[\"OpponentID_bfo\", \"OpponentID_espn\"]].drop_duplicates(),\n",
    "    on=[\"OpponentID_bfo\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(upcoming_bfo_df.shape)\n",
    "# Get bios for fighters in upcoming fight\n",
    "espn_dc = EspnDataCleaner()\n",
    "espn_dc._parse_bios()\n",
    "espn_dc.clean_bio_df\n",
    "bio_df = espn_dc.clean_bio_df.rename(columns={\n",
    "    \"FighterID\":\"FighterID_espn\", \"Name\": \"BioName\",\n",
    "})\n",
    "upcoming_bfo_df = upcoming_bfo_df.merge(\n",
    "    bio_df,\n",
    "    left_on=\"FighterID_espn\",\n",
    "    right_on=\"FighterID_espn\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_dropme\", \"\")\n",
    ").merge(\n",
    "    bio_df,\n",
    "    left_on=\"OpponentID_espn\",\n",
    "    right_on=\"FighterID_espn\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_opp\")\n",
    ")\n",
    "print(upcoming_bfo_df.shape)\n",
    "\n",
    "upcoming_bfo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 248) (133102, 250)\n",
      "shape of tonight's fight: (26, 250)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>FighterResult</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Rnd</th>\n",
       "      <th>Time</th>\n",
       "      <th>Event</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>TSL</th>\n",
       "      <th>...</th>\n",
       "      <th>n_career_fights_opp</th>\n",
       "      <th>n_ufc_fights_opp</th>\n",
       "      <th>t_since_first_fight_opp</th>\n",
       "      <th>t_since_prev_fight_opp</th>\n",
       "      <th>total_ufc_cage_time_opp</th>\n",
       "      <th>min_weight_opp</th>\n",
       "      <th>max_weight_opp</th>\n",
       "      <th>prev_weight_opp</th>\n",
       "      <th>BioName</th>\n",
       "      <th>BioName_opp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132984</th>\n",
       "      <td>2023-04-15_3949555_4863327</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3949555</td>\n",
       "      <td>4863327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>3990</td>\n",
       "      <td>357.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.0</td>\n",
       "      <td>daniel zellhuber</td>\n",
       "      <td>lando vannata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132985</th>\n",
       "      <td>2023-04-15_4040197_4397782</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4040197</td>\n",
       "      <td>4397782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>3347</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>joselyne edwards</td>\n",
       "      <td>lucie pudilova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132986</th>\n",
       "      <td>2023-04-15_3994033_4232775</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3994033</td>\n",
       "      <td>4232775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>4027</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2719.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205.0</td>\n",
       "      <td>tanner boser</td>\n",
       "      <td>ion cutelaba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132987</th>\n",
       "      <td>2023-04-15_4063667_4076472</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4063667</td>\n",
       "      <td>4076472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>3444</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1818.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>bill algeo</td>\n",
       "      <td>tj brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132988</th>\n",
       "      <td>2023-04-15_3045734_3961293</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3961293</td>\n",
       "      <td>3045734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>3591</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>pedro munhoz</td>\n",
       "      <td>chris gutierrez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fight_id       Date FighterResult Decision   Rnd  \\\n",
       "132984  2023-04-15_3949555_4863327 2023-04-15          None     None  None   \n",
       "132985  2023-04-15_4040197_4397782 2023-04-15          None     None  None   \n",
       "132986  2023-04-15_3994033_4232775 2023-04-15          None     None  None   \n",
       "132987  2023-04-15_4063667_4076472 2023-04-15          None     None  None   \n",
       "132988  2023-04-15_3045734_3961293 2023-04-15          None     None  None   \n",
       "\n",
       "        Time                                Event OpponentID_espn  \\\n",
       "132984  None  UFC Fight Night: Holloway vs. Allen         3949555   \n",
       "132985  None  UFC Fight Night: Holloway vs. Allen         4040197   \n",
       "132986  None  UFC Fight Night: Holloway vs. Allen         3994033   \n",
       "132987  None  UFC Fight Night: Holloway vs. Allen         4063667   \n",
       "132988  None  UFC Fight Night: Holloway vs. Allen         3961293   \n",
       "\n",
       "       FighterID_espn  TSL  ...  n_career_fights_opp  n_ufc_fights_opp  \\\n",
       "132984        4863327  NaN  ...                   20                12   \n",
       "132985        4397782  NaN  ...                   21                 8   \n",
       "132986        4232775  NaN  ...                   27                13   \n",
       "132987        4076472  NaN  ...                   26                 6   \n",
       "132988        3045734  NaN  ...                   24                 8   \n",
       "\n",
       "        t_since_first_fight_opp t_since_prev_fight_opp  \\\n",
       "132984                     3990                  357.0   \n",
       "132985                     3347                  238.0   \n",
       "132986                     4027                  147.0   \n",
       "132987                     3444                  126.0   \n",
       "132988                     3591                  154.0   \n",
       "\n",
       "        total_ufc_cage_time_opp  min_weight_opp  max_weight_opp  \\\n",
       "132984                   3089.0             NaN             NaN   \n",
       "132985                   2124.0             NaN             NaN   \n",
       "132986                   2719.0             NaN             NaN   \n",
       "132987                   1818.0             NaN             NaN   \n",
       "132988                   2294.0             NaN             NaN   \n",
       "\n",
       "        prev_weight_opp           BioName      BioName_opp  \n",
       "132984            155.0  daniel zellhuber    lando vannata  \n",
       "132985            135.0  joselyne edwards   lucie pudilova  \n",
       "132986            205.0      tanner boser     ion cutelaba  \n",
       "132987            145.0        bill algeo         tj brown  \n",
       "132988            135.0      pedro munhoz  chris gutierrez  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't like this line, \n",
    "df = raw_df.merge(\n",
    "    upcoming_bfo_df,\n",
    "    on=[\"FighterID_espn\", \"OpponentID_espn\", \"Date\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_dropme\")\n",
    ")\n",
    "drop_cols = df.columns[df.columns.str.endswith(\"_dropme\")]\n",
    "for drop_col in drop_cols:\n",
    "    col = drop_col[:-len(\"_dropme\")]\n",
    "    df[col] = df[col].fillna(df[drop_col])\n",
    "df = df.drop(columns=drop_cols)\n",
    "print(raw_df.shape, df.shape)\n",
    "foo = df.query(\"EventHref == '/events/ufc-fight-night-holloway-vs-allen-2796'\")\n",
    "print(\"shape of tonight's fight:\", foo.shape)\n",
    "foo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# OKAY PCA HAPPENS HERE. Just do everything in-sample for now. \n",
    "stat_cols = [\n",
    "    'TSL', 'TSA', 'SSL',\n",
    "    'SSA', #'TSL-TSA', \n",
    "    'KD', #'%BODY', '%HEAD', '%LEG', \n",
    "    'SCBL',\n",
    "    'SCBA', 'SCHL', 'SCHA', 'SCLL', 'SCLA', 'RV', 'TDL', 'TDA', 'TDS',\n",
    "    # 'TK ACC', 'SR', # I don't believe in ratio features in PCA, \n",
    "    # # because of the possibility of division by zero and heteroskedasticity\n",
    "    'SGBL', 'SGBA', 'SGHL', 'SGHA', 'SGLL', 'SGLA', 'AD', 'ADTB',\n",
    "    'ADHG', 'ADTM', 'ADTS', 'SM', 'SDBL', 'SDBA', 'SDHL',\n",
    "    'SDHA', 'SDLL', 'SDLA',\n",
    "    #'time_seconds',\n",
    "    # 'TD_fails', #'submission_rate',\n",
    "    'TD_fail', # formerly 'TD_fails'\n",
    "    'SDL', 'SCL', # formerly 'distance_strikes_landed', 'clinch_strikes_landed',\n",
    "    #'KD_power', \n",
    "    'SGL', # formerly 'ground_strikes_landed'\n",
    "]\n",
    "df[[\"KD\", \"KD_opp\"]] = df[[\"KD\", \"KD_opp\"]].astype(float) \n",
    "# convert from string to float. rather annoying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_diff_df = {\n",
    "    \"FighterID_espn\": df[\"FighterID_espn\"],\n",
    "    \"OpponentID_espn\": df[\"OpponentID_espn\"],\n",
    "    \"Date\": df[\"Date\"],\n",
    "    \"gender\": df[\"gender\"],\n",
    "    \"fight_id\": df[\"fight_id\"],\n",
    "}\n",
    "diff_cols = [col+\"_diff\" for col in stat_cols]\n",
    "for col, diff_col in zip(stat_cols, diff_cols):\n",
    "    stat_diff_df[diff_col] = (\n",
    "        np.sqrt(df[col]) - np.sqrt(df[col+\"_opp\"])\n",
    "    )\n",
    "# stat_diff_df = pd.DataFrame(stat_diff_df).dropna(subset=diff_cols).reset_index()\n",
    "stat_diff_df = pd.DataFrame(stat_diff_df).reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elo estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pca = 14\n",
    "# n_pca = 1 # just for testing\n",
    "bin_elo_alpha = 0.45\n",
    "acc_elo_alpha = 0.45\n",
    "pca_elo_alpha = 0.45\n",
    "real_elo_alpha = 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 813.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 816.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 818.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 815.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 818.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 821.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 820.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 818.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 811.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 817.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 821.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 818.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 822.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 823.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>fight_id</th>\n",
       "      <th>PC_0</th>\n",
       "      <th>pred_elo_PC_0</th>\n",
       "      <th>fighter_elo_PC_0</th>\n",
       "      <th>opponent_elo_PC_0</th>\n",
       "      <th>updated_fighter_elo_PC_0</th>\n",
       "      <th>updated_opponent_elo_PC_0</th>\n",
       "      <th>PC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>fighter_elo_PC_12</th>\n",
       "      <th>opponent_elo_PC_12</th>\n",
       "      <th>updated_fighter_elo_PC_12</th>\n",
       "      <th>updated_opponent_elo_PC_12</th>\n",
       "      <th>PC_13</th>\n",
       "      <th>pred_elo_PC_13</th>\n",
       "      <th>fighter_elo_PC_13</th>\n",
       "      <th>opponent_elo_PC_13</th>\n",
       "      <th>updated_fighter_elo_PC_13</th>\n",
       "      <th>updated_opponent_elo_PC_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2558095</td>\n",
       "      <td>2354059</td>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2354059</td>\n",
       "      <td>2558095</td>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2354119</td>\n",
       "      <td>2501396</td>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2501396</td>\n",
       "      <td>2354119</td>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2354132</td>\n",
       "      <td>3107994</td>\n",
       "      <td>1993-08-29_2354132_3107994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133097</th>\n",
       "      <td>2512976</td>\n",
       "      <td>3146944</td>\n",
       "      <td>2023-05-13_2512976_3146944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.619807</td>\n",
       "      <td>-0.109493</td>\n",
       "      <td>0.510314</td>\n",
       "      <td>-0.109493</td>\n",
       "      <td>0.510314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314846</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>-0.314846</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>0.639975</td>\n",
       "      <td>0.317220</td>\n",
       "      <td>0.639975</td>\n",
       "      <td>0.317220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133098</th>\n",
       "      <td>2516131</td>\n",
       "      <td>2951361</td>\n",
       "      <td>2023-06-10_2516131_2951361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.443042</td>\n",
       "      <td>1.176898</td>\n",
       "      <td>0.733856</td>\n",
       "      <td>1.176898</td>\n",
       "      <td>0.733856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610091</td>\n",
       "      <td>0.349301</td>\n",
       "      <td>-0.260790</td>\n",
       "      <td>0.349301</td>\n",
       "      <td>-0.260790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133099</th>\n",
       "      <td>2951361</td>\n",
       "      <td>2516131</td>\n",
       "      <td>2023-06-10_2516131_2951361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.443042</td>\n",
       "      <td>0.733856</td>\n",
       "      <td>1.176898</td>\n",
       "      <td>0.733856</td>\n",
       "      <td>1.176898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.610091</td>\n",
       "      <td>-0.260790</td>\n",
       "      <td>0.349301</td>\n",
       "      <td>-0.260790</td>\n",
       "      <td>0.349301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133100</th>\n",
       "      <td>2560746</td>\n",
       "      <td>3027545</td>\n",
       "      <td>2023-07-08_2560746_3027545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.415478</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.393125</td>\n",
       "      <td>-0.492688</td>\n",
       "      <td>-0.393125</td>\n",
       "      <td>-0.492688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.131069</td>\n",
       "      <td>0.107960</td>\n",
       "      <td>0.239029</td>\n",
       "      <td>0.107960</td>\n",
       "      <td>0.239029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133101</th>\n",
       "      <td>3027545</td>\n",
       "      <td>2560746</td>\n",
       "      <td>2023-07-08_2560746_3027545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.415478</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492688</td>\n",
       "      <td>-0.393125</td>\n",
       "      <td>-0.492688</td>\n",
       "      <td>-0.393125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.131069</td>\n",
       "      <td>0.239029</td>\n",
       "      <td>0.107960</td>\n",
       "      <td>0.239029</td>\n",
       "      <td>0.107960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133102 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FighterID_espn OpponentID_espn                    fight_id  PC_0  \\\n",
       "0             2558095         2354059  1991-09-26_2354059_2558095   NaN   \n",
       "1             2354059         2558095  1991-09-26_2354059_2558095   NaN   \n",
       "2             2354119         2501396  1992-01-01_2354119_2501396   NaN   \n",
       "3             2501396         2354119  1992-01-01_2354119_2501396   NaN   \n",
       "4             2354132         3107994  1993-08-29_2354132_3107994   NaN   \n",
       "...               ...             ...                         ...   ...   \n",
       "133097        2512976         3146944  2023-05-13_2512976_3146944   NaN   \n",
       "133098        2516131         2951361  2023-06-10_2516131_2951361   NaN   \n",
       "133099        2951361         2516131  2023-06-10_2516131_2951361   NaN   \n",
       "133100        2560746         3027545  2023-07-08_2560746_3027545   NaN   \n",
       "133101        3027545         2560746  2023-07-08_2560746_3027545   NaN   \n",
       "\n",
       "        pred_elo_PC_0  fighter_elo_PC_0  opponent_elo_PC_0  \\\n",
       "0            0.000000          0.000000           0.000000   \n",
       "1            0.000000          0.000000           0.000000   \n",
       "2            0.000000          0.000000           0.000000   \n",
       "3            0.000000          0.000000           0.000000   \n",
       "4            0.000000          0.000000           0.000000   \n",
       "...               ...               ...                ...   \n",
       "133097      -0.619807         -0.109493           0.510314   \n",
       "133098       0.443042          1.176898           0.733856   \n",
       "133099      -0.443042          0.733856           1.176898   \n",
       "133100      -0.415478          0.355464           0.770942   \n",
       "133101       0.415478          0.770942           0.355464   \n",
       "\n",
       "        updated_fighter_elo_PC_0  updated_opponent_elo_PC_0  PC_1  ...  \\\n",
       "0                       0.000000                   0.000000   NaN  ...   \n",
       "1                       0.000000                   0.000000   NaN  ...   \n",
       "2                       0.000000                   0.000000   NaN  ...   \n",
       "3                       0.000000                   0.000000   NaN  ...   \n",
       "4                       0.000000                   0.000000   NaN  ...   \n",
       "...                          ...                        ...   ...  ...   \n",
       "133097                 -0.109493                   0.510314   NaN  ...   \n",
       "133098                  1.176898                   0.733856   NaN  ...   \n",
       "133099                  0.733856                   1.176898   NaN  ...   \n",
       "133100                  0.355464                   0.770942   NaN  ...   \n",
       "133101                  0.770942                   0.355464   NaN  ...   \n",
       "\n",
       "        fighter_elo_PC_12  opponent_elo_PC_12  updated_fighter_elo_PC_12  \\\n",
       "0                0.000000            0.000000                   0.000000   \n",
       "1                0.000000            0.000000                   0.000000   \n",
       "2                0.000000            0.000000                   0.000000   \n",
       "3                0.000000            0.000000                   0.000000   \n",
       "4                0.000000            0.000000                   0.000000   \n",
       "...                   ...                 ...                        ...   \n",
       "133097          -0.314846            0.003451                  -0.314846   \n",
       "133098           0.127486            0.230649                   0.127486   \n",
       "133099           0.230649            0.127486                   0.230649   \n",
       "133100          -0.393125           -0.492688                  -0.393125   \n",
       "133101          -0.492688           -0.393125                  -0.492688   \n",
       "\n",
       "        updated_opponent_elo_PC_12  PC_13  pred_elo_PC_13  fighter_elo_PC_13  \\\n",
       "0                         0.000000    NaN        0.000000           0.000000   \n",
       "1                         0.000000    NaN        0.000000           0.000000   \n",
       "2                         0.000000    NaN        0.000000           0.000000   \n",
       "3                         0.000000    NaN        0.000000           0.000000   \n",
       "4                         0.000000    NaN        0.000000           0.000000   \n",
       "...                            ...    ...             ...                ...   \n",
       "133097                    0.003451    NaN        0.322755           0.639975   \n",
       "133098                    0.230649    NaN        0.610091           0.349301   \n",
       "133099                    0.127486    NaN       -0.610091          -0.260790   \n",
       "133100                   -0.492688    NaN       -0.131069           0.107960   \n",
       "133101                   -0.393125    NaN        0.131069           0.239029   \n",
       "\n",
       "        opponent_elo_PC_13  updated_fighter_elo_PC_13  \\\n",
       "0                 0.000000                   0.000000   \n",
       "1                 0.000000                   0.000000   \n",
       "2                 0.000000                   0.000000   \n",
       "3                 0.000000                   0.000000   \n",
       "4                 0.000000                   0.000000   \n",
       "...                    ...                        ...   \n",
       "133097            0.317220                   0.639975   \n",
       "133098           -0.260790                   0.349301   \n",
       "133099            0.349301                  -0.260790   \n",
       "133100            0.239029                   0.107960   \n",
       "133101            0.107960                   0.239029   \n",
       "\n",
       "        updated_opponent_elo_PC_13  \n",
       "0                         0.000000  \n",
       "1                         0.000000  \n",
       "2                         0.000000  \n",
       "3                         0.000000  \n",
       "4                         0.000000  \n",
       "...                            ...  \n",
       "133097                    0.317220  \n",
       "133098                   -0.260790  \n",
       "133099                    0.349301  \n",
       "133100                    0.239029  \n",
       "133101                    0.107960  \n",
       "\n",
       "[133102 rows x 87 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.mma_features import PcaEloWrapper, BinaryEloWrapper\n",
    "\n",
    "pca_ew = PcaEloWrapper(\n",
    "    n_pca=n_pca, target_cols=diff_cols, alpha=pca_elo_alpha,\n",
    "    conditional_var_col=None, # for consistency\n",
    ")\n",
    "pca_elo_feat_df = pca_ew.fit_transform_all(stat_diff_df)\n",
    "pca_elo_feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FighterID_espn                133102\n",
       " OpponentID_espn               133102\n",
       " fight_id                      133102\n",
       " PC_0                            7928\n",
       " pred_elo_PC_0                 133102\n",
       "                                ...  \n",
       " pred_elo_PC_13                133102\n",
       " fighter_elo_PC_13             133102\n",
       " opponent_elo_PC_13            133102\n",
       " updated_fighter_elo_PC_13     133102\n",
       " updated_opponent_elo_PC_13    133102\n",
       " Length: 87, dtype: int64,\n",
       " index              133102\n",
       " FighterID_espn     133102\n",
       " OpponentID_espn    133102\n",
       " Date               133102\n",
       " gender             133102\n",
       " fight_id           133102\n",
       " TSL_diff            18156\n",
       " TSA_diff            18156\n",
       " SSL_diff            18156\n",
       " SSA_diff            18156\n",
       " KD_diff             18156\n",
       " SCBL_diff            7942\n",
       " SCBA_diff            7942\n",
       " SCHL_diff            7942\n",
       " SCHA_diff            7942\n",
       " SCLL_diff            7942\n",
       " SCLA_diff            7942\n",
       " RV_diff             18156\n",
       " TDL_diff            18156\n",
       " TDA_diff            18156\n",
       " TDS_diff             7942\n",
       " SGBL_diff            7942\n",
       " SGBA_diff            7942\n",
       " SGHL_diff            7942\n",
       " SGHA_diff            7942\n",
       " SGLL_diff            7942\n",
       " SGLA_diff            7942\n",
       " AD_diff              7942\n",
       " ADTB_diff            7942\n",
       " ADHG_diff            7942\n",
       " ADTM_diff            7942\n",
       " ADTS_diff            7942\n",
       " SM_diff             18156\n",
       " SDBL_diff            7942\n",
       " SDBA_diff            7942\n",
       " SDHL_diff            7942\n",
       " SDHA_diff            7942\n",
       " SDLL_diff            7942\n",
       " SDLA_diff            7942\n",
       " TD_fail_diff        18156\n",
       " SDL_diff            18142\n",
       " SCL_diff            18142\n",
       " SGL_diff            18142\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_elo_feat_df.notnull().sum(), stat_diff_df.notnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some targets for Elo estimators along the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    65262\n",
       "1.0    65262\n",
       "NaN     2578\n",
       "Name: win_target, dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"win_target\"] = df[\"FighterResult\"].replace({\"W\":1, \"L\":0, \"D\":np.nan})\n",
    "df[\"win_target\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    45420\n",
       "1.0    45420\n",
       "NaN    42262\n",
       "Name: win_target_finish, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have to parse the decision column to get the detailed result\n",
    "def parse_decision(s):\n",
    "    if (s.startswith(\"submission\") or \n",
    "        s.startswith(\"sumission\") or\n",
    "        s.startswith(\"technical submission\")\n",
    "    ):\n",
    "        return \"submission\"\n",
    "    if (s.startswith(\"tko\") or \n",
    "        s.startswith(\"ko\") or\n",
    "        (s == 'could not continue')\n",
    "    ):\n",
    "        return \"tko_ko\"\n",
    "    if \"decision\" in s:\n",
    "        return \"decision\"\n",
    "    return \"other\"\n",
    "\n",
    "temp_decision = df[\"Decision\"].fillna(\"-\").str.lower().str.strip()\n",
    "decision_clean = temp_decision.apply(parse_decision)\n",
    "result_sign = df[\"FighterResult\"].map({\"W\": 1, \"L\":-1, \"D\": 0})\n",
    "decision_score = decision_clean.map({\"tko_ko\":2, \"submission\":2, \n",
    "                                                    \"decision\":1, \"other\":0})\n",
    "df[\"ordinal_fighter_result\"] = result_sign * decision_score\n",
    "submission_score = decision_clean.map({\"submission\":1, \"decision\":0, \n",
    "                                            \"other\":0, \"tko_ko\":0})\n",
    "tko_ko_score = decision_clean.map({\"submission\":0, \"decision\":0, \n",
    "                                            \"other\":0, \"tko_ko\":1})\n",
    "decision_score = decision_clean.map({\"submission\":0, \"decision\":1, \n",
    "                                            \"other\":0, \"tko_ko\":0})\n",
    "finish_score = decision_clean.map({\"submission\":1, \"decision\":0, \n",
    "                                            \"other\":0, \"tko_ko\":1})\n",
    "df[\"submission_fighter_result\"] = result_sign * submission_score\n",
    "df[\"tko_ko_fighter_result\"] = result_sign * tko_ko_score\n",
    "df[\"decision_fighter_result\"] = result_sign * decision_score\n",
    "df[\"finish_fighter_result\"] = result_sign * finish_score\n",
    "\n",
    "df[\"win_target_finish\"] = df[\"win_target\"] * decision_clean.map({\n",
    "    \"submission\":1, \"tko_ko\":1,\n",
    "    \"decision\":np.nan, \"other\":np.nan, \n",
    "})\n",
    "df[\"win_target_finish\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9891662033628346"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_fight_time(row):\n",
    "    if not np.isnan(row[\"time_dur\"]):\n",
    "        return row[\"time_dur\"]\n",
    "    if row[\"Rnd\"] == \"-\":\n",
    "        return np.nan\n",
    "    if row[\"Time\"] == \"-\":\n",
    "        # assuming 5 minute rounds\n",
    "        # fill in something for now\n",
    "        return int(row[\"Rnd\"]) * 5 * 60\n",
    "    n_rounds = row[\"Rnd\"].strip()\n",
    "    min, sec = row[\"Time\"].strip().split(\":\")\n",
    "    if n_rounds == \"-\":\n",
    "        return np.nan\n",
    "    n_rounds = int(n_rounds) - 1\n",
    "    if (min == \"-\") | (sec == \"-\"):\n",
    "        return np.nan\n",
    "    min = int(min)\n",
    "    sec = int(sec)\n",
    "    # assuming 5 minute rounds\n",
    "    return (n_rounds * 5 * 60) + min * 60 + sec\n",
    "    \n",
    "df[\"Rnd\"] = df[\"Rnd\"].fillna(\"-\")\n",
    "df[\"Time\"] = df[\"Time\"].fillna(\"-\")\n",
    "df[\"fight_time\"] = df.apply(parse_fight_time, axis=1)\n",
    "df[\"fight_time\"].notnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = (-1)**df[\"win_target\"]\n",
    "# restrict btw 1 and 25 minutes (length of a title fight)\n",
    "# short fight times -> big outliers\n",
    "clipped_time_dur = df[\"fight_time\"].clip(60, (5*5*60))\n",
    "df[\"signed_inverse_fight_time\"] = y / clipped_time_dur\n",
    "df[\"signed_inverse_sqrt_fight_time\"] = y / np.sqrt(clipped_time_dur)\n",
    "df[\"signed_inverse_log_fight_time\"] = y / np.log(clipped_time_dur)\n",
    "\n",
    "df[\"signed_inverse_fight_time\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for signed_inverse_fight_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 781.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 9)\n",
      "getting elo features for win_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 807.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for win_target_finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:06<00:00, 807.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>fight_id</th>\n",
       "      <th>win_target</th>\n",
       "      <th>pred_elo_win_target</th>\n",
       "      <th>fighter_elo_win_target</th>\n",
       "      <th>opponent_elo_win_target</th>\n",
       "      <th>updated_fighter_elo_win_target</th>\n",
       "      <th>updated_opponent_elo_win_target</th>\n",
       "      <th>win_target_finish</th>\n",
       "      <th>pred_elo_win_target_finish</th>\n",
       "      <th>fighter_elo_win_target_finish</th>\n",
       "      <th>opponent_elo_win_target_finish</th>\n",
       "      <th>updated_fighter_elo_win_target_finish</th>\n",
       "      <th>updated_opponent_elo_win_target_finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2558095</td>\n",
       "      <td>2354059</td>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2354059</td>\n",
       "      <td>2558095</td>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2354119</td>\n",
       "      <td>2501396</td>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2501396</td>\n",
       "      <td>2354119</td>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2354132</td>\n",
       "      <td>3107994</td>\n",
       "      <td>1993-08-29_2354132_3107994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FighterID_espn OpponentID_espn                    fight_id  win_target  \\\n",
       "0        2558095         2354059  1991-09-26_2354059_2558095         0.0   \n",
       "1        2354059         2558095  1991-09-26_2354059_2558095         1.0   \n",
       "2        2354119         2501396  1992-01-01_2354119_2501396         1.0   \n",
       "3        2501396         2354119  1992-01-01_2354119_2501396         0.0   \n",
       "4        2354132         3107994  1993-08-29_2354132_3107994         1.0   \n",
       "\n",
       "   pred_elo_win_target  fighter_elo_win_target  opponent_elo_win_target  \\\n",
       "0                  0.5                     0.0                      0.0   \n",
       "1                  0.5                     0.0                      0.0   \n",
       "2                  0.5                     0.0                      0.0   \n",
       "3                  0.5                     0.0                      0.0   \n",
       "4                  0.5                     0.0                      0.0   \n",
       "\n",
       "   updated_fighter_elo_win_target  updated_opponent_elo_win_target  \\\n",
       "0                         -0.1125                           0.1125   \n",
       "1                          0.1125                          -0.1125   \n",
       "2                          0.1125                          -0.1125   \n",
       "3                         -0.1125                           0.1125   \n",
       "4                          0.1125                          -0.1125   \n",
       "\n",
       "   win_target_finish  pred_elo_win_target_finish  \\\n",
       "0                0.0                         0.5   \n",
       "1                1.0                         0.5   \n",
       "2                1.0                         0.5   \n",
       "3                0.0                         0.5   \n",
       "4                1.0                         0.5   \n",
       "\n",
       "   fighter_elo_win_target_finish  opponent_elo_win_target_finish  \\\n",
       "0                            0.0                             0.0   \n",
       "1                            0.0                             0.0   \n",
       "2                            0.0                             0.0   \n",
       "3                            0.0                             0.0   \n",
       "4                            0.0                             0.0   \n",
       "\n",
       "   updated_fighter_elo_win_target_finish  \\\n",
       "0                                -0.1125   \n",
       "1                                 0.1125   \n",
       "2                                 0.1125   \n",
       "3                                -0.1125   \n",
       "4                                 0.1125   \n",
       "\n",
       "   updated_opponent_elo_win_target_finish  \n",
       "0                                  0.1125  \n",
       "1                                 -0.1125  \n",
       "2                                 -0.1125  \n",
       "3                                  0.1125  \n",
       "4                                 -0.1125  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.mma_features import RealEloWrapper\n",
    "\n",
    "real_elo_target_cols = [\n",
    "#     \"fighter_result_time_left\", \n",
    "#     \"ml_logit_mvmt\",\n",
    "    # \"ordinal_fighter_result\",\n",
    "    # \"submission_fighter_result\",\n",
    "    # \"tko_ko_fighter_result\",\n",
    "    # \"decision_fighter_result\",\n",
    "    # \"finish_fighter_result\",\n",
    "    \"signed_inverse_fight_time\",\n",
    "    # \"signed_inverse_sqrt_fight_time\",\n",
    "    # \"signed_inverse_log_fight_time\",\n",
    "]\n",
    "diff_elo_target_cols = [\n",
    "]\n",
    "\n",
    "binary_elo_target_cols = [\"win_target\", \"win_target_finish\"]\n",
    "\n",
    "elo_alphas = {\n",
    "    col: real_elo_alpha \n",
    "    for col in (real_elo_target_cols + diff_elo_target_cols)\n",
    "}\n",
    "# elo_alphas[\"ml_logit_mvmt\"] = 0.225\n",
    "\n",
    "real_ew = RealEloWrapper(elo_alphas=elo_alphas)\n",
    "real_elo_feat_df = real_ew.fit_transform_all(df)\n",
    "print(real_elo_feat_df.shape)\n",
    "real_elo_feat_df.head()\n",
    "\n",
    "elo_alphas = {\n",
    "    col: bin_elo_alpha for col in binary_elo_target_cols\n",
    "}\n",
    "bin_ew = BinaryEloWrapper(elo_alphas=elo_alphas)\n",
    "bin_elo_feat_df = bin_ew.fit_transform_all(df)\n",
    "print(bin_elo_feat_df.shape)\n",
    "bin_elo_feat_df.head()\n",
    "# feat_ml_df[\"log_height_diff\"] = np.log(feat_ml_df[\"imp_height\"]) - np.log(feat_ml_df[\"imp_height_opp\"])\n",
    "# feat_ml_df[\"log_age_diff\"] = np.log(feat_ml_df[\"age\"]) - np.log(feat_ml_df[\"age_opp\"])\n",
    "# feat_ml_df[\"log_reach_diff\"] = np.log(feat_ml_df[\"imp_reach\"]) - np.log(feat_ml_df[\"imp_reach_opp\"])\n",
    "# feat_ml_df[\"log_reach_diff\"] = feat_ml_df[\"log_reach_diff\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 360)\n"
     ]
    }
   ],
   "source": [
    "elo_feat_df = df.merge(\n",
    "    pca_elo_feat_df, \n",
    "    how=\"left\", \n",
    "    on=[\"fight_id\", \"FighterID_espn\", \"OpponentID_espn\"],\n",
    ").merge(\n",
    "    real_elo_feat_df.drop(columns=real_elo_target_cols),\n",
    "    how=\"left\",\n",
    "    on=[\"fight_id\", \"FighterID_espn\", \"OpponentID_espn\"],\n",
    ").merge(\n",
    "    bin_elo_feat_df.drop(columns=binary_elo_target_cols),\n",
    "    how=\"left\",\n",
    "    on=[\"fight_id\", \"FighterID_espn\", \"OpponentID_espn\"],\n",
    ")\n",
    "print(elo_feat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fight_id                                  133102\n",
       "Date                                      133102\n",
       "FighterResult                             132984\n",
       "Decision                                  132984\n",
       "Rnd                                       133102\n",
       "                                           ...  \n",
       "pred_elo_win_target_finish                133102\n",
       "fighter_elo_win_target_finish             133102\n",
       "opponent_elo_win_target_finish            133102\n",
       "updated_fighter_elo_win_target_finish     133102\n",
       "updated_opponent_elo_win_target_finish    133102\n",
       "Length: 360, dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elo_feat_df.notnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpler features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 20) (133102, 360)\n"
     ]
    }
   ],
   "source": [
    "from model.mma_elo_model import unknown_fighter_id\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_simple_features(df):\n",
    "    # simple things that i needn't get from the fighter stats page\n",
    "    # eg number of fights, t_since_last_fight\n",
    "    assert (df[\"fight_id\"].value_counts() == 2).all()\n",
    "    df = df.assign(\n",
    "        is_ufc=df[\"Event\"].fillna(\"\").str.contains(\"UFC\"),\n",
    "        Date=pd.to_datetime(df[\"Date\"]),\n",
    "    )\n",
    "    feat_df = df.sort_values(\"Date\").copy()[[\n",
    "        \"fight_id\", \"FighterID_espn\", \"OpponentID_espn\", \"Date\", \"is_ufc\"\n",
    "    ]]\n",
    "    # Rolling features over fighter_careers\n",
    "    # because the data is doubled, we can simply group by the fighter id\n",
    "    feat_df[\"dummy\"] = 1\n",
    "    # total fights\n",
    "    feat_df[\"total_fights\"] = feat_df.groupby(\"FighterID_espn\")[\"dummy\"].cumsum()\n",
    "    feat_df[\"total_fights_opp\"] = feat_df.groupby(\"OpponentID_espn\")[\"dummy\"].cumsum()\n",
    "    # total ufc fights\n",
    "    feat_df[\"total_ufc_fights\"] = feat_df.groupby(\"FighterID_espn\")[\"is_ufc\"].cumsum()\n",
    "    feat_df[\"total_ufc_fights_opp\"] = feat_df.groupby(\"OpponentID_espn\")[\"is_ufc\"].cumsum()\n",
    "    # time since last fight\n",
    "    feat_df[\"t_since_last_fight\"] = feat_df.groupby(\"FighterID_espn\")[\"Date\"].diff().dt.days\n",
    "    feat_df[\"t_since_last_fight_opp\"] = feat_df.groupby(\"OpponentID_espn\")[\"Date\"].diff().dt.days\n",
    "    fill_val = 2*365 # arbitrarily say 2 years\n",
    "    feat_df[\"t_since_last_fight\"] = np.maximum(fill_val, feat_df[\"t_since_last_fight\"].fillna(fill_val))   \n",
    "    feat_df[\"t_since_last_fight_opp\"] = np.maximum(fill_val, feat_df[\"t_since_last_fight_opp\"].fillna(fill_val)) \n",
    "    # time since first fight\n",
    "    feat_df[\"t_since_first_fight\"] = (feat_df[\"Date\"] - feat_df.groupby(\"FighterID_espn\")[\"Date\"].transform(\"min\")).dt.days\n",
    "    feat_df[\"t_since_first_fight_opp\"] = (feat_df[\"Date\"] - feat_df.groupby(\"OpponentID_espn\")[\"Date\"].transform(\"min\")).dt.days\n",
    "    # compute diffs\n",
    "    feat_df[\"t_since_last_fight_diff\"] = (feat_df[\"t_since_last_fight\"] - \n",
    "                                            feat_df[\"t_since_last_fight_opp\"])\n",
    "    feat_df[\"t_since_last_fight_log_diff\"] = (np.log(feat_df[\"t_since_last_fight\"]) - \n",
    "                                                np.log(feat_df[\"t_since_last_fight_opp\"]))\n",
    "    feat_df[\"total_fights_diff\"] = (feat_df[\"total_fights\"] - \n",
    "                                    feat_df[\"total_fights_opp\"])\n",
    "    feat_df[\"total_fights_sqrt_diff\"] = (np.sqrt(feat_df[\"total_fights\"]) - \n",
    "                                        np.sqrt(feat_df[\"total_fights_opp\"]))\n",
    "    feat_df[\"total_ufc_fights_diff\"] = (feat_df[\"total_ufc_fights\"] - \n",
    "                                        feat_df[\"total_ufc_fights_opp\"])\n",
    "    feat_df[\"total_ufc_fights_sqrt_diff\"] = (np.sqrt(feat_df[\"total_ufc_fights\"]) - \n",
    "                                                np.sqrt(feat_df[\"total_ufc_fights_opp\"]))\n",
    "    return feat_df\n",
    "\n",
    "simple_feat_df = get_simple_features(elo_feat_df)\n",
    "print(simple_feat_df.shape, elo_feat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fight_id', 'FighterID_espn', 'OpponentID_espn', 'Date', 'is_ufc',\n",
       "       'dummy', 'total_fights', 'total_fights_opp', 'total_ufc_fights',\n",
       "       'total_ufc_fights_opp', 't_since_last_fight', 't_since_last_fight_opp',\n",
       "       't_since_first_fight', 't_since_first_fight_opp',\n",
       "       't_since_last_fight_diff', 't_since_last_fight_log_diff',\n",
       "       'total_fights_diff', 'total_fights_sqrt_diff', 'total_ufc_fights_diff',\n",
       "       'total_ufc_fights_sqrt_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_feat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pred_elo_PC_0',\n",
       " 'pred_elo_PC_1',\n",
       " 'pred_elo_PC_2',\n",
       " 'pred_elo_PC_3',\n",
       " 'pred_elo_PC_4',\n",
       " 'pred_elo_PC_5',\n",
       " 'pred_elo_PC_6',\n",
       " 'pred_elo_PC_7',\n",
       " 'pred_elo_PC_8',\n",
       " 'pred_elo_PC_9',\n",
       " 'pred_elo_PC_10',\n",
       " 'pred_elo_PC_11',\n",
       " 'pred_elo_PC_12',\n",
       " 'pred_elo_PC_13',\n",
       " 'pred_elo_signed_inverse_fight_time',\n",
       " 'pred_elo_win_target',\n",
       " 'pred_elo_win_target_finish',\n",
       " 'age_diff',\n",
       " 'log_reach_diff',\n",
       " 'weight_diff',\n",
       " 'height_diff',\n",
       " 'log_t_since_prev_fight_diff',\n",
       " 'log_t_since_first_fight_diff',\n",
       " 'total_fights_diff']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_ml_df = elo_feat_df.merge(\n",
    "    simple_feat_df, \n",
    "    how=\"left\",\n",
    "    on=[\"FighterID_espn\", \"OpponentID_espn\", \"Date\"],\n",
    "    suffixes=(\"_legacy\", \"\"),\n",
    ")\n",
    "\n",
    "feat_ml_df[\"age_diff\"] = (feat_ml_df[\"DOB\"] - feat_ml_df[\"DOB_opp\"]).dt.days / 365\n",
    "feat_ml_df[\"age_diff\"] = feat_ml_df[\"age_diff\"].fillna(0)\n",
    "\n",
    "feat_ml_df[\"log_reach_diff\"] = (\n",
    "    np.log(feat_ml_df[\"ReachInches\"]) - np.log(feat_ml_df[\"ReachInches_opp\"])\n",
    ").fillna(0)\n",
    "feat_ml_df[\"weight_diff\"] = (\n",
    "    feat_ml_df[\"min_weight\"] - feat_ml_df[\"min_weight_opp\"]\n",
    ").fillna(0)\n",
    "feat_ml_df[\"height_diff\"] = (\n",
    "    feat_ml_df[\"HeightInches\"] - feat_ml_df[\"HeightInches_opp\"]\n",
    ").fillna(0)\n",
    "\n",
    "feat_ml_df[\"t_since_first_fight_diff\"] = (\n",
    "    feat_ml_df[\"t_since_first_fight\"] - feat_ml_df[\"t_since_first_fight_opp\"]\n",
    ").fillna(0)\n",
    "feat_ml_df[\"log_t_since_first_fight_diff\"] = (\n",
    "    np.log(1 + feat_ml_df[\"t_since_first_fight\"]) - \n",
    "    np.log(1 + feat_ml_df[\"t_since_first_fight_opp\"])\n",
    ").fillna(0)\n",
    "\n",
    "feat_ml_df[\"log_t_since_prev_fight_diff\"] = (\n",
    "    np.log(1 + feat_ml_df[\"t_since_prev_fight\"]) -\n",
    "    np.log(1 + feat_ml_df[\"t_since_prev_fight_opp\"])\n",
    ").fillna(0)\n",
    "\n",
    "real_elo_target_cols = [\n",
    "#     \"fighter_result_time_left\", \n",
    "#     \"ml_logit_mvmt\",\n",
    "#     \"ordinal_fighter_result\",\n",
    "#     \"submission_fighter_result\",\n",
    "#     \"tko_ko_fighter_result\",\n",
    "#     \"decision_fighter_result\",\n",
    "    \"signed_inverse_fight_time\",\n",
    "    # \"finish_fighter_result\",\n",
    "    # *[col for col in stat_pca_df.columns \n",
    "    #   if col not in [\"FighterID_espn\", \"OpponentID_espn\", \"Date\"]],\n",
    "]\n",
    "\n",
    "feat_cols = [\n",
    "    *[f\"pred_elo_PC_{i}\" for i in range(n_pca)],\n",
    "\n",
    "    *[\"pred_elo_\"+c for c in [*diff_elo_target_cols, \n",
    "                               *real_elo_target_cols, \n",
    "                               *binary_elo_target_cols]],\n",
    "    \n",
    "    # \"t_since_last_fight_log_diff\", \n",
    "#     \"fights_per_day_diff\",\n",
    "#     \"t_since_last_fight_diff\",\n",
    "#     \"total_fights_sqrt_diff\", \n",
    "#     \"total_ufc_fights_diff\",\n",
    "    \n",
    "    \"age_diff\", \n",
    "#     \"log_age_diff\",\n",
    "#     \"reach_diff\", \n",
    "    \"log_reach_diff\",\n",
    "    \"weight_diff\", \n",
    "#     \"log_weight_diff\",\n",
    "    \"height_diff\",\n",
    "#     \"log_height_diff\",\n",
    "#     \"ml_logit_mvmt\",\n",
    "    \"log_t_since_prev_fight_diff\",\n",
    "    \"log_t_since_first_fight_diff\",\n",
    "    \"total_fights_diff\",\n",
    "#     \"quad_log_t_since_first_fight_diff\",\n",
    "]\n",
    "\n",
    "# new_feat_cols = [*feat_cols, \"ml_logit\"]\n",
    "feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pred_elo_PC_0', 'pred_elo_PC_1', 'pred_elo_PC_2', 'pred_elo_PC_3',\n",
       "       'pred_elo_PC_4', 'pred_elo_PC_5', 'pred_elo_PC_6', 'pred_elo_PC_7',\n",
       "       'pred_elo_PC_8', 'pred_elo_PC_9', 'pred_elo_PC_10', 'pred_elo_PC_11',\n",
       "       'pred_elo_PC_12', 'pred_elo_PC_13',\n",
       "       'pred_elo_signed_inverse_fight_time', 'pred_elo_win_target',\n",
       "       'pred_elo_win_target_finish'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_ml_df.columns[feat_ml_df.columns.str.contains(\"pred_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_elo_PC_0                         133102\n",
       "pred_elo_PC_1                         133102\n",
       "pred_elo_PC_2                         133102\n",
       "pred_elo_PC_3                         133102\n",
       "pred_elo_PC_4                         133102\n",
       "pred_elo_PC_5                         133102\n",
       "pred_elo_PC_6                         133102\n",
       "pred_elo_PC_7                         133102\n",
       "pred_elo_PC_8                         133102\n",
       "pred_elo_PC_9                         133102\n",
       "pred_elo_PC_10                        133102\n",
       "pred_elo_PC_11                        133102\n",
       "pred_elo_PC_12                        133102\n",
       "pred_elo_PC_13                        133102\n",
       "pred_elo_signed_inverse_fight_time    133102\n",
       "pred_elo_win_target                   133102\n",
       "pred_elo_win_target_finish            133102\n",
       "age_diff                              133102\n",
       "log_reach_diff                        133102\n",
       "weight_diff                           133102\n",
       "height_diff                           133102\n",
       "log_t_since_prev_fight_diff           133102\n",
       "log_t_since_first_fight_diff          133102\n",
       "total_fights_diff                     133102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see how much data we have for each feature\n",
    "feat_ml_df[feat_cols].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_elo_PC_0                         66551\n",
      "pred_elo_PC_1                         66551\n",
      "pred_elo_PC_2                         66551\n",
      "pred_elo_PC_3                         66551\n",
      "pred_elo_PC_4                         66551\n",
      "pred_elo_PC_5                         66551\n",
      "pred_elo_PC_6                         66551\n",
      "pred_elo_PC_7                         66551\n",
      "pred_elo_PC_8                         66551\n",
      "pred_elo_PC_9                         66551\n",
      "pred_elo_PC_10                        66551\n",
      "pred_elo_PC_11                        66551\n",
      "pred_elo_PC_12                        66551\n",
      "pred_elo_PC_13                        66551\n",
      "pred_elo_signed_inverse_fight_time    66551\n",
      "pred_elo_win_target                   66551\n",
      "pred_elo_win_target_finish            66551\n",
      "age_diff                              66551\n",
      "log_reach_diff                        66551\n",
      "weight_diff                           66551\n",
      "height_diff                           66551\n",
      "log_t_since_prev_fight_diff           66551\n",
      "log_t_since_first_fight_diff          66551\n",
      "total_fights_diff                     66551\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(66551, 384)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_ml_df = feat_ml_df.drop_duplicates(subset=[\"fight_id\"])\n",
    "print(feat_ml_df[feat_cols].notnull().sum())\n",
    "feat_ml_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation - opening line\n",
    "\n",
    "Note that this isn't realistic. Don't get your hopes up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fighter_implied_col = \"p_fighter_open_implied\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.mma_log_reg_stan import SimpleSymmetricModel\n",
    "\n",
    "mod = SimpleSymmetricModel(\n",
    "    feat_cols=feat_cols, target_col=\"win_target\", \n",
    "    p_fighter_implied_col=p_fighter_implied_col,\n",
    "    beta_prior_std=1.0, mcmc=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on date range: 2007-07-07 2020-12-31\n",
      "Initial log joint probability = -19407.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5882.87    0.00754549       1.91117           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5882.87   0.000398029     0.0889822           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-01-16\n",
      "Initial log joint probability = -18313.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5890.81    0.00316872      0.967578           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5890.81   0.000202928     0.0665365           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-01-20\n",
      "Initial log joint probability = -27456.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5898.85    0.00183448      0.338488      0.9155      0.9155       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5898.85   0.000172556     0.0641254           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-01-23\n",
      "Initial log joint probability = -21252.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -5906.8    0.00102141      0.311015           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -5906.8   0.000240033     0.0638593           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-01-30\n",
      "Initial log joint probability = -21373.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5914.68    0.00792539       2.11586           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5914.68    0.00021338       0.14974      0.8892      0.8892       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-05\n",
      "Initial log joint probability = -15924.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5915.27    0.00436811       1.23533           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5915.27   0.000295762      0.107714      0.9992      0.9992       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-06\n",
      "Initial log joint probability = -25354\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5924.54    0.00463689       2.75869           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -5924.54   9.64295e-05     0.0642623           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-12\n",
      "Initial log joint probability = -21978.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5929.08   0.000316076      0.483694      0.7426      0.7426       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5929.08   0.000123506      0.110874           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-13\n",
      "Initial log joint probability = -18214.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5934.04     0.0043757        2.3969           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -5934.04   7.75365e-05     0.0681173      0.8208      0.8208       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-19\n",
      "Initial log joint probability = -21506.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5936.78   0.000192329      0.303689           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -5936.78   0.000338194     0.0655958           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-20\n",
      "Initial log joint probability = -17713.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5946.42   0.000371032       0.66624      0.6618      0.6618       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5946.42   0.000136056     0.0318982           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-23\n",
      "Initial log joint probability = -20239.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5946.46    0.00359035      0.946423           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5946.46   0.000293049      0.150773      0.8637      0.8637       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-26\n",
      "Initial log joint probability = -18056.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5947.33    0.00461433       2.76353      0.4613      0.4613       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -5947.32   0.000194158     0.0405637           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-27\n",
      "Initial log joint probability = -27934.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5953.07    0.00167435       1.11892           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5953.07   0.000126356     0.0476939           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-05\n",
      "Initial log joint probability = -22019\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5953.67    0.00220713      0.877189           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5953.67   0.000226944     0.0749513      0.9586      0.9586       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-06\n",
      "Initial log joint probability = -29044.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5964.34     0.0011501       1.16068      0.6515      0.6515       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5964.34   8.19175e-05      0.103462           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-11\n",
      "Initial log joint probability = -17137.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5965.26    0.00123378      0.669974           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5965.26   0.000354896     0.0415661           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-12\n",
      "Initial log joint probability = -18552.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5967.21    0.00150142       2.70975      0.6296      0.6296       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -5967.2   0.000573427      0.109441           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-13\n",
      "Initial log joint probability = -17445.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5973.79   0.000726785       0.32239      0.4409           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5973.79   0.000171147     0.0357681           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-18\n",
      "Initial log joint probability = -20424.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5977.89    0.00160851      0.499517           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -5977.89   0.000199698       0.10834      0.5032       0.985       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-19\n",
      "Initial log joint probability = -22168.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5988.03    0.00127867       0.93072      0.9644      0.9644       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5988.03      0.000271      0.114597           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-20\n",
      "Initial log joint probability = -20848.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6000.21    0.00067872      0.677589      0.9745      0.9745       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6000.21   8.84208e-05     0.0903152           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-26\n",
      "Initial log joint probability = -21797.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6002.65    0.00290678       1.04734           1           1       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6002.65   0.000153273      0.137582           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-27\n",
      "Initial log joint probability = -21917.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6009.14   0.000549254      0.504857           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6009.14   0.000278043     0.0581243           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-01\n",
      "Initial log joint probability = -24847.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6013.8     0.0104234       9.20304      0.6206      0.6206       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6013.79   0.000274629      0.210702           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-02\n",
      "Initial log joint probability = -27481.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6021.53    0.00111066      0.325648           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6021.53   0.000460164      0.108808      0.5159           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-07\n",
      "Initial log joint probability = -18658.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -6024    0.00934694       2.22341           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22         -6024   0.000235197      0.127717           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-09\n",
      "Initial log joint probability = -19482.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6030.52    0.00463701       2.15861      0.4233      0.9824       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6030.52   0.000462425      0.126901      0.6638      0.6638       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-10\n",
      "Initial log joint probability = -23356.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6039.07    0.00476568       1.02776           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6039.07   0.000123211      0.124332      0.9142      0.9142       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-14\n",
      "Initial log joint probability = -18019.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6039.7    0.00299256        2.4821           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6039.69   0.000971825      0.129497           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-16\n",
      "Initial log joint probability = -18421.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6049.82    0.00196168       2.34373           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6049.82   0.000192589      0.145553           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-17\n",
      "Initial log joint probability = -24563.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6056.85    0.00782851       1.33228           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6056.85   0.000305091       0.13794           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-21\n",
      "Initial log joint probability = -23244.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6057.56   0.000825177       2.22559      0.6534      0.6534       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6057.56   0.000535803     0.0928726           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-23\n",
      "Initial log joint probability = -24186.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6071.06     0.0044028       2.95222           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6071.06   0.000351176       0.04361           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-24\n",
      "Initial log joint probability = -16013.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6081.62   0.000179584      0.360646      0.8264      0.8264       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6081.62    0.00018197      0.095045           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-28\n",
      "Initial log joint probability = -26721.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6085.28     0.0090456       16.1602      0.5771      0.5771       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      25      -6085.24   0.000836917      0.104547           1           1       30   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-29\n",
      "Initial log joint probability = -16707.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6088.43   0.000422711      0.261828           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6088.43   0.000413185     0.0788597           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-30\n",
      "Initial log joint probability = -20512\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6090.99      0.010321       4.31511           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      26      -6090.99   0.000679892      0.103559           1           1       29   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-01\n",
      "Initial log joint probability = -22645.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      18      -6098.59   0.000403349       0.19114      0.9991      0.9991       20   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-06\n",
      "Initial log joint probability = -18457.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6105.58     0.0356511       6.03508           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6105.56     0.0004526      0.113104           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-07\n",
      "Initial log joint probability = -26132.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6114.1    0.00451601      0.191722           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -6114.1   0.000256315      0.106954           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-08\n",
      "Initial log joint probability = -24272\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6121.57   0.000586272       0.31412           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6121.57   9.57919e-05     0.0768353      0.8389      0.8389       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-14\n",
      "Initial log joint probability = -17273.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6123.47   0.000309262      0.544615           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6123.47   6.80912e-05     0.0558351       0.451      0.9588       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-15\n",
      "Initial log joint probability = -21422.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6129.66   0.000405027      0.913577      0.7709      0.7709       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6129.66   0.000134456     0.0388614           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-21\n",
      "Initial log joint probability = -34619.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -6145    0.00380304       1.59372           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22         -6145   7.17266e-05     0.0896638      0.8204      0.8204       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-22\n",
      "Initial log joint probability = -19162\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6152.82    0.00656411      0.565015           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6152.82   0.000182446      0.168834      0.4468      0.9484       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-28\n",
      "Initial log joint probability = -25232.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6154.04   0.000268404       0.12613      0.8799      0.8799       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-29\n",
      "Initial log joint probability = -20614.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6155.52   0.000466245      0.492606           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6155.52    7.8697e-05     0.0645255           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-04\n",
      "Initial log joint probability = -19024.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6159.45    0.00140964       1.88915      0.9553      0.9553       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6159.45   0.000106286      0.104109           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-05\n",
      "Initial log joint probability = -19761.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6170.82    0.00223432      0.981339           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6170.82   0.000233252     0.0739763      0.9854      0.9854       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-10\n",
      "Initial log joint probability = -19605.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6175.87   0.000316552      0.312583      0.9103      0.9103       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6175.87      0.000212      0.109502           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-11\n",
      "Initial log joint probability = -23047.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6182.87    0.00291359       1.71249      0.9725      0.9725       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6182.87    0.00023976      0.103607           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-12\n",
      "Initial log joint probability = -29009.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6192.35   0.000759298      0.372926           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6192.35   0.000413797      0.121112           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-17\n",
      "Initial log joint probability = -20357\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6199.92   0.000987324       1.12017      0.8736      0.8736       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6199.92   0.000158261     0.0522567           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-18\n",
      "Initial log joint probability = -18587\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6201.93   0.000154517      0.399825      0.9194      0.9194       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6201.93    0.00012352     0.0455682           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-19\n",
      "Initial log joint probability = -17912.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6213.81    0.00201345      0.577627           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6213.81   0.000123249     0.0342263      0.8956      0.8956       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-24\n",
      "Initial log joint probability = -19632.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6218.04     0.0109131       1.74144      0.4513      0.4513       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6218.03   6.16002e-05       0.04704      0.2628      0.9008       30   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-25\n",
      "Initial log joint probability = -22325.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6234.04     0.0111443       4.14372           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6234.04   0.000362519     0.0747601           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-26\n",
      "Initial log joint probability = -19269.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6246.66   0.000229222      0.755472      0.5453      0.5453       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6246.66   0.000200174      0.128713           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-02\n",
      "Initial log joint probability = -26296.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      14      -6249.96   0.000224716     0.0546489           1           1       16   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-03\n",
      "Initial log joint probability = -25831.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6250.6    0.00086019      0.254664      0.9966      0.9966       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20       -6250.6   9.00786e-05      0.138843           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-04\n",
      "Initial log joint probability = -19102.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6250.83   0.000415759      0.209719       0.729       0.729       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6250.83   0.000119065     0.0742677      0.8557      0.8557       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-10\n",
      "Initial log joint probability = -20416.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6256.88     0.0026302      0.926878           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6256.87   0.000180534      0.143584      0.4525           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-16\n",
      "Initial log joint probability = -17632.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6265.88   0.000439916       0.88434           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6265.88   0.000127949     0.0826724           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-17\n",
      "Initial log joint probability = -23349.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6273.31    0.00363975       3.68481      0.9969      0.9969       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6273.31   0.000406596      0.167364           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-18\n",
      "Initial log joint probability = -22213.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6275.06   0.000356111       0.52015      0.6568      0.6568       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6275.06   0.000298811      0.136296           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-24\n",
      "Initial log joint probability = -22382.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6286.34    0.00317993       5.55192      0.5672      0.5672       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6286.34   0.000128185      0.143348           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-25\n",
      "Initial log joint probability = -18768.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6287.85    0.00241106       2.33624      0.6291      0.6291       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6287.85   0.000258949      0.142459           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-30\n",
      "Initial log joint probability = -26533.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6293.71    0.00105529       1.97026      0.8622      0.8622       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23       -6293.7   0.000430054     0.0953232      0.9555      0.9555       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-31\n",
      "Initial log joint probability = -25197.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6305.05    0.00113014      0.728821           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6305.05   0.000421252      0.123564           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-01\n",
      "Initial log joint probability = -22305.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6306.39    0.00356012      0.200558           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-06\n",
      "Initial log joint probability = -20261.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6309.88    0.00309926       1.44579      0.9027      0.9027       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6309.87   0.000704213     0.0791962           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-07\n",
      "Initial log joint probability = -21476.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6316.79    0.00146166        1.9626      0.9165      0.9165       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6316.79   0.000271999      0.116854           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-13\n",
      "Initial log joint probability = -21024.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6323.5    0.00842624       1.80093           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -6323.5   0.000179601      0.118637      0.8776      0.8776       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-14\n",
      "Initial log joint probability = -21021.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6326.82    0.00480611       1.17386           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6326.82   0.000151833     0.0813913           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-19\n",
      "Initial log joint probability = -18695.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6329.25   0.000648517      0.461264      0.9978      0.9978       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6329.25   0.000244152      0.180625      0.7266      0.7266       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-20\n",
      "Initial log joint probability = -16541\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6333.67    0.00125767      0.203882      0.8549      0.8549       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6333.67   0.000348684     0.0544184           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-21\n",
      "Initial log joint probability = -17622.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6342.1   0.000296033      0.511585      0.4956      0.4956       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20       -6342.1   0.000477839     0.0976673           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-27\n",
      "Initial log joint probability = -19422.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6358.54    0.00116903       1.05192       0.947       0.947       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6358.54   0.000208095      0.123177           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-28\n",
      "Initial log joint probability = -24477.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6366.71    0.00121803      0.531199           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6366.71   0.000186348      0.090845           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-29\n",
      "Initial log joint probability = -25777.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6366.85      0.030517       1.70653      0.9534      0.9534       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6366.85   0.000154061      0.140697      0.6598      0.6598       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-31\n",
      "Initial log joint probability = -24825.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6368.85   0.000993856      0.379052           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6368.85   0.000292306     0.0760075      0.9774      0.9774       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-04\n",
      "Initial log joint probability = -18118.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6378.58   0.000685032        1.3084      0.7986      0.7986       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6378.58    0.00102847     0.0667381           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-05\n",
      "Initial log joint probability = -22472.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6381.1     0.0013066      0.838802           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -6381.1   0.000249119     0.0392873           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-07\n",
      "Initial log joint probability = -19308.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6385.29    0.00541502       1.11497           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6385.29   0.000334274     0.0988535           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-11\n",
      "Initial log joint probability = -21126.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6391.26    0.00364536       1.06686           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6391.26   6.26911e-05     0.0642297      0.3801      0.9596       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-14\n",
      "Initial log joint probability = -20429.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6393.85    0.00398344      0.815618           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6393.85   7.78388e-05     0.0510785      0.4305      0.9838       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-16\n",
      "Initial log joint probability = -20726.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6395.01   0.000297939       0.61622           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6395.01   0.000561866     0.0943407           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-17\n",
      "Initial log joint probability = -19593.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6397.33   0.000423083      0.753964      0.6841      0.6841       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6397.33   0.000250952       0.18248           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-18\n",
      "Initial log joint probability = -21357.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6413.68     0.0028334       2.03248           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6413.68   0.000254825      0.154501      0.7514      0.7514       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-21\n",
      "Initial log joint probability = -26778\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6416.72     0.0213309      0.664228           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6416.72    0.00017738      0.127642           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-24\n",
      "Initial log joint probability = -32751.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6418.33    0.00457257      0.919267      0.8041      0.8041       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6418.33   0.000148416      0.110518           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-25\n",
      "Initial log joint probability = -19221.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6427.93     0.0117569       2.53513           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6427.93    0.00083341      0.070073           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-28\n",
      "Initial log joint probability = -26368.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6430.93    0.00395459       1.51184           1           1       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6430.93   0.000525259     0.0628084           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-30\n",
      "Initial log joint probability = -20501.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6435.54    0.00127469      0.595464       0.912       0.912       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6435.54   4.68571e-05     0.0812148      0.6443      0.6443       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-01\n",
      "Initial log joint probability = -20824.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6443.49    0.00107003       1.10377      0.8722      0.8722       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6443.49   0.000159736     0.0628392           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-02\n",
      "Initial log joint probability = -22274.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6452.89   0.000735328      0.430177           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6452.89   0.000693329      0.103516           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-05\n",
      "Initial log joint probability = -23755.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6456.01    0.00334988       2.53094           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6456.01   0.000114847      0.105101      0.3957      0.9773       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-09\n",
      "Initial log joint probability = -24239.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6461.26    0.00273197       1.06407           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6461.26   0.000368066      0.066805      0.8166      0.8166       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-12\n",
      "Initial log joint probability = -20736\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6462.64   0.000999772       1.20825       0.786       0.786       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6462.64   0.000156966     0.0762408           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-16\n",
      "Initial log joint probability = -27412.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6478.33    0.00683918       3.79471      0.7347      0.7347       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6478.33   0.000718131      0.129963           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-17\n",
      "Initial log joint probability = -20563.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6480.74    0.00347437         1.077           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6480.74   0.000126871      0.111589      0.9343      0.9343       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-19\n",
      "Initial log joint probability = -30387.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -6484   0.000754237      0.209647           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20         -6484   0.000119251      0.159331           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-22\n",
      "Initial log joint probability = -21183.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6486.46    0.00251759      0.446306           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6486.46   0.000100492      0.184031      0.8467      0.8467       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-23\n",
      "Initial log joint probability = -20230.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6507.04     0.0250715       10.6977           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6507.01   7.43718e-05      0.181168      0.7047      0.7047       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-26\n",
      "Initial log joint probability = -23702.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6507.4    0.00453529       1.58196           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -6507.4   0.000568884      0.116493           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-27\n",
      "Initial log joint probability = -29291.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6514.2   0.000392017      0.610144      0.9669      0.9669       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -6514.2   0.000179033     0.0998513           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-29\n",
      "Initial log joint probability = -19427.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6518.55     0.0496337       5.64952           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6518.54    0.00242726      0.195859           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-30\n",
      "Initial log joint probability = -21188.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6528.08    0.00151804      0.640435           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6528.08   0.000265257      0.160964           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-02\n",
      "Initial log joint probability = -19784.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6531.73     0.0021535       1.31493           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6531.73   0.000211242      0.175023           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-05\n",
      "Initial log joint probability = -25519.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6539.15   0.000890824      0.163834      0.8658      0.8658       20   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-06\n",
      "Initial log joint probability = -24141.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6549.95    0.00524926        2.4023           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6549.94   0.000157608      0.102034           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-07\n",
      "Initial log joint probability = -22360.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6550.49    0.00205317       2.82222      0.7404      0.7404       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6550.49   9.43374e-05      0.110581      0.7873      0.7873       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-12\n",
      "Initial log joint probability = -20705.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6554.79     0.0221864       2.76471           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6554.78   0.000125018       0.03148           1           1       29   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-13\n",
      "Initial log joint probability = -27769.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6561.76     0.0417923       4.15196           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6561.75   0.000210585     0.0352017      0.9488      0.9488       29   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-14\n",
      "Initial log joint probability = -21783.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6567.25    0.00411173       3.27758           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6567.25   0.000120334     0.0499172           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-19\n",
      "Initial log joint probability = -23789.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6571.46    0.00496811       1.86016           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6571.46   0.000124022     0.0990207           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-20\n",
      "Initial log joint probability = -21495.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6578.01     0.0335071       2.35361           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      25      -6578.01   0.000425777      0.203947           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-21\n",
      "Initial log joint probability = -17557.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6579.89    0.00235175       2.55818      0.4879           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6579.89   0.000107001      0.141595           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-27\n",
      "Initial log joint probability = -23948\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6580.24       0.11624       4.57107           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6580.23   0.000183974     0.0926818           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-03\n",
      "Initial log joint probability = -23042.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6588.24     0.0590802       4.19964           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6588.24   0.000307816      0.112831           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-04\n",
      "Initial log joint probability = -27836.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -6598    0.00526571       2.54973      0.9744      0.9744       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23         -6598   0.000148107      0.127128      0.9695      0.9695       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-10\n",
      "Initial log joint probability = -22938.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6606.56    0.00106923      0.439638      0.8516      0.8516       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6606.56   0.000172215      0.156269      0.8197      0.8197       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-11\n",
      "Initial log joint probability = -22097\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6622.06    0.00876536       4.63481           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6622.05   0.000300646     0.0486293           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-17\n",
      "Initial log joint probability = -24981.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6625.93   0.000261028      0.573243      0.7756      0.7756       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6625.93   0.000129982      0.136457           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-18\n",
      "Initial log joint probability = -19671.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6637.29    0.00909204        1.3031      0.9715      0.9715       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6637.29     0.0010251     0.0483212           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-19\n",
      "Initial log joint probability = -17988.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6638.44    0.00221435       1.36302           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6638.44   8.86965e-05     0.0363794           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-30\n",
      "Initial log joint probability = -20191.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -6639    0.00114574       1.36259      0.9652      0.9652       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22         -6639   0.000200441     0.0832655           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-12\n",
      "Initial log joint probability = -26987.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6642.23    0.00247482       1.64905           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6642.23   0.000100655      0.160884      0.6527      0.6527       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-14\n",
      "Initial log joint probability = -24260.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6644.75    0.00241138       1.18645           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6644.75   9.03254e-05     0.0603052      0.3008      0.9776       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-15\n",
      "Initial log joint probability = -29143.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6655.61    0.00823347       5.60216      0.9944      0.9944       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24       -6655.6   0.000145068     0.0995801           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-21\n",
      "Initial log joint probability = -27609.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6660.12     0.0222947       3.90571           1           1       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6660.12    0.00013144        0.0501           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-22\n",
      "Initial log joint probability = -31049.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6668.15    0.00363477        1.8559           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6668.15   0.000545401      0.130066           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-28\n",
      "Initial log joint probability = -20299.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6674.43    0.00103387       1.07235           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6674.43   0.000250273       0.17517           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-29\n",
      "Initial log joint probability = -28643.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6682.32    0.00183039        1.5429      0.5228           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6682.32   0.000135628     0.0521459           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-03\n",
      "Initial log joint probability = -23026.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6683.25    0.00245537       4.21114      0.5522      0.5522       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6683.25   4.81273e-05     0.0333204      0.3052      0.9701       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-04\n",
      "Initial log joint probability = -25869.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6685.78   0.000528147      0.203151           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6685.78   0.000149664     0.0819461           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-05\n",
      "Initial log joint probability = -19228.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6690.23   0.000553987       1.01239           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6690.23   0.000225571      0.228859           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-06\n",
      "Initial log joint probability = -23917.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6693.68     0.0088256      0.808731           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6693.68   0.000187306     0.0797857           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-11\n",
      "Initial log joint probability = -24546.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6696.82     0.0107193       2.37082           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6696.81   0.000197244       0.10818           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-12\n",
      "Initial log joint probability = -24601.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6704.82    0.00132614      0.368148       0.933       0.933       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6704.82   0.000271861      0.124239           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-18\n",
      "Initial log joint probability = -25900.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6707.7   0.000913403       2.38668       0.582       0.582       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6707.69   0.000250772      0.071057           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-19\n",
      "Initial log joint probability = -27898.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6721.57    0.00202739      0.213732           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6721.57   0.000222639     0.0948137           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-23\n",
      "Initial log joint probability = -24592.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6721.76    0.00611526       3.67643      0.4613      0.4613       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6721.76   9.43782e-05      0.030212           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-25\n",
      "Initial log joint probability = -28450.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6731.96   0.000347199      0.761395           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6731.96   0.000615752      0.137274           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-26\n",
      "Initial log joint probability = -23582.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6745.12    0.00330609       1.59077           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6745.12   0.000133546     0.0837094           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-27\n",
      "Initial log joint probability = -23846.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6745.49    0.00384725       2.32887           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6745.49   0.000448526      0.157039      0.3658      0.9763       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-04\n",
      "Initial log joint probability = -20605\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6751.2    0.00585158       6.60499      0.5296      0.5296       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6751.19   0.000442177      0.145428           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-05\n",
      "Initial log joint probability = -17411.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6761.62   0.000204754      0.154565      0.7563      0.7563       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-09\n",
      "Initial log joint probability = -21047\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6764.77     0.0253265        2.0468           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6764.76    0.00038988     0.0802213           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-11\n",
      "Initial log joint probability = -19048.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6773.96    0.00625845        3.8272           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6773.95    0.00013774       0.14552        0.67        0.67       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-12\n",
      "Initial log joint probability = -26483.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6786.38   0.000478018      0.853631      0.8837      0.8837       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6786.38   0.000507157      0.153206           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-17\n",
      "Initial log joint probability = -21915.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6788.89   0.000774232       0.29535           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6788.89     0.0001795     0.0623315           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-18\n",
      "Initial log joint probability = -22452.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6794.88      0.027474       12.7595           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6794.86   0.000882945     0.0852702           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-19\n",
      "Initial log joint probability = -27854.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6804.63    0.00928827       1.86578           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6804.63   0.000192376     0.0868083      0.9957      0.9957       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-25\n",
      "Initial log joint probability = -27127.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6813.74     0.0147229       1.97685           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6813.74   0.000126482      0.204523      0.6631      0.6631       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-26\n",
      "Initial log joint probability = -19985.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6821.63   0.000751835       1.75987      0.5988      0.5988       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6821.63   6.77061e-05     0.0511995      0.8022      0.8022       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-27\n",
      "Initial log joint probability = -21990.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6824.93     0.0017395      0.543292           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6824.93   0.000293229      0.137031           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-01\n",
      "Initial log joint probability = -25904.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6830.61    0.00251217        1.8344           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6830.61    0.00035516      0.161707           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-02\n",
      "Initial log joint probability = -27414\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6839.84   0.000723024      0.511035      0.9854      0.9854       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6839.84   0.000177115     0.0578122           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-08\n",
      "Initial log joint probability = -22793.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6842.17    0.00776519       1.34633      0.7657      0.7657       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6842.17    0.00216141      0.175055      0.9646      0.9646       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-09\n",
      "Initial log joint probability = -23704.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6850.53   0.000344696      0.695861      0.6797      0.6797       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6850.53   0.000125975      0.091352           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-15\n",
      "Initial log joint probability = -25331.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6859.78    0.00203039       2.62121      0.7859      0.7859       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6859.78   0.000209318      0.190696           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-16\n",
      "Initial log joint probability = -22391.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6868.46    0.00124297      0.551856           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6868.46   7.22996e-05     0.0691652      0.3831       0.946       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-20\n",
      "Initial log joint probability = -19463.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6874.99   0.000565962      0.444695           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6874.99   0.000450059      0.109225           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-22\n",
      "Initial log joint probability = -24074.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6876.9    0.00146467      0.207737           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20       -6876.9   9.01379e-05      0.122503           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-23\n",
      "Initial log joint probability = -19709.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6894.57    0.00378367       1.04302      0.7646      0.7646       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6894.57   0.000265068     0.0671058           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-24\n",
      "Initial log joint probability = -24830.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      15      -6895.83   0.000233053      0.210137      0.7664      0.7664       18   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-28\n",
      "Initial log joint probability = -36128.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6899.57   0.000664127      0.829883      0.9045      0.9045       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6899.57   0.000391041      0.184042           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-30\n",
      "Initial log joint probability = -31729.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6905.84    0.00240904        1.2252      0.8583      0.8583       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6905.84   0.000180272      0.119743           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-06\n",
      "Initial log joint probability = -27850.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6925.18    0.00219852       1.85391           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6925.17   0.000164638      0.162284      0.6515      0.6515       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-07\n",
      "Initial log joint probability = -25237.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6937.23    0.00531353        3.4363      0.4957      0.4957       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6937.23   7.59836e-05     0.0854667      0.7082      0.7082       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-11\n",
      "Initial log joint probability = -26266\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6942.31    0.00773784       1.34088           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6942.31   0.000173173      0.103401           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-13\n",
      "Initial log joint probability = -25786.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6950.73     0.0156508       6.07116           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6950.72   0.000159313      0.188181      0.5129           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-14\n",
      "Initial log joint probability = -21791.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6958.94    0.00436985       1.18347           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6958.94    0.00010872      0.106065      0.6979      0.6979       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-20\n",
      "Initial log joint probability = -29774.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6965.73     0.0157533        1.4232           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6965.73   0.000373558     0.0654725           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-21\n",
      "Initial log joint probability = -21342.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6971.75    0.00467533       1.80526           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6971.74   0.000128745     0.0337569      0.9761      0.9761       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-22\n",
      "Initial log joint probability = -32410.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6971.91    0.00457624       13.4942      0.5334      0.5334       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6971.89    5.8961e-05     0.0580585      0.4627           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-27\n",
      "Initial log joint probability = -27112\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6973.34     0.0156889       7.66852           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6973.33   0.000296357      0.176255           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-28\n",
      "Initial log joint probability = -22887.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6978.41    0.00220397        3.1991      0.4966      0.4966       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6978.41   0.000249791      0.106286           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-03\n",
      "Initial log joint probability = -26957.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6983.79     0.0105144       1.78686           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6983.79   0.000190029      0.155295      0.3704      0.9714       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-04\n",
      "Initial log joint probability = -28840\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6990.04    0.00135427      0.852956      0.8673      0.8673       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6990.04   0.000222179     0.0994655           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-09\n",
      "Initial log joint probability = -20882.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6993.68     0.0112898       2.75444           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6993.68   0.000394612     0.0352333           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-10\n",
      "Initial log joint probability = -27002.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7002.61    0.00345589      0.287278           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7002.61   0.000545335      0.129119           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-11\n",
      "Initial log joint probability = -20055.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7006.75    0.00126804      0.784608           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7006.75   0.000109734      0.014509           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-17\n",
      "Initial log joint probability = -31309.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7013.96     0.0142302       3.93432           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7013.95   0.000106562      0.067884           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-18\n",
      "Initial log joint probability = -21598.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7025.59    0.00435152      0.255609           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7025.59   0.000563651      0.133733           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-24\n",
      "Initial log joint probability = -25775.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7039.66   0.000712941       0.94499           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7039.66   0.000114251     0.0821939      0.4553       0.913       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-25\n",
      "Initial log joint probability = -25308.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7051.52   0.000726528      0.361236      0.8759      0.8759       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7051.52     0.0001634      0.113015      0.7347      0.7347       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-26\n",
      "Initial log joint probability = -21621.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7052.82    0.00348001       2.06771      0.5245           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7052.82   0.000246326     0.0680789           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-01\n",
      "Initial log joint probability = -27783.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7058.19    0.00343985      0.631164      0.9958      0.9958       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7058.19   0.000169887      0.124257           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-02\n",
      "Initial log joint probability = -25990.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7069.07    0.00036068      0.648479           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7069.07   0.000209318      0.120524           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-03\n",
      "Initial log joint probability = -31443.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7069.23    0.00103271      0.305569      0.3733      0.3733       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7069.23    0.00160078      0.116265           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-08\n",
      "Initial log joint probability = -21461.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7073.12    0.00217791       2.14193           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7073.12   0.000344326      0.141785           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-09\n",
      "Initial log joint probability = -30324.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7080.25    0.00063237       1.66355      0.6779      0.6779       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7080.25   0.000240121     0.0825033           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-14\n",
      "Initial log joint probability = -24572\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7082.09   0.000245746      0.210282           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7082.09   0.000113154      0.108841           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-15\n",
      "Initial log joint probability = -26528.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7083.33    0.00819227       2.40797           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7083.32   0.000302634      0.121128           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-16\n",
      "Initial log joint probability = -27201\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7090.92    0.00103706      0.440107           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7090.92   0.000231789      0.149581           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-20\n",
      "Initial log joint probability = -29059.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7094.8   0.000565016      0.169209           1           1       20   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-22\n",
      "Initial log joint probability = -21485.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7109.27   0.000978882        2.1769      0.4727      0.4727       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7109.27   0.000402806      0.101116           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-23\n",
      "Initial log joint probability = -19888\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7126.98   0.000565177       1.59991      0.6509      0.6509       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7126.98   0.000219465     0.0662603           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-26\n",
      "Initial log joint probability = -22414.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7130.21    0.00267478       2.42856           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7130.21   8.06838e-05      0.141243           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-29\n",
      "Initial log joint probability = -21803.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7137.49    0.00117598      0.722345      0.7871      0.7871       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7137.49   0.000395402     0.0644341           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-30\n",
      "Initial log joint probability = -26877.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7143.1   0.000777362      0.458505           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -7143.1   8.94099e-05      0.136393      0.6659      0.6659       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-02\n",
      "Initial log joint probability = -21508.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7145.77    0.00532824      0.801633      0.7876      0.7876       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7145.77    0.00025227      0.116404           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-05\n",
      "Initial log joint probability = -23515.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7155.68      0.016154       2.03992           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7155.68   0.000504373     0.0256814           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-06\n",
      "Initial log joint probability = -22499.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7160.59    0.00490149       1.37265           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7160.59   8.34025e-05     0.0348243      0.8826      0.8826       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-09\n",
      "Initial log joint probability = -35188.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7162.74    0.00304979       1.82994           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7162.74   0.000260519     0.0671622           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-12\n",
      "Initial log joint probability = -23916.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7167.41    0.00551823       5.72759      0.3864           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23       -7167.4    6.7732e-05      0.180615      0.4354      0.4354       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-13\n",
      "Initial log joint probability = -23216.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7191.05   0.000161441      0.227274           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7191.05    0.00025347     0.0819484           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-16\n",
      "Initial log joint probability = -31142\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7195.1    0.00260255      0.603116      0.5185           1       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -7195.1    0.00105565     0.0484628           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-19\n",
      "Initial log joint probability = -24251.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7197.66    0.00310619       2.29865           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7197.66   0.000268415      0.181337      0.7642      0.7642       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-20\n",
      "Initial log joint probability = -20096.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7214.39    0.00170553      0.624458           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7214.39   0.000404594     0.0807044           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-23\n",
      "Initial log joint probability = -24989.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7218.34   0.000653697       1.07593      0.8633      0.8633       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7218.34   0.000237907       0.11629           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-26\n",
      "Initial log joint probability = -28920\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7223.48    0.00287043        2.2519           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7223.48   0.000218734      0.131905           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-30\n",
      "Initial log joint probability = -27202.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7227.42    0.00100592       0.43128           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7227.42   6.23254e-05     0.0279234       0.823       0.823       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-02\n",
      "Initial log joint probability = -29319.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7228.02    0.00259335       1.56763      0.4835      0.4835       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7228.02   0.000150477      0.202993           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-03\n",
      "Initial log joint probability = -31758.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7234.52      0.077638       7.05316           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24       -7234.5   0.000676219     0.0486443      0.9116      0.9116       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-06\n",
      "Initial log joint probability = -26717.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7237.91    0.00148209      0.577278           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7237.91   0.000308399      0.194765           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-09\n",
      "Initial log joint probability = -25339\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7243.69    0.00716748       6.55647           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7243.69   0.000505604     0.0701563           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-10\n",
      "Initial log joint probability = -23365\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7254.8    0.00791876      0.992355           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -7254.8   0.000312549      0.122208           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-13\n",
      "Initial log joint probability = -31774.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7257.28    0.00029912       1.41387      0.5797      0.5797       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7257.28   0.000206207      0.057746           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-16\n",
      "Initial log joint probability = -28231.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7259.8     0.0393845       8.31418           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7259.77   0.000739314     0.0983032           1           1       29   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-17\n",
      "Initial log joint probability = -32682.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7273.63   0.000547441       0.20567       0.854       0.854       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-20\n",
      "Initial log joint probability = -23229.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7275.94    0.00829711       4.94069      0.6451      0.6451       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7275.93   0.000357721     0.0829958           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-23\n",
      "Initial log joint probability = -28410.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7289.59    0.00997429       9.29479      0.6679      0.6679       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7289.58    8.7313e-05      0.128329      0.2981           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-27\n",
      "Initial log joint probability = -28595.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7291.06    0.00399579       2.83808           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7291.06   0.000579378     0.0613023      0.9472      0.9472       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-28\n",
      "Initial log joint probability = -26764\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7295.25   0.000976513      0.479424           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7295.25   0.000264046      0.161159      0.7491      0.7491       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-29\n",
      "Initial log joint probability = -26728.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7297.34   0.000738109      0.704116           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7297.34   0.000121094     0.0769438           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-30\n",
      "Initial log joint probability = -34553.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7301.92     0.0130374       6.89792           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7301.91   0.000465857      0.109995           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-01\n",
      "Initial log joint probability = -26427.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7315.3    0.00901835       10.0686      0.5031      0.5031       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7315.29   9.43822e-05     0.0867287       0.729       0.729       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-07\n",
      "Initial log joint probability = -22635.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7317.49    0.00120566       1.43135      0.8676      0.8676       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7317.49   0.000177199      0.131673           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-08\n",
      "Initial log joint probability = -30558\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7317.62     0.0256417       12.6713           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24       -7317.6   5.64174e-05     0.0614833      0.3698      0.9102       29   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-12\n",
      "Initial log joint probability = -27429.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7319.22    0.00267814      0.905678           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7319.22   0.000225316      0.177708      0.9893      0.9893       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-14\n",
      "Initial log joint probability = -29132.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7326.18   6.40155e-05      0.136679      0.7334      0.7334       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-15\n",
      "Initial log joint probability = -21461.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7331.41    0.00210496       1.40095           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7331.41   0.000273172     0.0231008           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-19\n",
      "Initial log joint probability = -25662.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7331.87   0.000188581      0.161329           1           1       20   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-20\n",
      "Initial log joint probability = -29715.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7334.16    0.00805044      0.766315      0.9034      0.9034       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7334.16   0.000131321     0.0899531           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-21\n",
      "Initial log joint probability = -21189.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7338.85     0.0733375       14.0396           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      25      -7338.81   8.48009e-05     0.0858013      0.3433      0.9254       29   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-22\n",
      "Initial log joint probability = -26959.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7344.57     0.0369324       2.64173           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7344.57    0.00132002      0.111605           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-23\n",
      "Initial log joint probability = -30735.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7347.88    0.00841023       2.09021           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7347.87   0.000225749      0.105121      0.7613      0.7613       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-28\n",
      "Initial log joint probability = -30624.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7348.05   0.000656662      0.750526      0.7462      0.7462       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7348.05    0.00014344      0.049272           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-29\n",
      "Initial log joint probability = -20495.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7362.77   0.000748038       0.56403      0.9399      0.9399       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7362.77   0.000192491       0.15441           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-03\n",
      "Initial log joint probability = -25745.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7363.24     0.0162912       2.55865       1.122      0.1122       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7363.24   0.000338179      0.133251      0.9572      0.9572       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-04\n",
      "Initial log joint probability = -21055.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7369.41     0.0148022       2.20911           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7369.41   0.000195374      0.130595      0.9442      0.9442       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-05\n",
      "Initial log joint probability = -25417.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7373.76    0.00411716       2.00605           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7373.76   7.83292e-05     0.0793965      0.2918      0.9981       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-10\n",
      "Initial log joint probability = -31369.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7375.12    0.00630292       10.1527           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7375.07   0.000438506     0.0939058      0.8346      0.8346       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-12\n",
      "Initial log joint probability = -24906.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7391.17    0.00106335      0.371473           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7391.17   0.000185999      0.160338      0.6106      0.6106       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-16\n",
      "Initial log joint probability = -23753.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7395.75      0.026665       8.78388           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7395.71   0.000195254     0.0653684           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-17\n",
      "Initial log joint probability = -24750.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7395.91    0.00298356       3.35823           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7395.91   0.000290563      0.123695           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-18\n",
      "Initial log joint probability = -21955.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7406.56     0.0089324       3.15023           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7406.56   6.63981e-05      0.125344      0.7888      0.7888       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-19\n",
      "Initial log joint probability = -24791\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7414.84    0.00839452      0.864392           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7414.84   3.80134e-05      0.157975      0.5028      0.5028       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-20\n",
      "Initial log joint probability = -26883.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7417.44     0.0312075       2.25258           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7417.44   0.000148556      0.223664      0.5685      0.5685       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-25\n",
      "Initial log joint probability = -22007.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7424.65   0.000752452      0.295241           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7424.65   0.000319169      0.137401           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-26\n",
      "Initial log joint probability = -25553.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7424.74   0.000543194      0.383564           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7424.74   6.36655e-05     0.0986461      0.4259           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-03\n",
      "Initial log joint probability = -27648.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7435.86    0.00382153       4.15073           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7435.86   0.000261424     0.0666081           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-08\n",
      "Initial log joint probability = -25755.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7437.04   0.000727385      0.740558           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7437.04   0.000245529      0.219056      0.9438      0.9438       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-09\n",
      "Initial log joint probability = -26960.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7450.04    0.00325658       6.88935      0.7757      0.7757       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7450.03   9.58442e-05      0.152922      0.5642      0.5642       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-10\n",
      "Initial log joint probability = -26606.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7455.87   0.000283256      0.258489           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7455.87   0.000214607     0.0980858           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-12\n",
      "Initial log joint probability = -30726.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7456.02    0.00171046       1.07458      0.3805      0.9193       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7456.02    0.00176947      0.115361           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-17\n",
      "Initial log joint probability = -22432.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7467.53    0.00682375       3.27968           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7467.53   0.000757658     0.0970314           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-18\n",
      "Initial log joint probability = -32306.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7467.74    0.00617309       2.19997           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7467.73   0.000609313      0.227582      0.9591      0.9591       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-31\n",
      "Initial log joint probability = -25675.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7474.97     0.0051175      0.822186      0.9655      0.9655       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7474.97   0.000196607      0.133715           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-06\n",
      "Initial log joint probability = -28164\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7476.09    0.00850839      0.477978           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7476.09   7.52483e-05      0.289345      0.6204      0.6204       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-13\n",
      "Initial log joint probability = -22178.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7479.46    0.00634918       5.73365           1           1       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7479.45   0.000133475      0.109062           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-14\n",
      "Initial log joint probability = -27629.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7485.8    0.00271308      0.843283      0.9141      0.9141       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -7485.8     0.0001328      0.123455           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-18\n",
      "Initial log joint probability = -28246.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7488.94    0.00875945       1.92941           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7488.94   3.82767e-05      0.159739        0.55        0.55       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-20\n",
      "Initial log joint probability = -25673.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7489.18    0.00143238       1.26807           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7489.18   0.000121413      0.148164      0.7127      0.7127       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-21\n",
      "Initial log joint probability = -31216.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7499.56    0.00114105       4.27959      0.5574      0.5574       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7499.56   0.000437473      0.134067           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-27\n",
      "Initial log joint probability = -23327.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7503.14    0.00103607       2.24647      0.9231      0.9231       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7503.13   0.000288599      0.132111           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-28\n",
      "Initial log joint probability = -27118.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7504.98     0.0246219       4.06535           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7504.98    0.00150554     0.0876457           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-03\n",
      "Initial log joint probability = -26648\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7505.08    0.00340741       4.33543           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7505.08    0.00124427       0.16358           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-04\n",
      "Initial log joint probability = -28478.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7519.53    0.00277424       2.02276           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7519.53   0.000340198      0.151753           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-10\n",
      "Initial log joint probability = -19878.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7520.23   0.000864009      0.713467           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7520.23    0.00045318      0.148279           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-11\n",
      "Initial log joint probability = -22784.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7522.47    0.00226778       1.76319           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7522.47   0.000132782      0.119553      0.8013      0.8013       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-17\n",
      "Initial log joint probability = -27207.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7528.43    0.00340469       1.22062           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7528.43   8.21575e-05      0.182394      0.6163      0.6163       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-18\n",
      "Initial log joint probability = -27426.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7533.96     0.0091969        2.2376           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7533.96   8.70488e-05      0.180805       0.568       0.568       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-24\n",
      "Initial log joint probability = -23917\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7538.56    0.00143039      0.729474           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7538.56   0.000358263      0.235941           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-25\n",
      "Initial log joint probability = -29509.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7553.59   0.000898773      0.889509           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7553.59    0.00013116     0.0978653           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-03\n",
      "Initial log joint probability = -30716.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7556.75    0.00356931       2.81066           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7556.75   0.000194128     0.0994132           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-04\n",
      "Initial log joint probability = -28354.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7563.81    0.00163076      0.846123           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7563.81   8.49233e-05     0.0660572      0.5184           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-10\n",
      "Initial log joint probability = -25124.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7571.78    0.00219202       2.49101           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7571.78   0.000702567     0.0616781      0.9993      0.9993       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-11\n",
      "Initial log joint probability = -35855.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7581.46   0.000810328       1.69497      0.4675      0.4675       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7581.46    0.00014683     0.0677526      0.4865      0.9808       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-15\n",
      "Initial log joint probability = -20769.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7584.54   0.000456621      0.124907           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-17\n",
      "Initial log joint probability = -22898.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7588.97   0.000442323       0.67455           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7588.97   0.000347971      0.101455           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-18\n",
      "Initial log joint probability = -24306\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7599.16    0.00525107       5.17669           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7599.15   0.000101069     0.0474446      0.8221      0.8221       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-24\n",
      "Initial log joint probability = -25329.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7608.66    0.00282825      0.694469      0.5192           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7608.66    0.00142271     0.0828119           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-25\n",
      "Initial log joint probability = -25235.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7617.98      0.022001       3.15418           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7617.98    0.00150383     0.0942604           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-31\n",
      "Initial log joint probability = -30170.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7630.03    0.00342427      0.631254           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7630.03   0.000229859       0.10311           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-04-01\n",
      "Initial log joint probability = -33784.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7636.81    0.00938295       4.13632           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7636.81   0.000281528      0.163618           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-04-07\n",
      "Initial log joint probability = -29039.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7642.8    0.00134675      0.244201           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20       -7642.8   0.000123267      0.123575           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-04-08\n",
      "Initial log joint probability = -33831.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7650.67    0.00199339      0.212249           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "from model_selection.cross_val_pipeline import TimeSeriesCrossVal\n",
    "\n",
    "tscv = TimeSeriesCrossVal(min_test_date=pd.to_datetime(\"2021-01-01\"), \n",
    "                          n_dates_per_fold=1, \n",
    "                          p_fighter_implied_col=p_fighter_implied_col)\n",
    "preds_df = tscv.get_cross_val_preds(\n",
    "    mod, \n",
    "    feat_ml_df.dropna(subset=[\n",
    "        *feat_cols, \"win_target\", p_fighter_implied_col,\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:      0.6836532097948379\n",
      "Moneyline accuracy:  0.6671078755790867\n"
     ]
    }
   ],
   "source": [
    "mod_pred = preds_df[\"y_pred\"].round()\n",
    "ml_pred = preds_df[p_fighter_implied_col].round()\n",
    "print(\"Model accuracy:     \", (mod_pred == preds_df[\"win_target\"]).mean())\n",
    "print(\"Moneyline accuracy: \", (ml_pred == preds_df[\"win_target\"]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model log loss    : 0.5863996340772879\n",
      "Moneyline log loss: 0.6093059101142347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "xce = log_loss(y_true=preds_df[\"win_target\"], y_pred=preds_df[\"y_pred\"])\n",
    "xce_ml = log_loss(y_true=preds_df[\"win_target\"], y_pred=preds_df[p_fighter_implied_col])\n",
    "\n",
    "print(f\"model log loss    : {xce}\")\n",
    "print(f\"Moneyline log loss: {xce_ml}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pred_elo_PC_0', 0.12450440556756572),\n",
       " ('pred_elo_PC_1', -0.002821310401073378),\n",
       " ('pred_elo_PC_2', 0.008058694728148814),\n",
       " ('pred_elo_PC_3', 0.016002551471038528),\n",
       " ('pred_elo_PC_4', 0.028055441771392055),\n",
       " ('pred_elo_PC_5', -0.01896971655752299),\n",
       " ('pred_elo_PC_6', 0.014311270745261336),\n",
       " ('pred_elo_PC_7', -0.02503059408866972),\n",
       " ('pred_elo_PC_8', 0.002172635590656807),\n",
       " ('pred_elo_PC_9', 0.01706635243419307),\n",
       " ('pred_elo_PC_10', 0.019637498268429896),\n",
       " ('pred_elo_PC_11', -0.011845469525640386),\n",
       " ('pred_elo_PC_12', -0.017419943161882775),\n",
       " ('pred_elo_PC_13', 0.047408855883789895),\n",
       " ('pred_elo_signed_inverse_fight_time', -0.07071769167196695),\n",
       " ('pred_elo_win_target', 0.413489145572239),\n",
       " ('pred_elo_win_target_finish', -0.4065394565780645),\n",
       " ('age_diff', 0.25082992900563594),\n",
       " ('log_reach_diff', 0.04293612594498792),\n",
       " ('weight_diff', 0.01304635672972162),\n",
       " ('height_diff', 0.023562739649030336),\n",
       " ('log_t_since_prev_fight_diff', -0.16472521254888464),\n",
       " ('log_t_since_first_fight_diff', 0.23872774997405252),\n",
       " ('total_fights_diff', 0.0046976644078205705)]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(mod.feat_cols, mod.fit['beta']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"week\"] = preds_df[\"Date\"].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_ml_col = \"FighterOpen\"\n",
    "opponent_ml_col = \"OpponentOpen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall winnings\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ufc winnings\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAErCAYAAAASbs4DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABEr0lEQVR4nO3deXhU5fXA8e/JTkJCAgn7DrKLgCiKaHGpW92XWlsXtGqtbW1rXdqqrVW7aNtfa7VWrbXuWOu+1wUQF0RBVoFA2JeEJEA2IOuc3x/vHRhCtklmMjPJ+TxPnszMXebc2c6973vveUVVMcYYY0IpLtIBGGOM6XgsuRhjjAk5Sy7GGGNCzpKLMcaYkLPkYowxJuQsuRhjjAm5DpNcRORcEdksIhUiMrGZeR8Xkbu928eKSG77RLnv+QeLiIpIQns+b3sTkV+KyKORjsOYSPG+58MbmTZHRK5q75haQ0TuEJGng1mm3ZKLiGwQkb3ej/92Efm3iHRtw7pOqvfwn4AfqmpXVV3U0nWp6keqOrI1cZj9RGS6iGwJfExVf6eqMfHl6cga+b4YE1btfeRypqp2BSYBRwC3BbNwM3v6g4Cv2hCbaaGOfsQVS9rjvbD327RGRJrFVHUr8DYwDkBEzhKRr0SkxDtUHO2f19vrukVElgK7RWQmMBB43TsKukVEKoB4YImIrPWWG+2tq8Rb91kNxVJ/jzuI5b4lIgvqPfZTEXnNu/0NEVkkImVec90djb0e9fcs6x+CishRIvKpF9MSEZnexLoajN9bR4GIxAfMe673uiIicSLycxFZKyI7ROR5EenuTfM3431XRDYBs+o9Zxru/ezrvScVItI3cDsC1nGF93rsEpFrReQIEVnqxftAvfVeKSIrvXn/JyKDGtvu5gRsW7mIrBCRcwOmDReRD0WkVESKReQ/3uMiIn8RkUJv2lIR8X9mD2jSEJEZIvJxwH0VketEZI33nHeJyDARmed9Jp4XkaSA+c8QkcXe6/CpiIxvYltURH4gImuANU0tLyJPceD35eb6n3lvvn2fQe99e0FEnhaRMmCGt713icgn3va8KyLZ3vwp3rw7vOf/QkR6NRL7ABF5SUSKvPkf8B6PE5HbRGSj93o/KSLdvGlBfXa89+ITEbnfe99WiciJAdP7ishrIrJTRPJE5OqAafuazL379X8fNojIjd7zlorIf0QkJWD6TSKSLyLbROTKxt7DAMNE5HNvXa/K/u/cmyLyo3qv3VIROaeB1/QJEfmZd7uf/7Pn3R/ubad49xv9nHmvy4vee7NeRK5vKGARSRSRmd68SQ3NA4CqtssfsAE4ybs9AHeUcRcwAtgNfB1IBG4G8oCkgOUWe8t0qb+ugPUrMNy7neit45dAEnACUA6M9KY/Dtzt3Z4ObGnJcvWeL9WbdkjAY18A3wpY76G4BD4e2A6c400b7MWb0ND2AHcAT3u3+wE7gNO9dX3du5/TQEzNbfda4OsB8/8X+Ll3+yfAZ0B/IBl4GJhZL94ngTT/+1Dvufe9jo1sh38dDwEpwMlAJfAK0NPbzkLga97853jbMhpIwB3lftqGz9+FQF/vNbwI95nr402bCdzqTUsBpnmPnwIsBDIB8WLxLzMHuCpg/TOAj+t9Hl8DMoCxQBXwATAU6AasAC735p3kbfsU3E7S5d5nIrmRbVHgPaA70KW55Tn489XQe7VvHu99q/HegzjvOebgPj8jAu7/wZv/e8DruO9EPHA4kNFA3PHAEuAvuM9R4Gt9pfd+DwW6Ai8BT7XyszMDqAV+ivtOXASUAt296R8CD3rrmgAUASfW/21o6LXyXqfPcZ+l7sBK4Fpv2qm47/k4b/ueJeB3qYHXYw6wNWD+F9n/ffkmMD9g3sNw3/ukBtZzJfC6d/vb3vv0n4Bprzb3OfPe54XAr3C/HUOBdcApgd9l771/03ud4pv8zrX2y9qKL/cGoAIoATZ6b24X4Hbg+YD54rwXfHrAclc29kWo94XzJ5djgQIgLmD6TOCO+h8gDkwuTS7XwDY9DfzKu30I7oc8tZF5/wr8pd6XpSXJ5Ra8L1nA9P/h/TDVe7y57b4beMy7nY77gR3k3V+J9wXz7vfB/cAkBMQ7tIn3d9/r2Mh2+NfRL2D6DuCigPsvAj/xbr8NfLfe52KPP94QfB4XA2d7t58EHgH615vnBGA1cFTga+pNm0PzyeWYgPsLgVsC7v8Z+Kt3+x/AXfXWn4v3Y9lA7AqcEHC/yeUb+Hw19F7tm8d73+Y2sL23Bdy/DnjHu30l8CkwvpnX/GjcD3lCA9M+AK4LuD+ygc9fSz87M4BtgARM/xy4FLeTWgekB0z7PfC4d/txmk8ulwTcvxd4yLv9GF7C9e6PoPnkEjj/GKAa98OfDOzE23nF9Sk/2Mh6huF+V+NwCfh77P9NewK4obnPCS7hbKo37RfAvwM+E6/hEvPfAl/bxv7au1nsHFXNVNVBqnqdqu7F7QFs9M+gqj5gM25vxG9zkM/TF9jsrctvY711hmK5Z4GLvdvfBl5R1T0AIjJFRGZ7h5ilwLVAdpDbAa4v6ULvMLZEREqAabgf/2DjfxY4T0SSgfOAL1XV/9oPAl4OeI6VuC9hYPNGsO9DQ7YH3N7bwH3/SR6DgPsC4tmJO3o46L0QkYdkf3PcLxt6UhG5LKA5oAS3t+h/P2721v25uKbEKwFUdRbwAPB3YLuIPCIiGWHa1p/Ve48H4N7PxgS+F61ZvjkNvdcFAbf3sD/+p3A7PM95zUH3ikhiA8sPADaqam0D0w74HfBuJ3Dg56+lryfAVvV+FQPW19f726mq5fWmNffbEKix16EvB75ugdvTmPrzJwLZqloFPA9cIiJxuN+Zpxpagaquxe24T8DtYL4BbBORkbjE8aE3a1Ofk0G4Zu3Aab/kwNf/KFwrzB/qvbYNioZTkbfhNgxw7dy4Dd4aME/9DWluw7YBA7w3xW9gvXWGYrl3gWwRmYB7858NmPYsLtMPUNVuuD0KaWQ9u3FNCn69A25vxh25ZAb8panqH4KNX1VX4D7Ap+GSYWC8m4HT6j1Pirr+Mb+mXvdmP2xB2gx8r148XVT104OeWPVadWcJdlXV39WfLq6v5p/AD4EeqpoJLMd7P1S1QFWvVtW+uL2+B8U7fVRV/6aqh+OatkYAN3mrbeo9a822/rbetqaq6swmlgl8vZtbvv57c0Ds4vrhcppYf5NUtUZVf6OqY4CpwBnAZQ3MuhkYKA2fIHDA7wDuc1vLgQkkGP38/QwB69vm/XUXkfR60/yf87a8r/m4367A9Tan/vw1QLF3/wngO8CJwB5VndfEej4ELsA1m2317l8GZOGO0qHpz8lmYH29aemqenrAc7yLO8r7QBrpUwsUDcnleeAbInKit7fzM1z79EE/IgG249oEGzMf9yG52et8mg6cCTzXTCxBLeftgb0A/BHX/vpewOR03B5SpYgcifsxb8xi4Fvec07GfUj8ngbOFJFTRCReXOfpdBHp38r4nwWuB47D9bn4PQT81vshRkRyROTsJmKubzvQQ7xO2BB4CPiFiIz14ukmIhe2cl1puB/LIm9dV+CdTOLdvzDg9dzlzVsnrsN4ive53I1r56/z5luMOwpM9RLRd1sZG7jEd633XCIiaeJOCElvdsmWLV//+7IaSPHmScT1ZyW3NngROV5EDvWSVBnuB7KugVk/x/0A/8GLMUVEjvGmzQR+KiJDxF2i8Dtcv0FDRzkt0RO43vseXIjrL3tLVTfjflt+7z3/eNx794y33GLgdBHpLiK9cX2RLfU87uSHMSKSCvy6BctcEjD/ncALqloH4CUTH64JtcGjlgAf4nae5nr35wA/wjXV+t+Lpj4nnwNl4k6Q6uL91owTkSMCn0RV78X9hnwg3gkdjYl4clHVXOAS4H5cxj4Td8pydROL/R64zTt8u7GBdVYDZ+H20Itx/TuXqeqqZmJpzXLPAicB/633RbgOuFNEynGdZM83sY7bce2mu4DfEHBE4X0ZzsYdohbh9jBuooH3roXxz8S1I89S1eKAx+/DHWm968X8Ga4dtkW855gJrPPel7Y0yaCqLwP34JpaynBHGqe1cl0rcF/Qebgf2kOBTwJmOQKYL+6sw9eAH6vqelxn/D9x78tGXDv/n7xl/oJrH9+O28N8hlZS1QXA1bgmuF24ju0ZIVz+gO+LqpbiPp+P4vbYdwMHnD0WpN64nawyXHPqh7idovpx1uG+38OBTd5zXuRNfgz3AzoXWI9L5D+qv44gzMf1gxYDvwUuUNUd3rSLcf0424CXgV+rqn/H8CncSQcbcHvq/2npE6rq27i+1Vm492BWkwvsf77HcU1tKbgdv0BP4j6vzV3A+CFuh9afXD7GHYH57zf5OQl4bybgXv9i3OfjoJ1FVb0LdzLF++Kd3dYQaUHTmTHGxAwRmYE72WJapGNpKxG5DLgmFrcl4kcuxhhjDuY1lV2HO5Mx5lhyMcaYKCMip+Cawbdz4Ik3McOaxYwxxoScHbkYY4wJOUsuxhhjQs6SizFtJPWKVkYohmQReUxcUcwCEbmhmfm/La5I5G4ReSXwlFIR+aa4ooZ7RGROA8tOEJGF3vSF4i4i9k+bISJ1sr9iQoU0UWjVdFyWXEzUkwiXfA/384do/XfgrusYBByPu5D21EaebyyuMOmluPIee3DXRPntxF2vcVAVCHFVcF/FXXeRhbvG51U5sDruvICKCV1VdU6btszEJEsupk2kkVL23p50iXgl6r3HcsQNGNfTu99U+e8NcuBQCwmNPZc3f7yI/Flcyfz1IvJDCRjtU9wV/v8SVw59q4jcLQHDD9TbpoZKzje4vLjhIR4Cjvb20ku8dbSkJP++svnilXYXkZ+JKzmfL66SQEtdhitKuEtVV+Iu/pzRyLzfwVXRnauqFbiLeM/zrtRGVd9X1edxFxnWNx1X8+uvqlqlqn/DldE5IYhYTSdgycW01VpcsbxuuOoCT4tIH6/w3kvsL+wJroz4h6paKCKTcFdlfw/ogduTfk1cUU2/i4FvAJle9YMGn8ub92rcFfwTcKXFz6kX5xO4WlXDgYm4su1NjZJ5Nu6q80zc1fcNLu/9kF/L/r31zCbWWd85uCoIY7z7vb1t64crSfJ3EcmCfc1YSxtaiTdPX9yV5X5LcPXQGjI2cF6v8GE1rnZac8YCS+sVLlxa77kmekl+tYjcHukjTxMZllxMm6jqf1V1m6r6VPU/uMGrjvQmB1aNhgOLZV4NPKyq81W1TlWfwNWUOypg/r+p6mZ11bObe65vAvep6hZV3UVAk464Inun4Uqy71bVQlz5lm81sWnzVPUVdRWmM1qxfEv8XlV3+rcPV5PrTq8Q5Fu4SrcjvW1/VlUbG0DMX5W3NOCxUlw5kMbmL633WFPzB7PsXFzdtp7A+bj3/yZMp2N7FKZNvPIUN+BqNYH78fEXtJsFdBGRKbjaSRNwtZzA9Q1cLgeOtpfEgWXiDyj73sxz1S93Xr8kfSKQL/sL5cbVX389bV2+Jeovv6NefbrAcu5NqfD+Z+Bqcvlvlzc8OxXe9EBNzd/iZVV1XcDjy0TkTlxy+X0L1m06EEsuptVkfyn7E3F7+nUispj9pex9IvI8bu91O/CG7h9Hw1/++7dNPMW+ppfmngtXbTewUnRgKfPNuKOi7CCq7NYvad/U8g1didyS0u0huYJZVXeJSD5utEJ/AcbDcKO9NuQrbzoAIjIUVxV5dQue7ivcmCAS0DQ2HjfmTYPh0fhQE6YDs2Yx0xZNlrL3PIurfPsdDixjEWyZ+eae63ngx+LGEM/EjeAJgKrm4yrc/llEMsSN1z5MRL7Wko1swfLbgf71zphaTOhK8rfEk7jKx1kiMgrX7Ph4I/M+gxvG4VgRScOVen/Jn/i9ExVScDufceJK0/sH/5qDK6d/vXfSxg+9x2d5y57mNUPixXE77uwy08lYcjGt1oJS9qiqf4yZvrihi/2PB1VmvgXP9U9cAlgKLALewnXA+8eyuAzX7LbCe74XaHg0z8Y0tfws3B59gYj4hzEIWUl+ABH5jog0diQCbuyQtbihAT4E/qiq7wQsXyEixwKo6le4kxCewY2pno4rkOh3KW5kx3/gTqDYi3t9/cM6nIN7PUpwQxyfEzBExonAUhHZjXsPXsKNzWI6GastZjokETkNN7b5oGZnNsaEnB25mA5B3Oh5p3vXw/TD7cm/3NxyxpjwsCMX0yGIG/viQ2AUrhnnTdyIkmURDcyYTsqSizHGmJCzZjFjjDEhF5PXuWRnZ+vgwYMjHYYxxsSUhQsXFqtqTns8V0wml8GDB7NgwYJIh2GMMTFFRDa213NZs5gxxpiQs+RijDEm5Cy5GGOMCTlLLsYYY0LOkosxxpiQs+RijDEm5Cy5GGOMCTlLLsYYEwPqfMrPnl/C4s0lkQ6lRSy5GGNMDHj0o3W8+OUW1hVVND9zFLDkYowxUW719nL+/O5qThnbi3Mn9ot0OC1iycUYY6JYTZ2PG55fTNeUBH577qGISKRDapGYrC1mjDGdxd9n57F8axkPXTKJ7K7JkQ6nxezIxRhjotSyLaU8MCuPcyb05dRxfSIdTlDsyMUYY9pRbZ2P7eVVbN21lz7dUhjQPbXB+Spr6rjh+cX06JrEb84a185Rtp0lF2OMCaHKmjq2lexla8letu7a/3+L97+grJI6nxsBOE7gtEP7cN30YYzt2+2A9fzlvdWsKazg8SuOoFtqYiQ2pU0suRhjTBt9ta2UX736FRt37KG4ouqAaXECvTNS6JfVhSMGZ9Evqwv9MlPpm5nC5+t38tS8jby5NJ/pI3O4bvpwjhzSnQUbdvLIR+u4+MiBTB/ZM0Jb1TaiqpGOIWiTJ09WGyzMGBMtLnp4Hqu3l3PymN5e8uiy73/vbikkxjfevV1WWcNT8zby2Mfr2bG7miMGZ1FQVgnA2z8+jq7JoTsGEJGFqjo5ZCtsgh25GGNMGyzYsJP563dy+xlj+O60IUEvn5GSyA+OH86Vxwzh+QWbefjDtRSUVfLs1UeFNLG0t7BGLiKPAWcAhap6UI+UiEwHXgXWew+9pKp3hjMmY4wJpQfnrCUrNZGLjxzQpvV0SYrn8qmD+faUgWwvq6R/VsMd/bEi3KciPw6c2sw8H6nqBO/PEosxJmZ8ta2UWasKufKYIaQmhWZfPTE+LuYTC4Q5uajqXGBnOJ/DGGMi5R9z1tI1OYHLjh4c6VCiTjRcRHm0iCwRkbdFZGxjM4nINSKyQEQWFBUVtWd8xhhzkHVFFby5LJ9LjhoUk6cKh1ukk8uXwCBVPQy4H3ilsRlV9RFVnayqk3NyctorPmOMadDDH64jKT6uVZ34nUFEk4uqlqlqhXf7LSBRRLIjGZMxxjRnW8leXlq0hYuOGEBOeuzU+2pPEU0uItJbvBKfInKkF8+OSMZkjDHN+edH61CFa44bGulQola4T0WeCUwHskVkC/BrIBFAVR8CLgC+LyK1wF7gWxqLV3UaYzqNHRVVzPx8E2dP6NchzuoKl7AmF1W9uJnpDwAPhDMGY4wJpX9/soGqWh/fn25HLU2JdIe+MSZENu/cw7tfFUQ6jA6trLKGJ+Zt4NSxvRneMz3S4US12K0tYIw5wJ/fzeWtZQXk3n1qzIxWGI0qa+q49umFVFTWkp6SQNeURNJTEkhPTmDTzj2UV9Zy3fThkQ4z6llyMaYDUFU+zttBdZ2Piqpa0lPsuovWWpFfxpzcIsb0yaCq1sf64t1UVNVSVllLda2Pr4/pxaH9uzW/ok7OkosxHcDq7RX7Sr3v2l1jyaUNVuWXA/DIZYcf1GFfVVtHUhMVjs1+9ioZ0wF8tGZ/1Ypde6ojGEnsW1VQRnpyAv0yuxw0LTkh3pocW8iSizEdwCd5xcR5v3mWXNpmVX45o/qkWxJpI0suxsS46lof89fv5JjhrrhFyZ6aCEcUu1SVlQVljOqdEelQYp4lF2Ni3KJNu9hTXccZ4/sAsHO3Hbm01rbSSsoraxnVx04zbitLLsbEOH+T2CljeyMCJdYs1mort5UB2JFLCFhyMSbGfZxXzGEDMslMTaJbl0R2WbNYq60qcMllZG87cmkrSy7GxLCyyhqWbCllmtff0j01yTr022BlQTkDu6fG9Nj10cKSizEx7LO1O6jz6b7kkpmaaMmlDVbllzHKjlpCwpKLMTHsk7xiuiTGM3FgFgBZqUns2m3NYq1RWVPH+uLdjOpj/S2hYMnFmBj2UV4xU4Z2JynBfZUzU5OsQ7+V1myvwKcw2o5cQsKSizExalvJXtYV7d7XJAbQPS2RnZZcWmWl15lvRy6hYcnFmBj1SV4xANMO2Z9cMlOTqKzxUVlTF6mwYtaq/HK6JMYzsLsNABYKllyMiVEf5xWT3TWZkb32N+NkpSYBVgKmNVYVlDGidzrxcVb2JRQsuRgTg1SVT/KKmTa8xwE1sLqnuWrI1qkfHFVlZX6Z9beEkCUXY2JQ7vZyiiuq99UT88u0I5dWKSqvYteeGjsNOYQsuRgTgz5ec3B/C1izWGutLHBjuFhnfuhYcjEmBn2cV8ywnDT6dDtwzJGsVK9ZzErABGVVvr+mmB25hIolF2NiTHWtj/nrdh5wCrLfvmYxq4wclFUF5fTplrLv9TNtZ8nFmBjz5aZd7K2pO6i/BSApIY6uyQnWLBaklflljLYmsZCy5GJMjPkkr5j4OOGoYT0anJ6ZmmgDhgWhutbH2qIKaxILMUsuxsSYuauLOKx/NzJSEhuc3j3NKiMHY11xBTV1ap35IRbW5CIij4lIoYgsb2a+I0SkTkQuCGc8xsS6JZtLWLKllNPG9Wl0nszUJOtzCcKqfHemmF3jElrhPnJ5HDi1qRlEJB64B/hfmGMxJub9Y85aMlISuHjKwEbnyUrtuAOGLd9ayiNz16KqIVvnyoIykuLjGJKdFrJ1GgjriDiqOldEBjcz24+AF4EjwhmLMbEur7CC/60o4IfHD29yMKusDjpg2OLNJVz66HzKq2rplZHC2RP6hWS9q/LLOaRXVxLirZcglCL6aopIP+Bc4KEWzHuNiCwQkQVFRUXhD86YKPPI3LUkJ8QxY+rgJufLSk2ivLKWmjpf+wTWDpZsLuHSf80nKy2Jkb3Sufed3JAV51xVUMao3tbfEmqRTtV/BW5R1WY/Jar6iKpOVtXJOTk54Y/MmCiSX7qXlxdt5aLJA+jRNbnJebO8+mId5YyxJZtLuORf88lMTWTmNUdxx1lj2Vqyl399vL7N6965u5rtZVWM7mP9LaEW6eQyGXhORDYAFwAPisg5EY3ImCj06Efr8SlcfdzQZuf1XwjYEQYNW7plf2J57pqj6ZfZhaOH9eDkMb14cHYeheWVbVr/Kv8YLnbkEnIRTS6qOkRVB6vqYOAF4DpVfSWSMRkTbXbtrmbm55s4+7C+9M9qfqyR7vvqi0X/kcuHq4tYuHEn5ZUHx7psSymXPDqfbl0SmXn1UfTL3F/q5henj6aq1sdf3lvdpuf3nyk2yo5cQi6sHfoiMhOYDmSLyBbg10AigKo2289ijIEn5m1gT3Ud104f1qL5M736Yjuj/HTk3IJyLn/s8333+2d1YVTvdEb1zqBvZhfueWcVGV0See6aow5KqkOy07js6ME8/ul6Ljt6cKuvrl9VUEZ212Sym2lqNMEL99liFwcx74wwhmJMTNpTXcvjn27gpNG9GNGrZXvXWWmx0Szmb5K68+yxlFfWsqqgnFX5ZczOLaLOp/TL7MLMqw9OLH7XnzicF7/cwm/fXMlT3z3ygHFtWh5DufW3hElYk4sxpm2e+3wzJXtq+H4Lj1ogdioj5xVWECdw0REDSE6I3/d4VW0d64t30z8rtclTrjNTk/jxiYdw5xsrmJ1byAmjegX1/HU+JbegnMuOHtTqbTCNi3SHvjGmEdW1Pv750TqOHNKdwwdltXi5LonxJCfERf21LnmFFQzqkXZAYgFITohnVO+MJhOL36VHD2Jodhq/fXNl0Kdeb9ixm6pan3Xmh4kduRgTpV5dvJX80kp+f96hQS0nIu5Cyijvc8krrGB4z65tWkdifBy/OH00Vz+5gGfnb+LyBq4BqqqtY0dFNbv2VFOyp4Zde6rZtaeGRZt2AdaZHy6WXIyJQrurannow7WM7pPB10YEf11XZpSXgKmp87G+eDcnjQmuKashJ43uydFDe/CX91dTUVVLQWkl+aWVFJTtpaC0kuKKxpPs0Jy0Nic40zBLLsZEgTqfsnRLCR+vKeajvGK+3LiLWp/y929PalVHdVZqUlR36G/csYdan3JICH7YRYTbzhjNOX//hD/+L5fM1ER6Z6TQp1sKh/bLpE+3FHLSk8lKTSQrNYmstCQyUxPJ7JJEUoL1DISLJRdjIiivsJw/v7uaT9fuoHSvO9IY1y+Dq44dyvEjc5gytOExW5rTPS2Jld7ZWNEor9BdXxKqo4axfbvxxa0nkZwQT5ek+OYXMGFnycWYCPrN6ytYtKmE0w/tzbRDcjhmWI9my7u0RLQPGJZXWAHAsJzQNUnZEMXRxZKLMRFSWFbJJ3nFXDd9ODeeMjKk6/Y3i/l8Slxc8M1q4ZZXWEG/zC6kteCMMBObrMHRmAh5bck2fArnTAxN6fhAWWlJ+BTKGiirEg3WFFYwzDrSOzRLLsZEyMuLtjK+f7ewnK0UzRdS+nzK2qKKkHTmm+hlycWYCFi9vZyvtpVxTogGvKova1/xyug7Y2xryV4qa3x2CnAHZ8nFmAh4ZdFW4uOEMw/rG5b1+4tXRuPpyP7OfEsuHVtQyUVEponIFd7tHBEZEp6wjOm4fD7l1cXbmDY8m5z08FTj7e4Vr9y5O/qaxfYllxCeKWaiT4uTi4j8GrgF+IX3UCLwdDiCMqYj+2LDTraW7OXcMHTk+0XzgGFrCsvJ7pq0r3qz6ZiCOXI5FzgL2A2gqtsAK8pjTJBeWbyV1KR4Th7b9tInjclISSA+TqKyzyUUNcVM9AsmuVSrqgIKICJp4QnJmI6rsqaON5bmc8rY3qQmhe8aD1e8Mvrqi6kqayy5dArBJJfnReRhIFNErgbeB/4ZnrCM6Zjm5BZSXlkblmtb6suMwsrIReVVlFfWckhPa/To6FqcXFT1T7hx7l8ERgK/UtX7wxWYMR3Ry4u2kt01mWOGta5mWDDckUtok8vO3dVc9PA83l+xvVXL25linUdQx+Wq+h7wXphiMaZDK9lTzexVRVxy1CAS4sN/FUBmahKbd+4J6Tpnrypk/vqdLNpUwsOXHc7xI3sGtfwaSy6dRjBni5WLSJn3VykidSISvWVXjYkyby0roLrOx3mTwt8kBtA9NYmdIW4Wm7duB5mpiRzSqyvfe2ohH68pDmr5vMIK0lMS6BmmU7BN9AimWSxdVTO8vxTgfOCB8IVmTMfyyqKtDO/ZlbF922dY3cw0VxnZnYcTGvPW7uCoIT146rtTGJqdxlVPfsFn63a0ePk1heUM79m1VWPUmNjS6mNzVX0FOCF0oRgT23w+5c2l+SzbUkptvfHcN+/cw+cbdnLuxH7t9sOalZpEdZ2PPdV1IVnf5p172Fqyl6OH9aB7WhJPXzWF/lmpXPn4FyzYsLNF68gr3G01xTqJFve5iMh5AXfjgMl4pyUbY+DD1UX84NkvAUhNimfiwEwOH9SdIwZn7du7PytM5V4asr94ZXVIStvPW+u24WjvZITsrsk8e9UUvvXIZ8z49xc8fdUUJgzIbHT5kj3VFFdUWX9LJxHMJ+7MgNu1wAbg7JBGY0wMW7hxF/Fxwp8uHM/iTSV8sWEXD8xag8/bBTtycHcGdE9tt3j2Fa/cXUP/rLavb966HWR3TTrgyKNnRgrPXn0U33x4Hpf+az4zrz6Kcf26Nbi8nSnWubQ4uajqFeEMxJhYt3hzCaN6p3PuxP6cO7E/AOWVNSzaVMLizSVBn1nVVv7yKqE4HVlVmbd2B1OG9jioWa93txSevXoKFz40j5teWMpb109rsOnPn1zsGpfOodnkIiL300Tzl6peH9KIjIlBPp+yZHMJZ004sNkrPSWR40bkcNyInHaPKbBZrK027NhDQVklRw1t+Pqc/lmp/Ozkkdz43yXMzi3khFEHl7ZZU1hBSmIc/TK7tDkeE/1a0qG/AFjYxF+jROQxESkUkeWNTD9bRJaKyGIRWSAi04IL35josLaogvKqWiYODEH7U4jsbxZre3LZ19/SSHIBOHtCX/pndeGBWXkNnqGWV1jBsJyuUTnssgm9Zo9cVPWJNqz/cdzpyk82Mv0D4DVVVREZDzwPjGrD8xkTEYs2lQA02aHd3rp1Cd1olPPW7SAnPZlhOY2XFEyMj+N7XxvG7a8sZ966HUwdln3A9LzCCiYPjp7ka8IrmIsoc0TkTyLylojM8v81tYyqzgUaPUdRVSt0/y5OGnb2mYlRizaXkJGSwNDs6KnnmhAfR0ZKQpvL7vv7W45uoL+lvgsP709OejJ/n513wOO7q2rZWrLXxnDpRIK5zuUZYCUwBPgN7myxL9oagIicKyKrgDeBK5uY7xqv6WxBUVFRW5/WmJBatGkXhw3IjLomn6y0pDYfuawtqqC4omrfKchNSUmM5+pjh/BJ3g4Wbdq17/F1RbsBOKSXJZfOIpjk0kNV/wXUqOqHqnolcFRbA1DVl1V1FHAOcFcT8z2iqpNVdXJOTvt3jhrTmN1VtazeXh5V/S1+WalJbe7Qb0l/S6DvTBlEZmriAUcvawrLATsNuTMJJrn4d3/yReQbIjIR6B+qQLwmtGEikt3szMZEkaVbSvEpTIyi/ha/UFRGnrduB326pTCoR8uu0UlLTuCKqUN4f2UhK/Nd+cG8wgoS4oRBPaKn2dCEVzDJ5W4R6Qb8DLgReBT4aVueXESGi9eIKyKTgCSg5YWKjIkCizeXANHVme+XlZrErt2tbxbz+ZTP1u1sUX9LoMunDiItKZ4H56wFXHIZnJ1GYjtUgzbRIZgr9OerailQChzfkgVEZCYwHcgWkS3Ar4FEAFV9CFf88jIRqQH2AhdpKKvsGdMOFm3axeAeqVE5Jrzrc2n9kcvqwnJ27q7mqCDHn8lMTeKSowfxz7nruOHrI8grrGBEL7t4sjMJJrl8KiLrgf8AL6nqruYWUNWLm5l+D3BPEDEYE1VUlUWbS5g2PDpbc7NSE9lTXUdVbR3JCfFBLx9sf0ugq6YN5fFPNvC3D9awcecevjG+T9DrMLErmJL7hwC3AWOBhSLyhohcErbIjIkB20orKSqvisomMXBHEAAlrTxjbN7aHfTP6tKqmmg56clcdMQAXl60lTqfWmd+JxNUA6iqfq6qNwBH4q5facsFlsbEvMXexZMTB2ZGNI7G7LtKvxVNYz6fMn/9zlYdtfh972vDSPBOz7bk0rkEcxFlhohcLiJvA58C+bgkY0yntWjTLpIS4hjVu30GAAtWVpq7Sr81I1KuyC+jdG9Ni65vaUy/zC6cN6kfSQlxDM225NKZBNPnsgR4BbhTVeeFJxxjYsvizSUc2q8bSQnReRZUVhuaxfxj0LQluQDccdZYZkwdQpek4Pt8TOwK5hsxVFV/2lhi8aonG9Np1NT5WLa1NGr7W6BtzWLz1u5gcI9U+nRrWxXj1KQExrTT0M4megTTod/cKcLHtDEWY2LKqvxyqmp9UdvfApDpL7sfZLNYbZ2Pz9fvbPNRi+m8ovNY3pgIU1XufWcVs1Ztb3SeRZvd2fjRfOSSkhhPalJ80PXFVuSXUV5V2+j4LcY0x5KLMQ2Yk1vEg3PW8uOZi8kv3dvgPIs3lZCTnhz1g1+1pr7Y+ytcUm3LmWKmcwtlcomucrDGtJLPp9z7v1z6dkuh1qf84qVlDQ5+tWhzCRMGZAZVFiUSMlMTg+rQX729nIfmruPkMb3omZESxshMRxZ0chGRdBFp6JzC+0IQjzER98ayfFbml3HzqaO45dSRzMkt4sUvtx4wz67d1awv3h3V/S1+3dOSWnwqck2djxueX0zX5AR+d96hYY7MdGTBXOdyqIgsApYDK0RkoYiM809X1cfDEJ8x7aqmzsf/vZvLqN7pnHVYXy47ejBHDu7Ona9/xfayyn3zLd5SAkR3f4tfZmpSiwcMu39WHsu3lvG7cw8lu2tymCMzHVkwRy4PAzeo6iBVHYirjvxIeMIyJjL+u2ALG3bs4caTRxIXJ8TFCfdcMJ6qWh+3vry/eWzxphLiBMb3z4xswC3gyu433yy2ZHMJf5+dx3kT+3HquN7tEJnpyIJJLmmqOtt/R1Xn4IYmNqZDqKyp474PVjNpYCYnju657/Eh2WncdMpI3l9ZyKuLtwGuv2VEr3S6JgdzHXJkZKYmUbq3hto6X6PzVNbUccPzi+mZnsyvzxrbjtGZjiqY5LJORG4XkcHe323A+nAFZkx7e3LeBraXVXHzqaMO6qS/4pghTBqYyR2vf0VhWSVLvM78WNDdu9aldG/jRy/3vpPL2qLd3HvBeLp1SWyv0EwHFkxyuRLIAV4CXvZuXxGOoIxpb2WVNTw4Zy3Hjchp8NqO+Djh3gsOY091HVc/uYDSvTUx0ZkP7BtnprGmsU/XFvPYJ+u57OhBHHuIDSFuQqPFx/Te+C3XhzEWYyLm0bnrKNlTw82njGx0nuE9u/LTk0ZwzzurAJgwIKu9wmsTf9n9JZtLyOiSQI+0ZOK9SsXllTXc9N+lDO6Rys9PGxXJME0H02xyEZG/qupPROR14KCT/VX1rLBEZkw7Ka6o4tGP1/ONQ/swrl+3Jue9+tghvLM8n/XFu2OmhHy/THetys/+uwSAOIHsrsn0zEimplbJL93Lf6+dSmpS9PcfmdjRkk/TU97/P4UzEGMi5e+z86iq9XHDySOanTchPo5/X3Ek28sq9+39R7vhPdN5+8fHsnHHbgrLqygsq6KwvJLC8iqKK6r49ZljOXxQbByFmdjRbHJR1YXe/w/DH44x7Su/dC/PfLaJCyb1Z1hOy45Euqcl0d3rx4gVo/tkMLqPVSY27aclzWLLaKA5DFfuRVV1fMijMqadvLWsgOo6H9+fPizSoRjTobSkWeyMsEdhTITMyS1kWE4ag7Ptki1jQqnZU5FVdaP/D6gEDvX+9nqPGROT9lTXMn/dTo4f2bP5mY0xQQmmttg3gc+BC4FvAvNF5IJwBWZMuH2at4PqOh/Hj7LkYkyoBXPu4a3AEapaCCAiOcD7wAvhCMyYcJudW0hqUjyTB9uZUsaEWjBX6Mf5E4tnR5DLGxM1VJU5uUUcMzyb5IT4SIdjTIcTTHJ4R0T+JyIzRGQG8CbwVlMLiMhjIlIoIssbmf4dEVnq/X0qIocFEY8xrZZXWMHWkr3W32JMmDSbXEQkGUBVb8KV3R8PHAY8oqq3NLP448CpTUxfD3zNO535LqyEv2kns3PdQfj0kVZLy5hwaEmfyzxgkog8paqX4gpXtoiqzhWRwU1M/zTg7mdA/5au25i2mJNbxMhe6fTN7BLpUIzpkFqSXJJE5HJgqoicV3+iqrY42TTju8DbjU0UkWuAawAGDhwYoqc0nVF5ZQ1fbNjJldOGRDoUYzqsliSXa4HvAJnAmfWmKUEcyTRGRI7HJZdpjc2jqo/gNZtNnjy5oYoBxrTIJ3k7qKlT628xJoxaUlvsY+BjEflKVR8InObvj2kLERkPPAqcpqo72ro+Y5rz4epC0pMTrFijMWEU7GBh9c1ry5OLyEDckc+lqrq6LesypiVUldmriph2SDaJ8XYmvTHh0pLClb2BfkAXEZmIK1gJkAGkNrPsTGA6kC0iW4BfA4kAqvoQ8CugB/CgN6xsrapObtWWGNMCqwrKKSirtCYxY8KsJX0upwAzcGdy/Zn9yaUM+GVTC6rqxc1Mvwq4qgUxGBMSc3KLAPianYJsTFi1pM/lCRF5CrhYVZ9ph5iMCZvZuYWM6ZNBr4yUSIdiTIfWokZnVfUB3wtzLMaEVeneGhZu3MXxo+yoxZhwC6ZH8z0RuVFEBohId/9f2CIzJsQ+XlNMnc9OQTamPQRTFdl/ttgPAh5TYGjowjEmfObkFpKRksCEAZmRDsWYDq/FyUVV7XJmE7N8PmXO6iKOG5FDgp2CbEzYtTi5iEgi8H3gOO+hOcDDqloThriMCakV+WUUlVdZk5gx7SSYZrF/4K5RedC7f6n3mJ1KbKLe+yu3A3DcCOvMN6Y9BJNcjlDVwPFWZonIklAHZEyo5Zfu5dGP1nPciBxy0ttcscgY0wLBND7Xicgw/x0RGQrUhT4kY0JHVfnlS8uo8yl3nz0u0uEY02kEc+RyEzBbRNZ59wcDV4Q8ImNC6JXFW5mdW8TtZ4xhYI8mqxUZY0IomCOXT3AjUfq8v4dpY+FKY8KpqLyK37y+gkkDM5kxdXCkwzGmUwnmyOVJXD2xu7z7FwNPAReGOihjQuGO175iT1Ud914wnvg4aX4BY0zIBJNcRtbr0J9tHfomWr2zPJ83l+Vz0ykjGd4zPdLhGNPpBNMstkhEjvLfEZEpuKYyY6JKyZ5qbnvlK8b0yeCa46yAhDGREMyRyxTgMhHZ5N0fCKwUkWWAqur4kEdnTCvc9cZKSvZU88SVR9iAYMZESDDJ5dSwRWFMiMzOLeTFL7fww+OHM7Zvt0iHY0ynFUxtsY3hDMSYtiqvrOHWl5YxvGdXfnTi8EiHY0ynFsyRizFR7Z53VpFfVsmL359KckJ8pMMxplOzBmnTIcxbu4OnP9vElccMYdLArEiHY0ynZ8nFxLy91XX8/KWlDOyeyo0nj4x0OMYYrFnMdAD/914uG3fs4dmrp9AlyZrDjIkGduRiYtqiTbv418fr+faUgUwdlh3pcIwxHksuJmZV1dZx8wtL6ZWRwi9OGxXpcIwxAaxZzMSsv8/KY01hBf+ecQTpKYmRDscYE8COXExMWrGtjAfnrOW8if04fpQNXWxMtAlrchGRx0SkUESWNzJ9lIjME5EqEbkxnLGYjqO2zsfNLy4hMzWR288YE+lwjDENCPeRy+M0XTZmJ3A98Kcwx2E6kLeXF7B8axl3nDWWrLSkSIdjjGlAWJOLqs7FJZDGpheq6hdATTjjMB3Leyu20yMtidPG9Yl0KMaYRsRMn4uIXCMiC0RkQVFRUaTDMRFSU+djdm4hJ4zqaQOAGRPFYia5qOojqjpZVSfn5OREOhwTIZ+v30l5ZS0njekV6VCMMU2ImeRiDLgmseSEOI49xC6YNCaaWXIxMUNVeW/FdqYNzyY1yS7RMiaahfUbKiIzgelAtohsAX4NJAKo6kMi0htYAGQAPhH5CTBGVcvCGZeJTSvzy9laspcfnWBjtRgT7cKaXFT14mamFwD9wxmD6TjeX7kdEThhtF00aUy0s2YxEzPeW7GdCQMy6ZmeEulQjDHNsORiYkJ+6V6WbS3l63aWmDExwZKLiQnvrywE4OujLbkYEwssuZiY8P6K7Qzukcrwnl0jHYoxpgUsuZioV1FVy7y1OzhpdC9E7Kp8Y2KBJRcT9eauLqK6zmf9LcbEEEsuJuq9t2I7mamJHD4oK9KhGGNayJKLiWq1dT5mrXKFKhPi7eNqTKywb6uJal9s2EXp3ho7S8yYGGPJxUS191duJyk+juNGWCVsY2KJJRcTtfyFKqcO70FashWqNCaWWHIxUWtNYQWbdu6xs8SMiUGWXEzUem/FdgBOsv4WY2KOJRcTtd5als+EAZn0yrBClcbEGksuJiqtLargq21lnHlY30iHYoxpBUsuJiq9vmQbInDG+D6RDsUY0wqWXKJccUUVqhrpMA7g8yl/fX81y7eWhmX9qsrrS7YxZUh3axIzJkZZcmlHeYXlrNjW8hGc8wrLmfqHWdzy4tIwRhW8pz7byF/fX8P/vbc6LOtfkV/G2qLd1iRmTAyz5NJOdu6u5psPf8ZFj8yjsLyyRcvc9cZKqmt9PL9gC68s2hrmCFtmQ/Fu/vD2KpIT4vhwdRFF5VUhf47Xl+STECecNs6axIyJVZZc2sldb6ygbG8NVTU+fvvmymbnn72qkA9XF3HLqaM4YnAWt768jA3Fu9sh0sbV+ZSbXlhCQrzw6OWTqfMpry4ObdLzN4lNOySb7mlJIV23Mab9WHJpB7NXFfLyoq1cd/xwvj99GK8u3sbHa4obnb+mzsddb65gSHYa3502hPu+NZGE+Dh+OPNLqmrr2jHyA/37k/V8sWEXd5w5lmMPyWF8/268sHBLSJ/jy00lbC3Zy1nWJGZMTLPkEmbllTXc+vIyhvfsyg+OH8b3pw9jcI9Ubn91OZU1DSeKp+ZtZF3Rbm49fTRJCXH0zezCHy8Yz/KtZdzzdm47b4GTV1jBH/+Xy0mje3HepH4AnD+pP6sKgutHas7rS7aRlBBnV+UbE+MsuYTZve/kkl9WyT3njyc5IZ6UxHjuOmcc64t389CHaw+af+fuav76/mqOPSSbE0f33Pf4yWN7M2PqYB77ZD3ve1eut5faOh83/ncJXZLi+d154/aNBnnWYX1JjBde/DI0Ry91PuWNpfmcMLIn6SmJIVmnMSYyLLmE0efrd/LUZxuZMXXwAQNdHXtIDmcd1pcHZ69lfb1+lL+8t5rd1XX86owxBw3p+4vTRzG2bwY3vbCE/NK97bINAP/8aD2LN5dw59nj6Jm+/9TgrLQkThjVk1cXb6Wmztfm5/ls3Q6KK6o4a4I1iRkT6yy5hEllTR0/f3Ep/bO6cOPJIw+aftsZo0lOjOP2V5bvu44lt6CcZ+Zv5JIpAzmkV/pByyQnxHP/xROpqvXx4+cWUxuCH/Tm5BaU85f3VnPauN6c2cAFjedP6k9xRTVzVxe1+bleX7KNtKR4ThjVs/mZjTFRzeqYh8nfPljDuuLdPHnlkQ2Wi++ZnsLNp4zk9le/4rUl2zjrsL7c9cYK0lMS+clJIxpd79Ccrvz23HH89D9L+NHMRRw+KIt+mV3ok9mFvt1SyO6aTFycNLq8z6fU+HzU1ik1dT5q6pTaevdr6nzU+pTaOh+/eX0F6SkJ3H3OuIOOpACmj+xJVmoiL325lRPbUGCyutbH28sLOHlsb1IS41u9HmNMdAhrchGRx4AzgEJVHdfAdAHuA04H9gAzVPXLcMbUHpZvLeXhueu44PD+TQ5y9e0pg3hh4RbuemMltXXKx3nF3HHmGLKaOQX33In9+WprGc/M38TbywsOmJYYL/RIS8anSp0vIFF4ycLXiov9//GdSfTomtzgtKSEOM6e0I9n52+idE8N3VIb7ivZuGM3j360niuOGczQnK4HTf9oTRGle2s48zC7tsWYjkDCWVpERI4DKoAnG0kupwM/wiWXKcB9qjqlufVOnjxZFyxYEOpwQ6K2zsc5D35CQWkV799wHJmpTSeK5VtLOeuBj/EpDO/Zlbd/fCyJLRwrXlUp2VPDttK95JdUkl+6l22llRSXVxEfJyTECwlxcSTECQnx/v9Conc7MT6OxPj909z9OG8et2yvjBRG9j64iS7Qsi2lnPnAx9x9zjguOWrQQdOLK6o4/x+fsnHHHlIS47j1G2O4ZMrAA46EfvLcIuasLuLzX55EUoK11hoTDiKyUFUnt8dzhfXIRVXnisjgJmY5G5d4FPhMRDJFpI+q5oczrnB6YeEWlm8t4/6LJzabWADG9evG5VMH8+9PNnD7GWNanFgARISstCSy0pIY27dbW8Juk3H9MhjRqysvfbnloOSyp7qW7z7+BdvLKnnoksN5Zv5Gbn9lOR+s3M6954+nZ0YKe6vreHfFds6e0NcSizEdRKS/yf2AzQH3t3iPHURErhGRBSKyoKio7Z3H4bC7qpY/v7eaSQMzg6rme+vpo3nnJ8fytRgdJ15EOH9Sf77cVMK6oop9j9fW+fjhs4tYtrWU+y+exKnjevPklUdy59lj+WzdDk7+61zeXpbPrFWF7Kmus1pixnQgkU4uDfU8N9hOp6qPqOpkVZ2ckxOdP8KPzF1HUXkVt37j4NOIm5IQH8eo3hlhjCz8zpnYjziBl7505WBUldtfXc6sVYXcefa4fRdFigiXHT2YN350LAO7p/L9Z77ktleW0TM9mSlDekRyE4wxIRTp5LIFGBBwvz+wLUKxtElhWSWPzF3H6Yf2PuCals6iV0YK0w7J4eVFW/H5lAdm5THz881cN31Yg/0ww3t25cXvT+X6Ew+hrLKWcyf2I76Js9yMMbEl0qcivwb8UESew3Xol8Zqf8v/vbeaWp+Pm08ZFelQIub8Sf348XOL+eXLy3jui82cN7EfN51y8DU+fonxcdzw9RFcMmVgi/qnjDGxI9ynIs8EpgPZIrIF+DWQCKCqDwFv4c4Uy8OdinxFOOMJl9yCcp5fsJkZU4cwODst0uFEzClje5OenMBzX2xm2vBs/nD++BY1D/a0AcGM6XDCfbbYxc1MV+AH4Ywh0JebdvHg7LXcf/FEuiSF7kK937+9krTkBH50wvCQrTMWpSTGc8W0IXyxfif/uGSSnfllTCcW6WaxdpVfUsmsVdu59umF/POyySH58ft4TTFzcov45emjmr34sTO44euNVxcwxnQenWrX8hvj+/D78w7lw9VF/OQ/i9pcm6vOp/z2rZX0z+rCZUcPDk2QxhjTAXSqIxeAi44YSHllLXe/uZK0pGXcc/74JmtxNeXlRVtZmV/Gfd+aYPWwjDEmQKdLLgBXHTuU8spa7vtgDV1TEhosb9+c0j01/PndXA7r340zx9vFf8YYE6hTJheAn5x0COWVtTz2yXrSUxIb7SuorfOxYccecgvKWVVQxsr8cnK3l7F5pxtP5a8XTWj1kY8xxnRUnTa5iAi3nzGaiqoa/vbBGjJSEjhnYj9yC8pZmV/GqoJycgvKWb29nKpa1zcTHycMyU7jsP6ZfOuIgUwZ0p3Jg7tHeEuMMSb6hLUqcriEsipynU+5fuYi3lx24LWb2V2TGd0nnVG90xnZO4NRvdMZ3rOr9a0YY2JWh6mKHAvi44S/XDSBwwZ0I06E0X0yGNk7nexGxi8xxhjTvE6fXMANeHXNccMiHYYxxnQYneo6F2OMMe3DkosxxpiQs+RijDEm5Cy5GGOMCTlLLsYYY0LOkosxxpiQs+RijDEm5Cy5GGOMCbmYLP8iIkXARu9uNlAcwXAiyba98+rM29+Ztx3atv2DVDUnlME0JiaTSyARWdBetXKijW1759x26Nzb35m3HWJn+61ZzBhjTMhZcjHGGBNyHSG5PBLpACLItr3z6szb35m3HWJk+2O+z8UYY0z06QhHLsYYY6KMJRdjjDEhZ8nFGGNMyMVcchGRkSJytIgkiogNaA+IiEQ6hvYkIgNEJElE0rz7Mfc5bi3b9s657RB72x/VwdUnIucBrwJ3A/8CfiAiGZGNqv2JyBQR+ZqIHAGgqtpZEoyIfAN4G7gf+LeIjFRVX7R/0ULBtr1zbjvE5vZHbWD1iUgicBHwXVU9EZdkBgA3d6YEIyKnAU8D3wFuFZF/QcdPMOIMAP4A/BD4FTAfmC0iY6P9i9YWtu2dc9shtrc/KoNqQgZwiHf7ZeANIAn4dkf+YfXzmgEvB+5U1WuAy4CRIvICdOwEo+6c+W3APGANUKiqf8Z96d4VkRGq6otkjOESsO2f0Dm3fQvuB3U1nWjbwW2/qm7Gfe5javtjJrmoag3wf8B5InKs94J+DCwGpkUytvaiqnXAooD7Zao6DeglIg97j3W4C5dEZLjXBJgJdAO+499OVf0bcB/wSxFJ6WjJVUTGisjxwEAgC7i0E237NBG5zNveJFyrRafYdgAROVNEfuq12mQAM2Jp+2MmuXg+At4FLhWR41S1TlWfBfoCh0U2tPARkREBd7cCt4jIwIDHzgV6iMiY9o0s/ETkDOAl4E/Ab4BngOtE5BcBsz0PVKlqZUdKrl4T6Ezgp7htfwD4voj8PGC2DrftIhInIl2Bh3E/nhfiXoMrReS2gFk73Lb7icjJwF3ACm/H+ufAtSJyS8BsUb39CZEOIBiqWikizwAK/EJERgFVQC8gP6LBhYn34/q8iLymqt9S1adFZCTwiYgco6qbVLVYRGqB9AiHG1IiMhWXVC5W1UUi8ghwJDAV+MxrJnwOd+R6uIhkqequyEUcOiIyHbdneomqfi4irwM7gBOAj0SkGtcsPJUOtu1eq0SFiDwB1OF2ngQYDmwQkXLgLeAYOti2w77P/VPAmd57n41rGjwHeFNEaoiB9z4my7+ISBLug/U9oBK4T1UXNb1U7PFOOXwRt+c+FUhW1Yu9aXcBZwEP4sZ3uAQ4XVXXRyjckPO+ZCNU9XHvfg7wuKp+Q0SGArfh3v8jgStUdVnEgg0xERkN9FbV2SLSG9cc+iXwORAPDAPKgMnAlR1p2/1E5AZcc+DrwLXAZ7j3ei/gAw6lA267t/P4AfADXNP/C0At8BVQDgwlBt77mEwuft6eq0Zrh1YoiEhf3AcpBXgIqAlIMOcCvYHDgb+q6vKIBRoG3vubpqpl3u0+uB+a01U1X0QG4ZoJ01S1NJKxhpOI3Ir7rt4tIlcDk4B7VHVDtO61hoKIDAMuVNU/iMjPcJ3Yf1DV273pHXnbD8OdtJSEaxL9F3AVrvn/D6q6Odq3P6aTS2cjIj1wFVGrVfViERkLVKjqxmYWjXkikoBLsK+q6okicglwLPATVd0b2ejal4i8DdyuqgtERKKxvT0UvB2r3wKfAjfjTsE/AnhTVf/RkbcdwOtDPV5V/x7w2P+AX6jql9G+/THV59LZqeoOEfke8EcRycU1j0yPbFTtQ1Vrce3wm0Xk98DJuLNnOnRiqf8DIiLnAz1xbfAd8uxAP1XdJiKbgduBH6jq696Zc3ne9A677QCqugJY4b/vvffZuKP1qN9+O3KJQSLyU+AW4OvR2t4aat6plonASu//iaq6JrJRtR8RScb1q90AXNTRmkAb411A2FNVF3r34zpyM3hDvM/+FcCNuGbCryIcUotYcokxIpKFOwXxZ6q6NNLxtDcRmQF8EStfsFDxrnX4OrBWVXMjHU97i/YmoHDyksvXgAJVXRXpeFrKkksMEpEUVa2MdByR0Jl/ZIyJJZZcjDHGhFysXaFvjDEmBlhyMcYYE3KWXIwxxoScJRdjjDEhZ8nFmHYkInNEZHKk4zAm3Cy5GGOMCTlLLsY0QURuFpHrvdt/EZFZ3u0TReRpETlZROaJyJci8l9vHBJE5HAR+VBEForI/0SkT731xonIEyJyd/tvlTHhZ8nFmKbNxRXIBFfivKt3tfw0YBmu7P9JqjoJWADc4E2/H7hAVQ8HHsMVYPRLwA16tlpVAwe/MqbDsMKVxjRtIW5ApnTcwHRf4pLMscBrwBjcwG3gyqPPA0YC44D3vMfjOXAwu4eB51U1MOEY06FYcjGmCapaIyIbcIUDPwWWAsfjButaD7znH1/HT0QOBb5S1aMbWe2nwPEi8ufOWsbHdHzWLGZM8+biKtLOBT7CjYq4GDcy4jEiMhxARFJFZASQC+SIyNHe44ne2Dt+/8IN0/tfb5waYzocSy7GNO8j3CiY81R1O25o5Y9UtQiYAcwUkaW4ZDNKVauBC4B7RGQJLhFNDVyhqv4frontKRGx76HpcKxwpTHGmJCzPSZjjDEhZ8nFGGNMyFlyMcYYE3KWXIwxxoScJRdjjDEhZ8nFGGNMyFlyMcYYE3L/D1bhl2ML/CF3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-ufc winnings\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model_selection.metrics import MultiKellyPM\n",
    "\n",
    "kwargs = {\n",
    "    \"max_bankroll_fraction\": 0.05,\n",
    "    \"groupby_col\": \"week\",\n",
    "    \"fighter_ml_col\": fighter_ml_col,\n",
    "    \"opponent_ml_col\": opponent_ml_col,\n",
    "}\n",
    "\n",
    "print(\"overall winnings\")\n",
    "pm = MultiKellyPM(preds_df, **kwargs)\n",
    "event_return_df = pm.get_all_returns()\n",
    "pm.plot_diagnostics(event_return_df, x_col=\"week\")\n",
    "\n",
    "print(\"ufc winnings\")\n",
    "pm = MultiKellyPM(preds_df.query(\"is_ufc == 1\"), **kwargs)\n",
    "event_return_df = pm.get_all_returns()\n",
    "pm.plot_diagnostics(event_return_df, x_col=\"week\")\n",
    "\n",
    "print(\"non-ufc winnings\")\n",
    "pm = MultiKellyPM(preds_df.query(\"is_ufc == 0\"), **kwargs)\n",
    "event_return_df = pm.get_all_returns()\n",
    "pm.plot_diagnostics(event_return_df, x_col=\"week\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation - BetMGM, DraftKings, BetFair\n",
    "\n",
    "I think something's fishy here, this can't be right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16250, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "match_id               0.000000\n",
       "EventHref              0.000000\n",
       "DraftKings_fighter     0.765046\n",
       "BetMGM_fighter         0.792862\n",
       "Caesars_fighter        0.786954\n",
       "BetRivers_fighter      0.863877\n",
       "FanDuel_fighter        0.764554\n",
       "PointsBet_fighter      0.904000\n",
       "Unibet_fighter         0.813908\n",
       "BetWay_fighter         0.658954\n",
       "5D_fighter             0.086154\n",
       "Ref_fighter            0.018338\n",
       "FighterID_bfo          0.000000\n",
       "Bet365_fighter         0.902031\n",
       "DraftKings_opponent    0.765046\n",
       "BetMGM_opponent        0.792862\n",
       "Caesars_opponent       0.786954\n",
       "BetRivers_opponent     0.863877\n",
       "FanDuel_opponent       0.764554\n",
       "PointsBet_opponent     0.904000\n",
       "Unibet_opponent        0.813908\n",
       "BetWay_opponent        0.658954\n",
       "5D_opponent            0.086154\n",
       "Ref_opponent           0.018338\n",
       "OpponentID_bfo         0.000000\n",
       "Bet365_opponent        0.902031\n",
       "dtype: float64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_df = base_db_interface.read(\"clean_bfo_close_data\")\n",
    "# double the data\n",
    "fighter_cols = [c for c in close_df.columns if c.endswith(\"_fighter\")]\n",
    "opponent_cols = [c[:-len(\"_fighter\")] + \"_opponent\" for c in fighter_cols]\n",
    "for col in fighter_cols + opponent_cols:\n",
    "    close_df[col] = close_df[col].str.replace(\"▲\", \"\")\\\n",
    "        .str.replace(\"▼\", \"\")\\\n",
    "        .astype(float)\n",
    "    \n",
    "close_df_complement = close_df.rename(columns={\n",
    "    \"FighterID\": \"OpponentID\",\n",
    "    \"OpponentID\": \"FighterID\",\n",
    "    **{f: o for f, o in zip(fighter_cols, opponent_cols)},\n",
    "    **{o: f for f, o in zip(fighter_cols, opponent_cols)},\n",
    "})\n",
    "close_df = pd.concat([close_df, close_df_complement], axis=0)\\\n",
    "    .drop_duplicates(subset=[\"FighterID\", \"OpponentID\", \"EventHref\"])\\\n",
    "    .dropna(subset=[\"FighterID\", \"OpponentID\", \"EventHref\"])\\\n",
    "    .rename(columns={\"FighterID\": \"FighterID_bfo\", \"OpponentID\": \"OpponentID_bfo\"})\\\n",
    "    .drop(columns=[\"FighterName\", \"OpponentName\"])\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "print(close_df.shape)\n",
    "close_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122872            Calvin-Kattar-717\n",
       "122873                Wu-Yanan-8993\n",
       "122874             Justin-Tafa-9315\n",
       "122875           Jacob-Kilburn-8472\n",
       "122876           Ramazan-Emeev-7452\n",
       "                    ...            \n",
       "132966    Christian-Rodriquez-15110\n",
       "132967      Gerald-Meerschaert-3628\n",
       "132971        Cynthia-Calvillo-6940\n",
       "132980       Magomed-Umalatov-11254\n",
       "132981            David-Zawada-5347\n",
       "Name: FighterID_bfo, Length: 3022, dtype: object"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df[\"FighterID_bfo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fight_id_legacy    0.000000\n",
       "Date               0.000000\n",
       "FighterResult      0.000000\n",
       "Decision           0.000000\n",
       "Rnd                0.000000\n",
       "                     ...   \n",
       "Unibet_opponent    0.573461\n",
       "BetWay_opponent    0.269689\n",
       "5D_opponent        0.425215\n",
       "Ref_opponent       0.271013\n",
       "Bet365_opponent    0.795169\n",
       "Length: 410, dtype: float64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_preds_df = preds_df.merge(\n",
    "    close_df,\n",
    "    how=\"left\",\n",
    "    on=[\"FighterID_bfo\", \"OpponentID_bfo\", \"EventHref\"],\n",
    ")\n",
    "aug_preds_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DraftKings_fighter</th>\n",
       "      <th>BetMGM_fighter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16245</th>\n",
       "      <td>-365.0</td>\n",
       "      <td>-450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16246</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16247</th>\n",
       "      <td>-435.0</td>\n",
       "      <td>-450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16248</th>\n",
       "      <td>575.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16249</th>\n",
       "      <td>-900.0</td>\n",
       "      <td>-1200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DraftKings_fighter  BetMGM_fighter\n",
       "0                     NaN             NaN\n",
       "1                     NaN             NaN\n",
       "2                     NaN             NaN\n",
       "3                     NaN             NaN\n",
       "4                     NaN             NaN\n",
       "...                   ...             ...\n",
       "16245              -365.0          -450.0\n",
       "16246                 NaN          -450.0\n",
       "16247              -435.0          -450.0\n",
       "16248               575.0           600.0\n",
       "16249              -900.0         -1200.0\n",
       "\n",
       "[16250 rows x 2 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_df[[\"DraftKings_fighter\", \"BetMGM_fighter\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122872    115.0\n",
       "122873   -240.0\n",
       "122874   -105.0\n",
       "122875    225.0\n",
       "122876   -210.0\n",
       "          ...  \n",
       "132966    210.0\n",
       "132967    250.0\n",
       "132971    275.0\n",
       "132980   -900.0\n",
       "132981    125.0\n",
       "Name: FighterOpen, Length: 3022, dtype: object"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df[fighter_ml_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall winnings\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ufc winnings\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-ufc winnings\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "market = \"DraftKings\"\n",
    "# market = \"BetMGM\"\n",
    "\n",
    "kwargs = {\n",
    "    \"max_bankroll_fraction\": 1,\n",
    "    \"groupby_col\": \"week\",\n",
    "    \"fighter_ml_col\": f\"{market}_fighter\",\n",
    "    \"opponent_ml_col\": f\"{market}_opponent\",\n",
    "}\n",
    "\n",
    "temp_preds_df = aug_preds_df.dropna(subset=[\n",
    "    f\"{market}_fighter\", f\"{market}_opponent\"\n",
    "])\n",
    "temp_preds_df\n",
    "\n",
    "print(\"overall winnings\")\n",
    "pm = MultiKellyPM(temp_preds_df, **kwargs)\n",
    "event_return_df = pm.get_all_returns()\n",
    "pm.plot_diagnostics(event_return_df, x_col=\"week\")\n",
    "\n",
    "print(\"ufc winnings\")\n",
    "pm = MultiKellyPM(temp_preds_df.query(\"is_ufc == 1\"), **kwargs)\n",
    "event_return_df = pm.get_all_returns()\n",
    "pm.plot_diagnostics(event_return_df, x_col=\"week\")\n",
    "\n",
    "print(\"non-ufc winnings\")\n",
    "pm = MultiKellyPM(temp_preds_df.query(\"is_ufc == 0\"), **kwargs)\n",
    "event_return_df = pm.get_all_returns()\n",
    "pm.plot_diagnostics(event_return_df, x_col=\"week\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for upcoming fights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>pred_elo_PC_0</th>\n",
       "      <th>pred_elo_PC_1</th>\n",
       "      <th>pred_elo_PC_2</th>\n",
       "      <th>pred_elo_PC_3</th>\n",
       "      <th>pred_elo_PC_4</th>\n",
       "      <th>pred_elo_PC_5</th>\n",
       "      <th>pred_elo_PC_6</th>\n",
       "      <th>pred_elo_PC_7</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_elo_signed_inverse_fight_time</th>\n",
       "      <th>pred_elo_win_target</th>\n",
       "      <th>pred_elo_win_target_finish</th>\n",
       "      <th>age_diff</th>\n",
       "      <th>log_reach_diff</th>\n",
       "      <th>weight_diff</th>\n",
       "      <th>height_diff</th>\n",
       "      <th>log_t_since_prev_fight_diff</th>\n",
       "      <th>log_t_since_first_fight_diff</th>\n",
       "      <th>total_fights_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132984</th>\n",
       "      <td>4863327</td>\n",
       "      <td>3949555</td>\n",
       "      <td>-0.195705</td>\n",
       "      <td>-0.249167</td>\n",
       "      <td>-0.068994</td>\n",
       "      <td>0.682357</td>\n",
       "      <td>0.265850</td>\n",
       "      <td>0.332739</td>\n",
       "      <td>-0.606089</td>\n",
       "      <td>0.157302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000824</td>\n",
       "      <td>0.572789</td>\n",
       "      <td>0.529700</td>\n",
       "      <td>7.317808</td>\n",
       "      <td>0.081126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.528675</td>\n",
       "      <td>-0.510659</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132985</th>\n",
       "      <td>4397782</td>\n",
       "      <td>4040197</td>\n",
       "      <td>0.112259</td>\n",
       "      <td>0.714654</td>\n",
       "      <td>0.967333</td>\n",
       "      <td>-1.279557</td>\n",
       "      <td>0.390686</td>\n",
       "      <td>-0.224637</td>\n",
       "      <td>0.238147</td>\n",
       "      <td>0.725284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002596</td>\n",
       "      <td>0.507695</td>\n",
       "      <td>0.560020</td>\n",
       "      <td>1.295890</td>\n",
       "      <td>0.036368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084218</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132986</th>\n",
       "      <td>4232775</td>\n",
       "      <td>3994033</td>\n",
       "      <td>0.202585</td>\n",
       "      <td>0.976380</td>\n",
       "      <td>0.029361</td>\n",
       "      <td>-1.416281</td>\n",
       "      <td>-0.196303</td>\n",
       "      <td>-0.420252</td>\n",
       "      <td>0.437974</td>\n",
       "      <td>-0.305062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000838</td>\n",
       "      <td>0.543284</td>\n",
       "      <td>0.660596</td>\n",
       "      <td>-2.369863</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.354646</td>\n",
       "      <td>-0.046496</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132987</th>\n",
       "      <td>4076472</td>\n",
       "      <td>4063667</td>\n",
       "      <td>0.210980</td>\n",
       "      <td>0.391183</td>\n",
       "      <td>-0.089732</td>\n",
       "      <td>-0.591662</td>\n",
       "      <td>-0.648010</td>\n",
       "      <td>0.036722</td>\n",
       "      <td>0.744049</td>\n",
       "      <td>-0.196450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000849</td>\n",
       "      <td>0.543324</td>\n",
       "      <td>0.527520</td>\n",
       "      <td>-0.950685</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.507671</td>\n",
       "      <td>0.142094</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132988</th>\n",
       "      <td>3045734</td>\n",
       "      <td>3961293</td>\n",
       "      <td>-0.381281</td>\n",
       "      <td>-0.505066</td>\n",
       "      <td>0.555358</td>\n",
       "      <td>0.363368</td>\n",
       "      <td>0.224523</td>\n",
       "      <td>0.700904</td>\n",
       "      <td>0.680059</td>\n",
       "      <td>-0.225259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.421996</td>\n",
       "      <td>0.584334</td>\n",
       "      <td>-4.624658</td>\n",
       "      <td>-0.030305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.619535</td>\n",
       "      <td>0.358149</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132989</th>\n",
       "      <td>2335674</td>\n",
       "      <td>4690549</td>\n",
       "      <td>0.285680</td>\n",
       "      <td>-0.398737</td>\n",
       "      <td>0.437694</td>\n",
       "      <td>-1.458451</td>\n",
       "      <td>-0.138322</td>\n",
       "      <td>0.162732</td>\n",
       "      <td>-0.757358</td>\n",
       "      <td>-0.317639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.506069</td>\n",
       "      <td>0.417221</td>\n",
       "      <td>-12.665753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110348</td>\n",
       "      <td>0.809855</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132991</th>\n",
       "      <td>2594871</td>\n",
       "      <td>4227265</td>\n",
       "      <td>-0.194510</td>\n",
       "      <td>0.650643</td>\n",
       "      <td>-0.265063</td>\n",
       "      <td>-0.548014</td>\n",
       "      <td>0.247813</td>\n",
       "      <td>0.141773</td>\n",
       "      <td>0.096254</td>\n",
       "      <td>-1.325625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.500631</td>\n",
       "      <td>0.468554</td>\n",
       "      <td>-1.021918</td>\n",
       "      <td>0.061036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.375433</td>\n",
       "      <td>-0.061522</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132993</th>\n",
       "      <td>3900088</td>\n",
       "      <td>2526299</td>\n",
       "      <td>0.345742</td>\n",
       "      <td>0.411075</td>\n",
       "      <td>-0.050783</td>\n",
       "      <td>0.761484</td>\n",
       "      <td>-0.134104</td>\n",
       "      <td>-1.021289</td>\n",
       "      <td>-1.008232</td>\n",
       "      <td>0.382047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.514171</td>\n",
       "      <td>0.576980</td>\n",
       "      <td>2.882192</td>\n",
       "      <td>-0.068993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.164626</td>\n",
       "      <td>-0.320020</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132996</th>\n",
       "      <td>3902098</td>\n",
       "      <td>2614933</td>\n",
       "      <td>-0.981286</td>\n",
       "      <td>-0.950759</td>\n",
       "      <td>-0.842446</td>\n",
       "      <td>0.633129</td>\n",
       "      <td>-0.954096</td>\n",
       "      <td>-0.628756</td>\n",
       "      <td>0.892606</td>\n",
       "      <td>-0.476728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>0.480028</td>\n",
       "      <td>0.430665</td>\n",
       "      <td>2.136986</td>\n",
       "      <td>0.014389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.533062</td>\n",
       "      <td>-0.133283</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132997</th>\n",
       "      <td>4394200</td>\n",
       "      <td>4963343</td>\n",
       "      <td>0.321315</td>\n",
       "      <td>0.165845</td>\n",
       "      <td>-0.302548</td>\n",
       "      <td>0.084098</td>\n",
       "      <td>0.106047</td>\n",
       "      <td>0.583619</td>\n",
       "      <td>-0.376468</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001841</td>\n",
       "      <td>0.547239</td>\n",
       "      <td>0.502525</td>\n",
       "      <td>-6.315068</td>\n",
       "      <td>0.038915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.018780</td>\n",
       "      <td>0.409856</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132999</th>\n",
       "      <td>4089026</td>\n",
       "      <td>4816066</td>\n",
       "      <td>-1.073514</td>\n",
       "      <td>-0.620703</td>\n",
       "      <td>0.211283</td>\n",
       "      <td>-0.816519</td>\n",
       "      <td>0.877023</td>\n",
       "      <td>-0.425521</td>\n",
       "      <td>0.448058</td>\n",
       "      <td>0.218753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002225</td>\n",
       "      <td>0.420889</td>\n",
       "      <td>0.557077</td>\n",
       "      <td>2.512329</td>\n",
       "      <td>-0.007905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.142372</td>\n",
       "      <td>0.183711</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133003</th>\n",
       "      <td>4239928</td>\n",
       "      <td>3020090</td>\n",
       "      <td>0.088705</td>\n",
       "      <td>0.837004</td>\n",
       "      <td>-0.081885</td>\n",
       "      <td>0.039529</td>\n",
       "      <td>-0.063510</td>\n",
       "      <td>-0.524971</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>-0.584603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>0.381587</td>\n",
       "      <td>0.548625</td>\n",
       "      <td>-0.391781</td>\n",
       "      <td>0.029853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.942802</td>\n",
       "      <td>-0.174199</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133004</th>\n",
       "      <td>2512055</td>\n",
       "      <td>2335754</td>\n",
       "      <td>0.532863</td>\n",
       "      <td>0.326385</td>\n",
       "      <td>0.068641</td>\n",
       "      <td>-0.647781</td>\n",
       "      <td>-0.200518</td>\n",
       "      <td>-0.350859</td>\n",
       "      <td>0.444590</td>\n",
       "      <td>-0.384626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>0.618386</td>\n",
       "      <td>0.567531</td>\n",
       "      <td>3.835616</td>\n",
       "      <td>-0.026317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.442064</td>\n",
       "      <td>-0.259292</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133010</th>\n",
       "      <td>4418784</td>\n",
       "      <td>4292349</td>\n",
       "      <td>-0.058534</td>\n",
       "      <td>0.294277</td>\n",
       "      <td>-0.205873</td>\n",
       "      <td>0.369073</td>\n",
       "      <td>1.105809</td>\n",
       "      <td>0.260411</td>\n",
       "      <td>0.249523</td>\n",
       "      <td>0.678917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.412370</td>\n",
       "      <td>0.429623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206614</td>\n",
       "      <td>-0.514944</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133011</th>\n",
       "      <td>3151289</td>\n",
       "      <td>3922491</td>\n",
       "      <td>-0.599303</td>\n",
       "      <td>1.475839</td>\n",
       "      <td>-0.967742</td>\n",
       "      <td>0.014702</td>\n",
       "      <td>0.082234</td>\n",
       "      <td>0.185902</td>\n",
       "      <td>-0.429443</td>\n",
       "      <td>0.737151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001998</td>\n",
       "      <td>0.391191</td>\n",
       "      <td>0.510594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.253860</td>\n",
       "      <td>0.069939</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133012</th>\n",
       "      <td>2504643</td>\n",
       "      <td>4333158</td>\n",
       "      <td>0.096802</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>-0.012390</td>\n",
       "      <td>-0.223778</td>\n",
       "      <td>-0.185530</td>\n",
       "      <td>0.124228</td>\n",
       "      <td>-0.563981</td>\n",
       "      <td>-0.172217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.516288</td>\n",
       "      <td>0.298212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153586</td>\n",
       "      <td>0.205259</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133013</th>\n",
       "      <td>3970873</td>\n",
       "      <td>4688408</td>\n",
       "      <td>0.064634</td>\n",
       "      <td>-0.146394</td>\n",
       "      <td>-0.327473</td>\n",
       "      <td>-0.314480</td>\n",
       "      <td>0.571793</td>\n",
       "      <td>-0.969727</td>\n",
       "      <td>-0.644147</td>\n",
       "      <td>-0.022577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>0.537971</td>\n",
       "      <td>0.607369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889154</td>\n",
       "      <td>0.555333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133014</th>\n",
       "      <td>5060394</td>\n",
       "      <td>4324623</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>-0.173635</td>\n",
       "      <td>-0.246236</td>\n",
       "      <td>0.611450</td>\n",
       "      <td>0.029376</td>\n",
       "      <td>-0.293469</td>\n",
       "      <td>-0.144704</td>\n",
       "      <td>0.112844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.451117</td>\n",
       "      <td>0.480701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.497977</td>\n",
       "      <td>-0.736978</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133016</th>\n",
       "      <td>3922557</td>\n",
       "      <td>4217395</td>\n",
       "      <td>0.811043</td>\n",
       "      <td>-0.521314</td>\n",
       "      <td>0.688678</td>\n",
       "      <td>-0.772041</td>\n",
       "      <td>-0.924842</td>\n",
       "      <td>0.167326</td>\n",
       "      <td>0.041051</td>\n",
       "      <td>-0.088420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.534412</td>\n",
       "      <td>0.471930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664368</td>\n",
       "      <td>0.064518</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133017</th>\n",
       "      <td>3309918</td>\n",
       "      <td>4277049</td>\n",
       "      <td>0.266692</td>\n",
       "      <td>-0.070910</td>\n",
       "      <td>-0.008271</td>\n",
       "      <td>0.098454</td>\n",
       "      <td>1.143072</td>\n",
       "      <td>-0.191985</td>\n",
       "      <td>0.049392</td>\n",
       "      <td>-0.488933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.550576</td>\n",
       "      <td>0.620086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244263</td>\n",
       "      <td>0.361569</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133019</th>\n",
       "      <td>3894823</td>\n",
       "      <td>2502364</td>\n",
       "      <td>0.130970</td>\n",
       "      <td>-0.318741</td>\n",
       "      <td>0.264974</td>\n",
       "      <td>-0.204758</td>\n",
       "      <td>-0.554714</td>\n",
       "      <td>0.351630</td>\n",
       "      <td>1.418354</td>\n",
       "      <td>-0.401714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.511458</td>\n",
       "      <td>0.357717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053653</td>\n",
       "      <td>-0.222785</td>\n",
       "      <td>-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133020</th>\n",
       "      <td>4339130</td>\n",
       "      <td>2503659</td>\n",
       "      <td>0.593418</td>\n",
       "      <td>0.810061</td>\n",
       "      <td>-1.324708</td>\n",
       "      <td>1.662906</td>\n",
       "      <td>-1.107296</td>\n",
       "      <td>0.308445</td>\n",
       "      <td>-0.269646</td>\n",
       "      <td>0.517220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.408821</td>\n",
       "      <td>0.315391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.164308</td>\n",
       "      <td>-1.262711</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133021</th>\n",
       "      <td>3089069</td>\n",
       "      <td>3030256</td>\n",
       "      <td>-0.657081</td>\n",
       "      <td>-0.592595</td>\n",
       "      <td>-0.228173</td>\n",
       "      <td>0.164238</td>\n",
       "      <td>0.157888</td>\n",
       "      <td>-0.295335</td>\n",
       "      <td>-1.117541</td>\n",
       "      <td>0.123758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.398233</td>\n",
       "      <td>0.323180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.594022</td>\n",
       "      <td>-0.262904</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133022</th>\n",
       "      <td>4024488</td>\n",
       "      <td>5080935</td>\n",
       "      <td>-0.163086</td>\n",
       "      <td>0.291715</td>\n",
       "      <td>0.040737</td>\n",
       "      <td>-0.177596</td>\n",
       "      <td>-0.124726</td>\n",
       "      <td>-0.038337</td>\n",
       "      <td>0.315883</td>\n",
       "      <td>-0.280897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.440457</td>\n",
       "      <td>0.360446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027292</td>\n",
       "      <td>0.355801</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133025</th>\n",
       "      <td>4815974</td>\n",
       "      <td>4389093</td>\n",
       "      <td>-0.657956</td>\n",
       "      <td>-0.746681</td>\n",
       "      <td>0.398674</td>\n",
       "      <td>0.335451</td>\n",
       "      <td>-0.073774</td>\n",
       "      <td>0.162743</td>\n",
       "      <td>0.178847</td>\n",
       "      <td>0.537192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.456016</td>\n",
       "      <td>0.400476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712317</td>\n",
       "      <td>-0.901612</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133034</th>\n",
       "      <td>4375156</td>\n",
       "      <td>4686725</td>\n",
       "      <td>-0.019820</td>\n",
       "      <td>0.556889</td>\n",
       "      <td>0.191263</td>\n",
       "      <td>0.706798</td>\n",
       "      <td>-0.076375</td>\n",
       "      <td>0.164163</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.554404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>0.486330</td>\n",
       "      <td>0.560031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.050603</td>\n",
       "      <td>-0.027378</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133035</th>\n",
       "      <td>4835137</td>\n",
       "      <td>4012999</td>\n",
       "      <td>-0.243549</td>\n",
       "      <td>0.132756</td>\n",
       "      <td>0.828913</td>\n",
       "      <td>0.262290</td>\n",
       "      <td>1.633730</td>\n",
       "      <td>-0.290362</td>\n",
       "      <td>0.412471</td>\n",
       "      <td>-0.497415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.508694</td>\n",
       "      <td>0.401993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349184</td>\n",
       "      <td>-0.104183</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133036</th>\n",
       "      <td>2558075</td>\n",
       "      <td>4903365</td>\n",
       "      <td>0.147911</td>\n",
       "      <td>0.056638</td>\n",
       "      <td>0.130269</td>\n",
       "      <td>-1.129835</td>\n",
       "      <td>-0.065689</td>\n",
       "      <td>0.484352</td>\n",
       "      <td>0.012530</td>\n",
       "      <td>0.163817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>0.543451</td>\n",
       "      <td>0.599235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121890</td>\n",
       "      <td>1.049269</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133037</th>\n",
       "      <td>4251462</td>\n",
       "      <td>2517186</td>\n",
       "      <td>0.165704</td>\n",
       "      <td>0.569984</td>\n",
       "      <td>-0.608713</td>\n",
       "      <td>-0.955094</td>\n",
       "      <td>0.774204</td>\n",
       "      <td>-0.695898</td>\n",
       "      <td>0.266996</td>\n",
       "      <td>0.132750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.398662</td>\n",
       "      <td>0.404082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.835501</td>\n",
       "      <td>-0.461602</td>\n",
       "      <td>-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133039</th>\n",
       "      <td>4914568</td>\n",
       "      <td>4702563</td>\n",
       "      <td>0.219062</td>\n",
       "      <td>0.759179</td>\n",
       "      <td>-0.001518</td>\n",
       "      <td>0.400720</td>\n",
       "      <td>-0.156865</td>\n",
       "      <td>0.096837</td>\n",
       "      <td>0.471451</td>\n",
       "      <td>-0.102770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002336</td>\n",
       "      <td>0.415307</td>\n",
       "      <td>0.513223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285991</td>\n",
       "      <td>-0.706106</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133040</th>\n",
       "      <td>4227055</td>\n",
       "      <td>4034272</td>\n",
       "      <td>0.457317</td>\n",
       "      <td>0.834310</td>\n",
       "      <td>-0.451403</td>\n",
       "      <td>0.590604</td>\n",
       "      <td>0.782637</td>\n",
       "      <td>-0.339107</td>\n",
       "      <td>-0.273679</td>\n",
       "      <td>0.292134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003406</td>\n",
       "      <td>0.494078</td>\n",
       "      <td>0.574159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173272</td>\n",
       "      <td>0.208359</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133041</th>\n",
       "      <td>2988175</td>\n",
       "      <td>4406574</td>\n",
       "      <td>-0.043845</td>\n",
       "      <td>0.520167</td>\n",
       "      <td>0.217524</td>\n",
       "      <td>-0.965000</td>\n",
       "      <td>0.505374</td>\n",
       "      <td>-0.239545</td>\n",
       "      <td>-0.556433</td>\n",
       "      <td>-0.638585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000598</td>\n",
       "      <td>0.381165</td>\n",
       "      <td>0.418910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.113944</td>\n",
       "      <td>0.503882</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133042</th>\n",
       "      <td>4426250</td>\n",
       "      <td>4684474</td>\n",
       "      <td>0.019640</td>\n",
       "      <td>-0.775182</td>\n",
       "      <td>0.577893</td>\n",
       "      <td>0.159711</td>\n",
       "      <td>-0.244184</td>\n",
       "      <td>-0.093082</td>\n",
       "      <td>1.441984</td>\n",
       "      <td>-0.586338</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000828</td>\n",
       "      <td>0.541631</td>\n",
       "      <td>0.548498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.835501</td>\n",
       "      <td>0.438607</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133043</th>\n",
       "      <td>4875506</td>\n",
       "      <td>4788300</td>\n",
       "      <td>-0.003243</td>\n",
       "      <td>-0.289146</td>\n",
       "      <td>0.241639</td>\n",
       "      <td>-0.335586</td>\n",
       "      <td>-0.151699</td>\n",
       "      <td>0.480890</td>\n",
       "      <td>0.339751</td>\n",
       "      <td>-0.014289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000646</td>\n",
       "      <td>0.480145</td>\n",
       "      <td>0.490172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.027292</td>\n",
       "      <td>0.908553</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133046</th>\n",
       "      <td>4419372</td>\n",
       "      <td>3028863</td>\n",
       "      <td>0.882613</td>\n",
       "      <td>-0.245899</td>\n",
       "      <td>-0.084419</td>\n",
       "      <td>-1.801159</td>\n",
       "      <td>-0.421756</td>\n",
       "      <td>-0.629837</td>\n",
       "      <td>-0.266369</td>\n",
       "      <td>0.771705</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001004</td>\n",
       "      <td>0.577750</td>\n",
       "      <td>0.582803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232059</td>\n",
       "      <td>-0.546031</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133054</th>\n",
       "      <td>2951202</td>\n",
       "      <td>4081024</td>\n",
       "      <td>-0.122876</td>\n",
       "      <td>0.344964</td>\n",
       "      <td>-0.207511</td>\n",
       "      <td>-0.455348</td>\n",
       "      <td>0.505773</td>\n",
       "      <td>0.014431</td>\n",
       "      <td>-0.273535</td>\n",
       "      <td>0.666618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003052</td>\n",
       "      <td>0.636970</td>\n",
       "      <td>0.670309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.221724</td>\n",
       "      <td>0.486626</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133055</th>\n",
       "      <td>4379258</td>\n",
       "      <td>4289516</td>\n",
       "      <td>0.313306</td>\n",
       "      <td>1.668011</td>\n",
       "      <td>0.238057</td>\n",
       "      <td>-0.932895</td>\n",
       "      <td>-0.193452</td>\n",
       "      <td>0.208198</td>\n",
       "      <td>0.587217</td>\n",
       "      <td>-0.659940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.532897</td>\n",
       "      <td>0.345214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.671047</td>\n",
       "      <td>-0.198674</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133056</th>\n",
       "      <td>2504169</td>\n",
       "      <td>3085551</td>\n",
       "      <td>-0.175675</td>\n",
       "      <td>-0.268599</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.566623</td>\n",
       "      <td>0.537921</td>\n",
       "      <td>1.281252</td>\n",
       "      <td>0.577633</td>\n",
       "      <td>0.793715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.559849</td>\n",
       "      <td>0.697334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117873</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133057</th>\n",
       "      <td>4032401</td>\n",
       "      <td>4421978</td>\n",
       "      <td>-0.377505</td>\n",
       "      <td>-1.312164</td>\n",
       "      <td>0.367624</td>\n",
       "      <td>-0.307423</td>\n",
       "      <td>-0.478049</td>\n",
       "      <td>-1.443996</td>\n",
       "      <td>0.521851</td>\n",
       "      <td>0.346934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.446873</td>\n",
       "      <td>0.389356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.667093</td>\n",
       "      <td>0.184483</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133058</th>\n",
       "      <td>3953381</td>\n",
       "      <td>4245092</td>\n",
       "      <td>0.023338</td>\n",
       "      <td>-0.670303</td>\n",
       "      <td>-0.277535</td>\n",
       "      <td>-0.608048</td>\n",
       "      <td>0.641021</td>\n",
       "      <td>-0.186049</td>\n",
       "      <td>-0.890652</td>\n",
       "      <td>0.148667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002313</td>\n",
       "      <td>0.549372</td>\n",
       "      <td>0.460165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.046213</td>\n",
       "      <td>-0.025136</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133059</th>\n",
       "      <td>3031559</td>\n",
       "      <td>3023388</td>\n",
       "      <td>0.630170</td>\n",
       "      <td>-0.044230</td>\n",
       "      <td>0.160650</td>\n",
       "      <td>-0.172191</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.184488</td>\n",
       "      <td>-0.466574</td>\n",
       "      <td>0.109992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.569104</td>\n",
       "      <td>0.550174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.713478</td>\n",
       "      <td>0.247692</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133060</th>\n",
       "      <td>4245094</td>\n",
       "      <td>3971496</td>\n",
       "      <td>0.203367</td>\n",
       "      <td>-0.219879</td>\n",
       "      <td>-1.728134</td>\n",
       "      <td>0.602505</td>\n",
       "      <td>-0.470242</td>\n",
       "      <td>1.383190</td>\n",
       "      <td>-0.217612</td>\n",
       "      <td>0.632655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.500925</td>\n",
       "      <td>0.634977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608110</td>\n",
       "      <td>-0.406027</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133065</th>\n",
       "      <td>5074126</td>\n",
       "      <td>4783385</td>\n",
       "      <td>-0.056904</td>\n",
       "      <td>-0.278366</td>\n",
       "      <td>0.242566</td>\n",
       "      <td>-0.321009</td>\n",
       "      <td>-0.185009</td>\n",
       "      <td>-0.059651</td>\n",
       "      <td>0.153842</td>\n",
       "      <td>0.123760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000297</td>\n",
       "      <td>0.520426</td>\n",
       "      <td>0.511591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.519636</td>\n",
       "      <td>0.412738</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133066</th>\n",
       "      <td>4321051</td>\n",
       "      <td>5076593</td>\n",
       "      <td>-0.479688</td>\n",
       "      <td>-0.066555</td>\n",
       "      <td>0.989041</td>\n",
       "      <td>-0.253741</td>\n",
       "      <td>-0.123955</td>\n",
       "      <td>-0.148609</td>\n",
       "      <td>0.038582</td>\n",
       "      <td>0.302530</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000827</td>\n",
       "      <td>0.382280</td>\n",
       "      <td>0.467848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272779</td>\n",
       "      <td>0.096828</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133068</th>\n",
       "      <td>3913473</td>\n",
       "      <td>4684776</td>\n",
       "      <td>0.763423</td>\n",
       "      <td>0.183209</td>\n",
       "      <td>0.384434</td>\n",
       "      <td>-0.633261</td>\n",
       "      <td>0.194807</td>\n",
       "      <td>-0.317664</td>\n",
       "      <td>0.031905</td>\n",
       "      <td>0.013964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>0.443114</td>\n",
       "      <td>0.454842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.216808</td>\n",
       "      <td>-0.180734</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133071</th>\n",
       "      <td>4275487</td>\n",
       "      <td>3024395</td>\n",
       "      <td>-0.625163</td>\n",
       "      <td>0.289565</td>\n",
       "      <td>0.255464</td>\n",
       "      <td>0.268661</td>\n",
       "      <td>-0.186597</td>\n",
       "      <td>-0.654163</td>\n",
       "      <td>-0.229661</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.489869</td>\n",
       "      <td>0.415550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.027786</td>\n",
       "      <td>0.216503</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133073</th>\n",
       "      <td>4687003</td>\n",
       "      <td>4881997</td>\n",
       "      <td>0.382454</td>\n",
       "      <td>-0.412174</td>\n",
       "      <td>0.419772</td>\n",
       "      <td>-0.704622</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>-0.067649</td>\n",
       "      <td>-0.587148</td>\n",
       "      <td>0.320651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.535505</td>\n",
       "      <td>0.508242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.175009</td>\n",
       "      <td>-0.234475</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133078</th>\n",
       "      <td>4306125</td>\n",
       "      <td>4815998</td>\n",
       "      <td>0.430175</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>0.020797</td>\n",
       "      <td>0.122686</td>\n",
       "      <td>-0.342395</td>\n",
       "      <td>0.482577</td>\n",
       "      <td>1.142052</td>\n",
       "      <td>0.185939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.493297</td>\n",
       "      <td>0.542998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.758530</td>\n",
       "      <td>0.615629</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133079</th>\n",
       "      <td>3115931</td>\n",
       "      <td>4021217</td>\n",
       "      <td>0.479946</td>\n",
       "      <td>1.099809</td>\n",
       "      <td>1.654416</td>\n",
       "      <td>-0.171943</td>\n",
       "      <td>0.203370</td>\n",
       "      <td>1.725225</td>\n",
       "      <td>-0.698627</td>\n",
       "      <td>0.767611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.417181</td>\n",
       "      <td>0.410370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.328504</td>\n",
       "      <td>0.284359</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133080</th>\n",
       "      <td>3146944</td>\n",
       "      <td>2512976</td>\n",
       "      <td>0.619807</td>\n",
       "      <td>0.528609</td>\n",
       "      <td>0.260285</td>\n",
       "      <td>0.360597</td>\n",
       "      <td>-0.528526</td>\n",
       "      <td>-0.009197</td>\n",
       "      <td>0.713280</td>\n",
       "      <td>-0.306213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.402384</td>\n",
       "      <td>0.397964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.935573</td>\n",
       "      <td>-0.479448</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133081</th>\n",
       "      <td>4873640</td>\n",
       "      <td>4410084</td>\n",
       "      <td>0.019379</td>\n",
       "      <td>-0.697238</td>\n",
       "      <td>0.692133</td>\n",
       "      <td>-1.162415</td>\n",
       "      <td>0.314892</td>\n",
       "      <td>0.196571</td>\n",
       "      <td>0.023354</td>\n",
       "      <td>0.602986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>0.594137</td>\n",
       "      <td>0.574962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.316037</td>\n",
       "      <td>-0.031966</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133082</th>\n",
       "      <td>4426312</td>\n",
       "      <td>4738092</td>\n",
       "      <td>-0.071143</td>\n",
       "      <td>-0.105174</td>\n",
       "      <td>0.226470</td>\n",
       "      <td>0.139899</td>\n",
       "      <td>0.096431</td>\n",
       "      <td>-0.010048</td>\n",
       "      <td>0.792512</td>\n",
       "      <td>-0.672556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002990</td>\n",
       "      <td>0.560121</td>\n",
       "      <td>0.548809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984344</td>\n",
       "      <td>0.624639</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133084</th>\n",
       "      <td>3090893</td>\n",
       "      <td>4046059</td>\n",
       "      <td>-0.514279</td>\n",
       "      <td>0.045537</td>\n",
       "      <td>0.456830</td>\n",
       "      <td>-0.824749</td>\n",
       "      <td>-0.339423</td>\n",
       "      <td>0.332397</td>\n",
       "      <td>-0.178514</td>\n",
       "      <td>0.678643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002185</td>\n",
       "      <td>0.507349</td>\n",
       "      <td>0.667098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.005953</td>\n",
       "      <td>0.332274</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133085</th>\n",
       "      <td>3088232</td>\n",
       "      <td>2500946</td>\n",
       "      <td>-0.363337</td>\n",
       "      <td>-0.168818</td>\n",
       "      <td>-1.722193</td>\n",
       "      <td>1.532001</td>\n",
       "      <td>0.190395</td>\n",
       "      <td>-1.475967</td>\n",
       "      <td>0.117545</td>\n",
       "      <td>-0.439120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>0.544109</td>\n",
       "      <td>0.457917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.239779</td>\n",
       "      <td>-0.431805</td>\n",
       "      <td>-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133088</th>\n",
       "      <td>2335666</td>\n",
       "      <td>2504639</td>\n",
       "      <td>-0.262384</td>\n",
       "      <td>-0.043037</td>\n",
       "      <td>-0.112755</td>\n",
       "      <td>1.874633</td>\n",
       "      <td>-0.728907</td>\n",
       "      <td>1.372556</td>\n",
       "      <td>-1.303580</td>\n",
       "      <td>0.125084</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001088</td>\n",
       "      <td>0.505921</td>\n",
       "      <td>0.555496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226773</td>\n",
       "      <td>0.120628</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133089</th>\n",
       "      <td>4668069</td>\n",
       "      <td>3155846</td>\n",
       "      <td>-0.308709</td>\n",
       "      <td>-0.837457</td>\n",
       "      <td>0.404753</td>\n",
       "      <td>-0.200344</td>\n",
       "      <td>0.464319</td>\n",
       "      <td>0.783454</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>-0.674187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.546297</td>\n",
       "      <td>0.474824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024015</td>\n",
       "      <td>-0.134321</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133092</th>\n",
       "      <td>4695736</td>\n",
       "      <td>4873642</td>\n",
       "      <td>0.640564</td>\n",
       "      <td>0.827686</td>\n",
       "      <td>0.150212</td>\n",
       "      <td>-0.497430</td>\n",
       "      <td>0.427796</td>\n",
       "      <td>-0.325431</td>\n",
       "      <td>-0.407120</td>\n",
       "      <td>-0.088253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000615</td>\n",
       "      <td>0.380141</td>\n",
       "      <td>0.362549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482098</td>\n",
       "      <td>0.346808</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133098</th>\n",
       "      <td>2516131</td>\n",
       "      <td>2951361</td>\n",
       "      <td>0.443042</td>\n",
       "      <td>-0.700990</td>\n",
       "      <td>0.176203</td>\n",
       "      <td>-1.212771</td>\n",
       "      <td>-0.458434</td>\n",
       "      <td>-0.098586</td>\n",
       "      <td>1.531828</td>\n",
       "      <td>-0.365694</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001708</td>\n",
       "      <td>0.691412</td>\n",
       "      <td>0.646887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079714</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133100</th>\n",
       "      <td>2560746</td>\n",
       "      <td>3027545</td>\n",
       "      <td>-0.415478</td>\n",
       "      <td>-0.020843</td>\n",
       "      <td>0.940490</td>\n",
       "      <td>-0.412782</td>\n",
       "      <td>0.128540</td>\n",
       "      <td>0.924691</td>\n",
       "      <td>-0.142310</td>\n",
       "      <td>-0.718087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001123</td>\n",
       "      <td>0.503709</td>\n",
       "      <td>0.502376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710743</td>\n",
       "      <td>0.269782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FighterID_espn OpponentID_espn  pred_elo_PC_0  pred_elo_PC_1  \\\n",
       "132984        4863327         3949555      -0.195705      -0.249167   \n",
       "132985        4397782         4040197       0.112259       0.714654   \n",
       "132986        4232775         3994033       0.202585       0.976380   \n",
       "132987        4076472         4063667       0.210980       0.391183   \n",
       "132988        3045734         3961293      -0.381281      -0.505066   \n",
       "132989        2335674         4690549       0.285680      -0.398737   \n",
       "132991        2594871         4227265      -0.194510       0.650643   \n",
       "132993        3900088         2526299       0.345742       0.411075   \n",
       "132996        3902098         2614933      -0.981286      -0.950759   \n",
       "132997        4394200         4963343       0.321315       0.165845   \n",
       "132999        4089026         4816066      -1.073514      -0.620703   \n",
       "133003        4239928         3020090       0.088705       0.837004   \n",
       "133004        2512055         2335754       0.532863       0.326385   \n",
       "133010        4418784         4292349      -0.058534       0.294277   \n",
       "133011        3151289         3922491      -0.599303       1.475839   \n",
       "133012        2504643         4333158       0.096802       0.010190   \n",
       "133013        3970873         4688408       0.064634      -0.146394   \n",
       "133014        5060394         4324623       0.002017      -0.173635   \n",
       "133016        3922557         4217395       0.811043      -0.521314   \n",
       "133017        3309918         4277049       0.266692      -0.070910   \n",
       "133019        3894823         2502364       0.130970      -0.318741   \n",
       "133020        4339130         2503659       0.593418       0.810061   \n",
       "133021        3089069         3030256      -0.657081      -0.592595   \n",
       "133022        4024488         5080935      -0.163086       0.291715   \n",
       "133025        4815974         4389093      -0.657956      -0.746681   \n",
       "133034        4375156         4686725      -0.019820       0.556889   \n",
       "133035        4835137         4012999      -0.243549       0.132756   \n",
       "133036        2558075         4903365       0.147911       0.056638   \n",
       "133037        4251462         2517186       0.165704       0.569984   \n",
       "133039        4914568         4702563       0.219062       0.759179   \n",
       "133040        4227055         4034272       0.457317       0.834310   \n",
       "133041        2988175         4406574      -0.043845       0.520167   \n",
       "133042        4426250         4684474       0.019640      -0.775182   \n",
       "133043        4875506         4788300      -0.003243      -0.289146   \n",
       "133046        4419372         3028863       0.882613      -0.245899   \n",
       "133054        2951202         4081024      -0.122876       0.344964   \n",
       "133055        4379258         4289516       0.313306       1.668011   \n",
       "133056        2504169         3085551      -0.175675      -0.268599   \n",
       "133057        4032401         4421978      -0.377505      -1.312164   \n",
       "133058        3953381         4245092       0.023338      -0.670303   \n",
       "133059        3031559         3023388       0.630170      -0.044230   \n",
       "133060        4245094         3971496       0.203367      -0.219879   \n",
       "133065        5074126         4783385      -0.056904      -0.278366   \n",
       "133066        4321051         5076593      -0.479688      -0.066555   \n",
       "133068        3913473         4684776       0.763423       0.183209   \n",
       "133071        4275487         3024395      -0.625163       0.289565   \n",
       "133073        4687003         4881997       0.382454      -0.412174   \n",
       "133078        4306125         4815998       0.430175      -0.010858   \n",
       "133079        3115931         4021217       0.479946       1.099809   \n",
       "133080        3146944         2512976       0.619807       0.528609   \n",
       "133081        4873640         4410084       0.019379      -0.697238   \n",
       "133082        4426312         4738092      -0.071143      -0.105174   \n",
       "133084        3090893         4046059      -0.514279       0.045537   \n",
       "133085        3088232         2500946      -0.363337      -0.168818   \n",
       "133088        2335666         2504639      -0.262384      -0.043037   \n",
       "133089        4668069         3155846      -0.308709      -0.837457   \n",
       "133092        4695736         4873642       0.640564       0.827686   \n",
       "133098        2516131         2951361       0.443042      -0.700990   \n",
       "133100        2560746         3027545      -0.415478      -0.020843   \n",
       "\n",
       "        pred_elo_PC_2  pred_elo_PC_3  pred_elo_PC_4  pred_elo_PC_5  \\\n",
       "132984      -0.068994       0.682357       0.265850       0.332739   \n",
       "132985       0.967333      -1.279557       0.390686      -0.224637   \n",
       "132986       0.029361      -1.416281      -0.196303      -0.420252   \n",
       "132987      -0.089732      -0.591662      -0.648010       0.036722   \n",
       "132988       0.555358       0.363368       0.224523       0.700904   \n",
       "132989       0.437694      -1.458451      -0.138322       0.162732   \n",
       "132991      -0.265063      -0.548014       0.247813       0.141773   \n",
       "132993      -0.050783       0.761484      -0.134104      -1.021289   \n",
       "132996      -0.842446       0.633129      -0.954096      -0.628756   \n",
       "132997      -0.302548       0.084098       0.106047       0.583619   \n",
       "132999       0.211283      -0.816519       0.877023      -0.425521   \n",
       "133003      -0.081885       0.039529      -0.063510      -0.524971   \n",
       "133004       0.068641      -0.647781      -0.200518      -0.350859   \n",
       "133010      -0.205873       0.369073       1.105809       0.260411   \n",
       "133011      -0.967742       0.014702       0.082234       0.185902   \n",
       "133012      -0.012390      -0.223778      -0.185530       0.124228   \n",
       "133013      -0.327473      -0.314480       0.571793      -0.969727   \n",
       "133014      -0.246236       0.611450       0.029376      -0.293469   \n",
       "133016       0.688678      -0.772041      -0.924842       0.167326   \n",
       "133017      -0.008271       0.098454       1.143072      -0.191985   \n",
       "133019       0.264974      -0.204758      -0.554714       0.351630   \n",
       "133020      -1.324708       1.662906      -1.107296       0.308445   \n",
       "133021      -0.228173       0.164238       0.157888      -0.295335   \n",
       "133022       0.040737      -0.177596      -0.124726      -0.038337   \n",
       "133025       0.398674       0.335451      -0.073774       0.162743   \n",
       "133034       0.191263       0.706798      -0.076375       0.164163   \n",
       "133035       0.828913       0.262290       1.633730      -0.290362   \n",
       "133036       0.130269      -1.129835      -0.065689       0.484352   \n",
       "133037      -0.608713      -0.955094       0.774204      -0.695898   \n",
       "133039      -0.001518       0.400720      -0.156865       0.096837   \n",
       "133040      -0.451403       0.590604       0.782637      -0.339107   \n",
       "133041       0.217524      -0.965000       0.505374      -0.239545   \n",
       "133042       0.577893       0.159711      -0.244184      -0.093082   \n",
       "133043       0.241639      -0.335586      -0.151699       0.480890   \n",
       "133046      -0.084419      -1.801159      -0.421756      -0.629837   \n",
       "133054      -0.207511      -0.455348       0.505773       0.014431   \n",
       "133055       0.238057      -0.932895      -0.193452       0.208198   \n",
       "133056       0.608406       0.566623       0.537921       1.281252   \n",
       "133057       0.367624      -0.307423      -0.478049      -1.443996   \n",
       "133058      -0.277535      -0.608048       0.641021      -0.186049   \n",
       "133059       0.160650      -0.172191       0.131000       0.184488   \n",
       "133060      -1.728134       0.602505      -0.470242       1.383190   \n",
       "133065       0.242566      -0.321009      -0.185009      -0.059651   \n",
       "133066       0.989041      -0.253741      -0.123955      -0.148609   \n",
       "133068       0.384434      -0.633261       0.194807      -0.317664   \n",
       "133071       0.255464       0.268661      -0.186597      -0.654163   \n",
       "133073       0.419772      -0.704622       0.018410      -0.067649   \n",
       "133078       0.020797       0.122686      -0.342395       0.482577   \n",
       "133079       1.654416      -0.171943       0.203370       1.725225   \n",
       "133080       0.260285       0.360597      -0.528526      -0.009197   \n",
       "133081       0.692133      -1.162415       0.314892       0.196571   \n",
       "133082       0.226470       0.139899       0.096431      -0.010048   \n",
       "133084       0.456830      -0.824749      -0.339423       0.332397   \n",
       "133085      -1.722193       1.532001       0.190395      -1.475967   \n",
       "133088      -0.112755       1.874633      -0.728907       1.372556   \n",
       "133089       0.404753      -0.200344       0.464319       0.783454   \n",
       "133092       0.150212      -0.497430       0.427796      -0.325431   \n",
       "133098       0.176203      -1.212771      -0.458434      -0.098586   \n",
       "133100       0.940490      -0.412782       0.128540       0.924691   \n",
       "\n",
       "        pred_elo_PC_6  pred_elo_PC_7  ...  pred_elo_signed_inverse_fight_time  \\\n",
       "132984      -0.606089       0.157302  ...                           -0.000824   \n",
       "132985       0.238147       0.725284  ...                           -0.002596   \n",
       "132986       0.437974      -0.305062  ...                           -0.000838   \n",
       "132987       0.744049      -0.196450  ...                           -0.000849   \n",
       "132988       0.680059      -0.225259  ...                            0.000486   \n",
       "132989      -0.757358      -0.317639  ...                            0.000959   \n",
       "132991       0.096254      -1.325625  ...                            0.000098   \n",
       "132993      -1.008232       0.382047  ...                            0.000154   \n",
       "132996       0.892606      -0.476728  ...                           -0.001054   \n",
       "132997      -0.376468       0.366369  ...                           -0.001841   \n",
       "132999       0.448058       0.218753  ...                           -0.002225   \n",
       "133003       0.013639      -0.584603  ...                           -0.001938   \n",
       "133004       0.444590      -0.384626  ...                           -0.000105   \n",
       "133010       0.249523       0.678917  ...                            0.001402   \n",
       "133011      -0.429443       0.737151  ...                           -0.001998   \n",
       "133012      -0.563981      -0.172217  ...                            0.000778   \n",
       "133013      -0.644147      -0.022577  ...                           -0.000212   \n",
       "133014      -0.144704       0.112844  ...                            0.000290   \n",
       "133016       0.041051      -0.088420  ...                            0.004192   \n",
       "133017       0.049392      -0.488933  ...                            0.003077   \n",
       "133019       1.418354      -0.401714  ...                            0.001126   \n",
       "133020      -0.269646       0.517220  ...                            0.000042   \n",
       "133021      -1.117541       0.123758  ...                            0.005731   \n",
       "133022       0.315883      -0.280897  ...                            0.002353   \n",
       "133025       0.178847       0.537192  ...                            0.002851   \n",
       "133034       0.268000       0.554404  ...                           -0.000294   \n",
       "133035       0.412471      -0.497415  ...                            0.004100   \n",
       "133036       0.012530       0.163817  ...                           -0.007304   \n",
       "133037       0.266996       0.132750  ...                            0.000943   \n",
       "133039       0.471451      -0.102770  ...                           -0.002336   \n",
       "133040      -0.273679       0.292134  ...                           -0.003406   \n",
       "133041      -0.556433      -0.638585  ...                           -0.000598   \n",
       "133042       1.441984      -0.586338  ...                           -0.000828   \n",
       "133043       0.339751      -0.014289  ...                           -0.000646   \n",
       "133046      -0.266369       0.771705  ...                           -0.001004   \n",
       "133054      -0.273535       0.666618  ...                           -0.003052   \n",
       "133055       0.587217      -0.659940  ...                            0.000565   \n",
       "133056       0.577633       0.793715  ...                           -0.002761   \n",
       "133057       0.521851       0.346934  ...                            0.000843   \n",
       "133058      -0.890652       0.148667  ...                           -0.002313   \n",
       "133059      -0.466574       0.109992  ...                            0.002305   \n",
       "133060      -0.217612       0.632655  ...                            0.001144   \n",
       "133065       0.153842       0.123760  ...                           -0.000297   \n",
       "133066       0.038582       0.302530  ...                           -0.000827   \n",
       "133068       0.031905       0.013964  ...                           -0.000496   \n",
       "133071      -0.229661       0.006536  ...                            0.001436   \n",
       "133073      -0.587148       0.320651  ...                            0.001567   \n",
       "133078       1.142052       0.185939  ...                            0.002073   \n",
       "133079      -0.698627       0.767611  ...                            0.000749   \n",
       "133080       0.713280      -0.306213  ...                            0.000419   \n",
       "133081       0.023354       0.602986  ...                            0.003814   \n",
       "133082       0.792512      -0.672556  ...                           -0.002990   \n",
       "133084      -0.178514       0.678643  ...                           -0.002185   \n",
       "133085       0.117545      -0.439120  ...                           -0.000229   \n",
       "133088      -1.303580       0.125084  ...                           -0.001088   \n",
       "133089       0.113100      -0.674187  ...                            0.000868   \n",
       "133092      -0.407120      -0.088253  ...                           -0.000615   \n",
       "133098       1.531828      -0.365694  ...                           -0.001708   \n",
       "133100      -0.142310      -0.718087  ...                           -0.001123   \n",
       "\n",
       "        pred_elo_win_target  pred_elo_win_target_finish   age_diff  \\\n",
       "132984             0.572789                    0.529700   7.317808   \n",
       "132985             0.507695                    0.560020   1.295890   \n",
       "132986             0.543284                    0.660596  -2.369863   \n",
       "132987             0.543324                    0.527520  -0.950685   \n",
       "132988             0.421996                    0.584334  -4.624658   \n",
       "132989             0.506069                    0.417221 -12.665753   \n",
       "132991             0.500631                    0.468554  -1.021918   \n",
       "132993             0.514171                    0.576980   2.882192   \n",
       "132996             0.480028                    0.430665   2.136986   \n",
       "132997             0.547239                    0.502525  -6.315068   \n",
       "132999             0.420889                    0.557077   2.512329   \n",
       "133003             0.381587                    0.548625  -0.391781   \n",
       "133004             0.618386                    0.567531   3.835616   \n",
       "133010             0.412370                    0.429623   0.000000   \n",
       "133011             0.391191                    0.510594   0.000000   \n",
       "133012             0.516288                    0.298212   0.000000   \n",
       "133013             0.537971                    0.607369   0.000000   \n",
       "133014             0.451117                    0.480701   0.000000   \n",
       "133016             0.534412                    0.471930   0.000000   \n",
       "133017             0.550576                    0.620086   0.000000   \n",
       "133019             0.511458                    0.357717   0.000000   \n",
       "133020             0.408821                    0.315391   0.000000   \n",
       "133021             0.398233                    0.323180   0.000000   \n",
       "133022             0.440457                    0.360446   0.000000   \n",
       "133025             0.456016                    0.400476   0.000000   \n",
       "133034             0.486330                    0.560031   0.000000   \n",
       "133035             0.508694                    0.401993   0.000000   \n",
       "133036             0.543451                    0.599235   0.000000   \n",
       "133037             0.398662                    0.404082   0.000000   \n",
       "133039             0.415307                    0.513223   0.000000   \n",
       "133040             0.494078                    0.574159   0.000000   \n",
       "133041             0.381165                    0.418910   0.000000   \n",
       "133042             0.541631                    0.548498   0.000000   \n",
       "133043             0.480145                    0.490172   0.000000   \n",
       "133046             0.577750                    0.582803   0.000000   \n",
       "133054             0.636970                    0.670309   0.000000   \n",
       "133055             0.532897                    0.345214   0.000000   \n",
       "133056             0.559849                    0.697334   0.000000   \n",
       "133057             0.446873                    0.389356   0.000000   \n",
       "133058             0.549372                    0.460165   0.000000   \n",
       "133059             0.569104                    0.550174   0.000000   \n",
       "133060             0.500925                    0.634977   0.000000   \n",
       "133065             0.520426                    0.511591   0.000000   \n",
       "133066             0.382280                    0.467848   0.000000   \n",
       "133068             0.443114                    0.454842   0.000000   \n",
       "133071             0.489869                    0.415550   0.000000   \n",
       "133073             0.535505                    0.508242   0.000000   \n",
       "133078             0.493297                    0.542998   0.000000   \n",
       "133079             0.417181                    0.410370   0.000000   \n",
       "133080             0.402384                    0.397964   0.000000   \n",
       "133081             0.594137                    0.574962   0.000000   \n",
       "133082             0.560121                    0.548809   0.000000   \n",
       "133084             0.507349                    0.667098   0.000000   \n",
       "133085             0.544109                    0.457917   0.000000   \n",
       "133088             0.505921                    0.555496   0.000000   \n",
       "133089             0.546297                    0.474824   0.000000   \n",
       "133092             0.380141                    0.362549   0.000000   \n",
       "133098             0.691412                    0.646887   0.000000   \n",
       "133100             0.503709                    0.502376   0.000000   \n",
       "\n",
       "        log_reach_diff  weight_diff  height_diff  log_t_since_prev_fight_diff  \\\n",
       "132984        0.081126          0.0          4.0                    -0.528675   \n",
       "132985        0.036368          0.0          0.0                     0.084218   \n",
       "132986        0.006645          0.0          1.0                     0.354646   \n",
       "132987        0.013793          0.0          3.0                     0.507671   \n",
       "132988       -0.030305          0.0         -3.0                     0.619535   \n",
       "132989        0.000000          0.0          0.0                     0.110348   \n",
       "132991        0.061036          0.0          5.0                    -0.375433   \n",
       "132993       -0.068993          0.0         -1.0                    -1.164626   \n",
       "132996        0.014389          0.0         -3.0                    -0.533062   \n",
       "132997        0.038915          0.0          4.0                     0.018780   \n",
       "132999       -0.007905          0.0          2.0                     0.142372   \n",
       "133003        0.029853          0.0          3.0                     0.942802   \n",
       "133004       -0.026317          0.0         -1.0                     0.442064   \n",
       "133010        0.000000          0.0          0.0                     0.206614   \n",
       "133011        0.000000          0.0          0.0                    -0.253860   \n",
       "133012        0.000000          0.0          0.0                     0.153586   \n",
       "133013        0.000000          0.0          0.0                     0.889154   \n",
       "133014        0.000000          0.0          0.0                    -0.497977   \n",
       "133016        0.000000          0.0          0.0                     0.664368   \n",
       "133017        0.000000          0.0          0.0                     0.244263   \n",
       "133019        0.000000          0.0          0.0                     0.053653   \n",
       "133020        0.000000          0.0          0.0                    -1.164308   \n",
       "133021        0.000000          0.0          0.0                    -0.594022   \n",
       "133022        0.000000          0.0          0.0                     0.027292   \n",
       "133025        0.000000          0.0          0.0                    -0.712317   \n",
       "133034        0.000000          0.0          0.0                    -1.050603   \n",
       "133035        0.000000          0.0          0.0                     0.349184   \n",
       "133036        0.000000          0.0          0.0                     0.121890   \n",
       "133037        0.000000          0.0          0.0                    -0.835501   \n",
       "133039        0.000000          0.0          0.0                     0.285991   \n",
       "133040        0.000000          0.0          0.0                     0.173272   \n",
       "133041        0.000000          0.0          0.0                    -0.113944   \n",
       "133042        0.000000          0.0          0.0                     0.835501   \n",
       "133043        0.000000          0.0          0.0                    -0.027292   \n",
       "133046        0.000000          0.0          0.0                    -0.232059   \n",
       "133054        0.000000          0.0          0.0                    -0.221724   \n",
       "133055        0.000000          0.0          0.0                    -0.671047   \n",
       "133056        0.000000          0.0          0.0                     0.000000   \n",
       "133057        0.000000          0.0          0.0                     1.667093   \n",
       "133058        0.000000          0.0          0.0                    -0.046213   \n",
       "133059        0.000000          0.0          0.0                    -1.713478   \n",
       "133060        0.000000          0.0          0.0                     0.608110   \n",
       "133065        0.000000          0.0          0.0                    -0.519636   \n",
       "133066        0.000000          0.0          0.0                    -0.272779   \n",
       "133068        0.000000          0.0          0.0                    -0.216808   \n",
       "133071        0.000000          0.0          0.0                     1.027786   \n",
       "133073        0.000000          0.0          0.0                    -0.175009   \n",
       "133078        0.000000          0.0          0.0                     0.758530   \n",
       "133079        0.000000          0.0          0.0                    -0.328504   \n",
       "133080        0.000000          0.0          0.0                    -0.935573   \n",
       "133081        0.000000          0.0          0.0                    -0.316037   \n",
       "133082        0.000000          0.0          0.0                     0.984344   \n",
       "133084        0.000000          0.0          0.0                     1.005953   \n",
       "133085        0.000000          0.0          0.0                    -0.239779   \n",
       "133088        0.000000          0.0          0.0                     0.226773   \n",
       "133089        0.000000          0.0          0.0                     0.024015   \n",
       "133092        0.000000          0.0          0.0                     0.482098   \n",
       "133098        0.000000          0.0          0.0                     0.000000   \n",
       "133100        0.000000          0.0          0.0                     0.710743   \n",
       "\n",
       "        log_t_since_first_fight_diff  total_fights_diff  \n",
       "132984                     -0.510659                 -7  \n",
       "132985                     -0.146069                 -5  \n",
       "132986                     -0.046496                  3  \n",
       "132987                      0.142094                 -3  \n",
       "132988                      0.358149                  4  \n",
       "132989                      0.809855                 39  \n",
       "132991                     -0.061522                 13  \n",
       "132993                     -0.320020                -12  \n",
       "132996                     -0.133283                -10  \n",
       "132997                      0.409856                  3  \n",
       "132999                      0.183711                  9  \n",
       "133003                     -0.174199                 -3  \n",
       "133004                     -0.259292                -12  \n",
       "133010                     -0.514944                -10  \n",
       "133011                      0.069939                  5  \n",
       "133012                      0.205259                 -3  \n",
       "133013                      0.555333                 -1  \n",
       "133014                     -0.736978                 -6  \n",
       "133016                      0.064518                  3  \n",
       "133017                      0.361569                  3  \n",
       "133019                     -0.222785                -19  \n",
       "133020                     -1.262711                -26  \n",
       "133021                     -0.262904                 -1  \n",
       "133022                      0.355801                 -7  \n",
       "133025                     -0.901612                 -7  \n",
       "133034                     -0.027378                 -2  \n",
       "133035                     -0.104183                 -9  \n",
       "133036                      1.049269                 21  \n",
       "133037                     -0.461602                -23  \n",
       "133039                     -0.706106                 -3  \n",
       "133040                      0.208359                 -1  \n",
       "133041                      0.503882                  9  \n",
       "133042                      0.438607                 -1  \n",
       "133043                      0.908553                  5  \n",
       "133046                     -0.546031                 -1  \n",
       "133054                      0.486626                 24  \n",
       "133055                     -0.198674                 -1  \n",
       "133056                      0.117873                 16  \n",
       "133057                      0.184483                -14  \n",
       "133058                     -0.025136                 -1  \n",
       "133059                      0.247692                  7  \n",
       "133060                     -0.406027                 -7  \n",
       "133065                      0.412738                  2  \n",
       "133066                      0.096828                 11  \n",
       "133068                     -0.180734                  2  \n",
       "133071                      0.216503                -13  \n",
       "133073                     -0.234475                  3  \n",
       "133078                      0.615629                  4  \n",
       "133079                      0.284359                 12  \n",
       "133080                     -0.479448                -26  \n",
       "133081                     -0.031966                  3  \n",
       "133082                      0.624639                  9  \n",
       "133084                      0.332274                  7  \n",
       "133085                     -0.431805                -17  \n",
       "133088                      0.120628                 11  \n",
       "133089                     -0.134321                 -7  \n",
       "133092                      0.346808                -14  \n",
       "133098                      0.079714                 10  \n",
       "133100                      0.269782                  1  \n",
       "\n",
       "[59 rows x 26 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feat_ml_df.query(\"Date == '2023-04-15'\")[[\"FighterName\", \"OpponentName\"]]\n",
    "feat_ml_df.query(\"is_upcoming == 1\")[[\"FighterID_espn\", \"OpponentID_espn\", *feat_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12915, 384), (13, 384))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from wrangle.clean_bfo_data import parse_american_odds\n",
    "\n",
    "train_df = feat_ml_df.query(\"is_upcoming == 0\")\\\n",
    "    .dropna(subset=[\n",
    "        *feat_cols, \"win_target\", p_fighter_implied_col\n",
    "    ], how=\"any\")\n",
    "test_df = feat_ml_df.query(\"Date == '2023-04-15'\").copy()\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -27421.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.71080858, 0.4167712 , 0.59135897, 0.52973717, 0.18859853,\n",
       "       0.28878326, 0.66659051, 0.63481703, 0.44319354, 0.5662856 ,\n",
       "       0.40209936, 0.39251686, 0.77878135])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7651.29      0.003545       1.65107           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7651.28   0.000445495      0.173913      0.8069      0.8069       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "mod = SimpleSymmetricModel(\n",
    "    feat_cols=feat_cols, target_col=\"win_target\", \n",
    "    p_fighter_implied_col=p_fighter_implied_col,\n",
    "    beta_prior_std=1.0, mcmc=False\n",
    ")\n",
    "\n",
    "y_pred = mod.fit_predict(train_df, test_df, feat_cols)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterName</th>\n",
       "      <th>OpponentName</th>\n",
       "      <th>FighterOpen</th>\n",
       "      <th>OpponentOpen</th>\n",
       "      <th>p_fighter_open_implied</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132984</th>\n",
       "      <td>daniel zellhuber</td>\n",
       "      <td>lando vannata</td>\n",
       "      <td>-175</td>\n",
       "      <td>+150</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.710809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132985</th>\n",
       "      <td>joselyne edwards</td>\n",
       "      <td>lucie pudilova</td>\n",
       "      <td>+150</td>\n",
       "      <td>-175</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.416771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132986</th>\n",
       "      <td>tanner boser</td>\n",
       "      <td>ion curelaba</td>\n",
       "      <td>-160</td>\n",
       "      <td>+140</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.591359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132987</th>\n",
       "      <td>bill algeo</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>-139</td>\n",
       "      <td>+119</td>\n",
       "      <td>0.560185</td>\n",
       "      <td>0.529737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132988</th>\n",
       "      <td>pedro munhoz</td>\n",
       "      <td>chris gutierrez</td>\n",
       "      <td>+200</td>\n",
       "      <td>-235</td>\n",
       "      <td>0.322115</td>\n",
       "      <td>0.188599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132989</th>\n",
       "      <td>clay guida</td>\n",
       "      <td>rafa garcia</td>\n",
       "      <td>+140</td>\n",
       "      <td>-160</td>\n",
       "      <td>0.403727</td>\n",
       "      <td>0.288783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132991</th>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>azamat murzakanov</td>\n",
       "      <td>-200</td>\n",
       "      <td>+170</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.666591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132993</th>\n",
       "      <td>billy quarantillo</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>-155</td>\n",
       "      <td>+135</td>\n",
       "      <td>0.588212</td>\n",
       "      <td>0.634817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132996</th>\n",
       "      <td>arnold allen</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>+125</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.428884</td>\n",
       "      <td>0.443194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132997</th>\n",
       "      <td>bruna brasil</td>\n",
       "      <td>denise gomes</td>\n",
       "      <td>-160</td>\n",
       "      <td>+140</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.566286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132999</th>\n",
       "      <td>gillian robertson</td>\n",
       "      <td>piera rodriguez</td>\n",
       "      <td>+115</td>\n",
       "      <td>-135</td>\n",
       "      <td>0.447406</td>\n",
       "      <td>0.402099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133003</th>\n",
       "      <td>brandon royval</td>\n",
       "      <td>matheus nicolau</td>\n",
       "      <td>+125</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.428884</td>\n",
       "      <td>0.392517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133004</th>\n",
       "      <td>zak cummings</td>\n",
       "      <td>ed herman</td>\n",
       "      <td>-250</td>\n",
       "      <td>+210</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.778781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FighterName       OpponentName FighterOpen OpponentOpen  \\\n",
       "132984   daniel zellhuber      lando vannata        -175         +150   \n",
       "132985   joselyne edwards     lucie pudilova        +150         -175   \n",
       "132986       tanner boser       ion curelaba        -160         +140   \n",
       "132987         bill algeo           tj brown        -139         +119   \n",
       "132988       pedro munhoz    chris gutierrez        +200         -235   \n",
       "132989         clay guida        rafa garcia        +140         -160   \n",
       "132991      dustin jacoby  azamat murzakanov        -200         +170   \n",
       "132993  billy quarantillo      edson barboza        -155         +135   \n",
       "132996       arnold allen       max holloway        +125         -145   \n",
       "132997       bruna brasil       denise gomes        -160         +140   \n",
       "132999  gillian robertson    piera rodriguez        +115         -135   \n",
       "133003     brandon royval    matheus nicolau        +125         -145   \n",
       "133004       zak cummings          ed herman        -250         +210   \n",
       "\n",
       "        p_fighter_open_implied    y_pred  \n",
       "132984                0.614035  0.710809  \n",
       "132985                0.385965  0.416771  \n",
       "132986                0.596273  0.591359  \n",
       "132987                0.560185  0.529737  \n",
       "132988                0.322115  0.188599  \n",
       "132989                0.403727  0.288783  \n",
       "132991                0.642857  0.666591  \n",
       "132993                0.588212  0.634817  \n",
       "132996                0.428884  0.443194  \n",
       "132997                0.596273  0.566286  \n",
       "132999                0.447406  0.402099  \n",
       "133003                0.428884  0.392517  \n",
       "133004                0.688889  0.778781  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = test_df.assign(y_pred = y_pred)\n",
    "preds_df[[\"FighterName\", \"OpponentName\", \n",
    "          \"FighterOpen\", \"OpponentOpen\", \n",
    "          p_fighter_implied_col, \"y_pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterName</th>\n",
       "      <th>OpponentName</th>\n",
       "      <th>DraftKings_fighter</th>\n",
       "      <th>DraftKings_opponent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daniel zellhuber</td>\n",
       "      <td>lando vannata</td>\n",
       "      <td>-130</td>\n",
       "      <td>+110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joselyne edwards</td>\n",
       "      <td>lucie pudilova</td>\n",
       "      <td>+115</td>\n",
       "      <td>-135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tanner boser</td>\n",
       "      <td>ion curelaba</td>\n",
       "      <td>+110</td>\n",
       "      <td>-130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bill algeo</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>-190</td>\n",
       "      <td>+160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pedro munhoz</td>\n",
       "      <td>chris gutierrez</td>\n",
       "      <td>+170</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clay guida</td>\n",
       "      <td>rafa garcia</td>\n",
       "      <td>+215</td>\n",
       "      <td>-255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>azamat murzakanov</td>\n",
       "      <td>-150</td>\n",
       "      <td>+130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>billy quarantillo</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>-170</td>\n",
       "      <td>+145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arnold allen</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>+140</td>\n",
       "      <td>-165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bruna brasil</td>\n",
       "      <td>denise gomes</td>\n",
       "      <td>-150</td>\n",
       "      <td>+130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gillian robertson</td>\n",
       "      <td>piera rodriguez</td>\n",
       "      <td>-125</td>\n",
       "      <td>+105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>brandon royval</td>\n",
       "      <td>matheus nicolau</td>\n",
       "      <td>+170</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zak cummings</td>\n",
       "      <td>ed herman</td>\n",
       "      <td>-225</td>\n",
       "      <td>+190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FighterName       OpponentName DraftKings_fighter  \\\n",
       "0    daniel zellhuber      lando vannata               -130   \n",
       "1    joselyne edwards     lucie pudilova               +115   \n",
       "2        tanner boser       ion curelaba               +110   \n",
       "3          bill algeo           tj brown               -190   \n",
       "4        pedro munhoz    chris gutierrez               +170   \n",
       "5          clay guida        rafa garcia               +215   \n",
       "6       dustin jacoby  azamat murzakanov               -150   \n",
       "7   billy quarantillo      edson barboza               -170   \n",
       "8        arnold allen       max holloway               +140   \n",
       "9        bruna brasil       denise gomes               -150   \n",
       "10  gillian robertson    piera rodriguez               -125   \n",
       "11     brandon royval    matheus nicolau               +170   \n",
       "12       zak cummings          ed herman               -225   \n",
       "\n",
       "   DraftKings_opponent  \n",
       "0                 +110  \n",
       "1                 -135  \n",
       "2                 -130  \n",
       "3                 +160  \n",
       "4                 -200  \n",
       "5                 -255  \n",
       "6                 +130  \n",
       "7                 +145  \n",
       "8                 -165  \n",
       "9                 +130  \n",
       "10                +105  \n",
       "11                -200  \n",
       "12                +190  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df = pd.DataFrame([['daniel zellhuber', 'lando vannata', \"-130\", \"+110\"],\n",
    "['joselyne edwards', 'lucie pudilova', \"+115\", \"-135\"],\n",
    "['tanner boser', 'ion curelaba', \"+110\", \"-130\"],\n",
    "['bill algeo', 'tj brown', \"-190\", \"+160\"],\n",
    "['pedro munhoz', 'chris gutierrez', \"+170\", \"-200\"],\n",
    "['clay guida', 'rafa garcia', \"+215\", \"-255\"],\n",
    "['dustin jacoby', 'azamat murzakanov', \"-150\", \"+130\"],\n",
    "['billy quarantillo', 'edson barboza', \"-170\", \"+145\"],\n",
    "['arnold allen', 'max holloway', \"+140\", \"-165\"],\n",
    "['bruna brasil', 'denise gomes', \"-150\", \"+130\"],\n",
    "['gillian robertson', 'piera rodriguez', \"-125\", \"+105\"],\n",
    "['brandon royval', 'matheus nicolau', \"+170\", \"-200\"],\n",
    "['zak cummings', 'ed herman', \"-225\", \"+190\"]], \n",
    "columns=[\"FighterName\", \"OpponentName\", \"DraftKings_fighter\", \"DraftKings_opponent\"])\n",
    "ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight_id_legacy</th>\n",
       "      <th>Date</th>\n",
       "      <th>FighterResult</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Rnd</th>\n",
       "      <th>Time</th>\n",
       "      <th>Event</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>TSL</th>\n",
       "      <th>...</th>\n",
       "      <th>age_diff</th>\n",
       "      <th>log_reach_diff</th>\n",
       "      <th>weight_diff</th>\n",
       "      <th>height_diff</th>\n",
       "      <th>t_since_first_fight_diff</th>\n",
       "      <th>log_t_since_first_fight_diff</th>\n",
       "      <th>log_t_since_prev_fight_diff</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>DraftKings_fighter</th>\n",
       "      <th>DraftKings_opponent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-15_3949555_4863327</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3949555</td>\n",
       "      <td>4863327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.317808</td>\n",
       "      <td>0.081126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1596</td>\n",
       "      <td>-0.510659</td>\n",
       "      <td>-0.528675</td>\n",
       "      <td>0.710809</td>\n",
       "      <td>-130</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-15_4040197_4397782</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4040197</td>\n",
       "      <td>4397782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295890</td>\n",
       "      <td>0.036368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-455</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>0.084218</td>\n",
       "      <td>0.416771</td>\n",
       "      <td>115</td>\n",
       "      <td>-135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-15_3994033_4232775</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3994033</td>\n",
       "      <td>4232775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.369863</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-183</td>\n",
       "      <td>-0.046496</td>\n",
       "      <td>0.354646</td>\n",
       "      <td>0.591359</td>\n",
       "      <td>110</td>\n",
       "      <td>-130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-15_4063667_4076472</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4063667</td>\n",
       "      <td>4076472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.950685</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>526</td>\n",
       "      <td>0.142094</td>\n",
       "      <td>0.507671</td>\n",
       "      <td>0.529737</td>\n",
       "      <td>-190</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-15_3045734_3961293</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3961293</td>\n",
       "      <td>3045734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.624658</td>\n",
       "      <td>-0.030305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1547</td>\n",
       "      <td>0.358149</td>\n",
       "      <td>0.619535</td>\n",
       "      <td>0.188599</td>\n",
       "      <td>170</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-04-15_2335674_4690549</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4690549</td>\n",
       "      <td>2335674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.665753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3870</td>\n",
       "      <td>0.809855</td>\n",
       "      <td>0.110348</td>\n",
       "      <td>0.288783</td>\n",
       "      <td>215</td>\n",
       "      <td>-255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-04-15_2594871_4227265</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4227265</td>\n",
       "      <td>2594871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.021918</td>\n",
       "      <td>0.061036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-287</td>\n",
       "      <td>-0.061522</td>\n",
       "      <td>-0.375433</td>\n",
       "      <td>0.666591</td>\n",
       "      <td>-150</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-04-15_2526299_3900088</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>2526299</td>\n",
       "      <td>3900088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.882192</td>\n",
       "      <td>-0.068993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1400</td>\n",
       "      <td>-0.320020</td>\n",
       "      <td>-1.164626</td>\n",
       "      <td>0.634817</td>\n",
       "      <td>-170</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-04-15_2614933_3902098</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>2614933</td>\n",
       "      <td>3902098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.136986</td>\n",
       "      <td>0.014389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-574</td>\n",
       "      <td>-0.133283</td>\n",
       "      <td>-0.533062</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>140</td>\n",
       "      <td>-165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-04-15_4394200_4963343</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4963343</td>\n",
       "      <td>4394200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.315068</td>\n",
       "      <td>0.038915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1036</td>\n",
       "      <td>0.409856</td>\n",
       "      <td>0.018780</td>\n",
       "      <td>0.566286</td>\n",
       "      <td>-150</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-04-15_4089026_4816066</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4816066</td>\n",
       "      <td>4089026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.512329</td>\n",
       "      <td>-0.007905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>435</td>\n",
       "      <td>0.183711</td>\n",
       "      <td>0.142372</td>\n",
       "      <td>0.402099</td>\n",
       "      <td>-125</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-04-15_3020090_4239928</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3020090</td>\n",
       "      <td>4239928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391781</td>\n",
       "      <td>0.029853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-741</td>\n",
       "      <td>-0.174199</td>\n",
       "      <td>0.942802</td>\n",
       "      <td>0.392517</td>\n",
       "      <td>170</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-04-15_2335754_2512055</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>2335754</td>\n",
       "      <td>2512055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.835616</td>\n",
       "      <td>-0.026317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1663</td>\n",
       "      <td>-0.259292</td>\n",
       "      <td>0.442064</td>\n",
       "      <td>0.778781</td>\n",
       "      <td>-225</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               fight_id_legacy       Date FighterResult Decision Rnd Time  \\\n",
       "0   2023-04-15_3949555_4863327 2023-04-15          None     None   -    -   \n",
       "1   2023-04-15_4040197_4397782 2023-04-15          None     None   -    -   \n",
       "2   2023-04-15_3994033_4232775 2023-04-15          None     None   -    -   \n",
       "3   2023-04-15_4063667_4076472 2023-04-15          None     None   -    -   \n",
       "4   2023-04-15_3045734_3961293 2023-04-15          None     None   -    -   \n",
       "5   2023-04-15_2335674_4690549 2023-04-15          None     None   -    -   \n",
       "6   2023-04-15_2594871_4227265 2023-04-15          None     None   -    -   \n",
       "7   2023-04-15_2526299_3900088 2023-04-15          None     None   -    -   \n",
       "8   2023-04-15_2614933_3902098 2023-04-15          None     None   -    -   \n",
       "9   2023-04-15_4394200_4963343 2023-04-15          None     None   -    -   \n",
       "10  2023-04-15_4089026_4816066 2023-04-15          None     None   -    -   \n",
       "11  2023-04-15_3020090_4239928 2023-04-15          None     None   -    -   \n",
       "12  2023-04-15_2335754_2512055 2023-04-15          None     None   -    -   \n",
       "\n",
       "                                  Event OpponentID_espn FighterID_espn  TSL  \\\n",
       "0   UFC Fight Night: Holloway vs. Allen         3949555        4863327  NaN   \n",
       "1   UFC Fight Night: Holloway vs. Allen         4040197        4397782  NaN   \n",
       "2   UFC Fight Night: Holloway vs. Allen         3994033        4232775  NaN   \n",
       "3   UFC Fight Night: Holloway vs. Allen         4063667        4076472  NaN   \n",
       "4   UFC Fight Night: Holloway vs. Allen         3961293        3045734  NaN   \n",
       "5   UFC Fight Night: Holloway vs. Allen         4690549        2335674  NaN   \n",
       "6   UFC Fight Night: Holloway vs. Allen         4227265        2594871  NaN   \n",
       "7   UFC Fight Night: Holloway vs. Allen         2526299        3900088  NaN   \n",
       "8   UFC Fight Night: Holloway vs. Allen         2614933        3902098  NaN   \n",
       "9   UFC Fight Night: Holloway vs. Allen         4963343        4394200  NaN   \n",
       "10  UFC Fight Night: Holloway vs. Allen         4816066        4089026  NaN   \n",
       "11  UFC Fight Night: Holloway vs. Allen         3020090        4239928  NaN   \n",
       "12  UFC Fight Night: Holloway vs. Allen         2335754        2512055  NaN   \n",
       "\n",
       "    ...   age_diff  log_reach_diff  weight_diff  height_diff  \\\n",
       "0   ...   7.317808        0.081126          0.0          4.0   \n",
       "1   ...   1.295890        0.036368          0.0          0.0   \n",
       "2   ...  -2.369863        0.006645          0.0          1.0   \n",
       "3   ...  -0.950685        0.013793          0.0          3.0   \n",
       "4   ...  -4.624658       -0.030305          0.0         -3.0   \n",
       "5   ... -12.665753        0.000000          0.0          0.0   \n",
       "6   ...  -1.021918        0.061036          0.0          5.0   \n",
       "7   ...   2.882192       -0.068993          0.0         -1.0   \n",
       "8   ...   2.136986        0.014389          0.0         -3.0   \n",
       "9   ...  -6.315068        0.038915          0.0          4.0   \n",
       "10  ...   2.512329       -0.007905          0.0          2.0   \n",
       "11  ...  -0.391781        0.029853          0.0          3.0   \n",
       "12  ...   3.835616       -0.026317          0.0         -1.0   \n",
       "\n",
       "    t_since_first_fight_diff  log_t_since_first_fight_diff  \\\n",
       "0                      -1596                     -0.510659   \n",
       "1                       -455                     -0.146069   \n",
       "2                       -183                     -0.046496   \n",
       "3                        526                      0.142094   \n",
       "4                       1547                      0.358149   \n",
       "5                       3870                      0.809855   \n",
       "6                       -287                     -0.061522   \n",
       "7                      -1400                     -0.320020   \n",
       "8                       -574                     -0.133283   \n",
       "9                       1036                      0.409856   \n",
       "10                       435                      0.183711   \n",
       "11                      -741                     -0.174199   \n",
       "12                     -1663                     -0.259292   \n",
       "\n",
       "    log_t_since_prev_fight_diff    y_pred  DraftKings_fighter  \\\n",
       "0                     -0.528675  0.710809                -130   \n",
       "1                      0.084218  0.416771                 115   \n",
       "2                      0.354646  0.591359                 110   \n",
       "3                      0.507671  0.529737                -190   \n",
       "4                      0.619535  0.188599                 170   \n",
       "5                      0.110348  0.288783                 215   \n",
       "6                     -0.375433  0.666591                -150   \n",
       "7                     -1.164626  0.634817                -170   \n",
       "8                     -0.533062  0.443194                 140   \n",
       "9                      0.018780  0.566286                -150   \n",
       "10                     0.142372  0.402099                -125   \n",
       "11                     0.942802  0.392517                 170   \n",
       "12                     0.442064  0.778781                -225   \n",
       "\n",
       "    DraftKings_opponent  \n",
       "0                   110  \n",
       "1                  -135  \n",
       "2                  -130  \n",
       "3                   160  \n",
       "4                  -200  \n",
       "5                  -255  \n",
       "6                   130  \n",
       "7                   145  \n",
       "8                  -165  \n",
       "9                   130  \n",
       "10                  105  \n",
       "11                 -200  \n",
       "12                  190  \n",
       "\n",
       "[13 rows x 387 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_preds_df = preds_df.merge(\n",
    "    ml_df,\n",
    "    on=[\"FighterName\", \"OpponentName\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "aug_preds_df[\"DraftKings_fighter\"] = aug_preds_df[\"DraftKings_fighter\"].astype(int)\n",
    "aug_preds_df[\"DraftKings_opponent\"] = aug_preds_df[\"DraftKings_opponent\"].astype(int)\n",
    "aug_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterName</th>\n",
       "      <th>fighter_bet</th>\n",
       "      <th>OpponentName</th>\n",
       "      <th>opponent_bet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daniel zellhuber</td>\n",
       "      <td>0.030442</td>\n",
       "      <td>lando vannata</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joselyne edwards</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>lucie pudilova</td>\n",
       "      <td>0.001872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tanner boser</td>\n",
       "      <td>0.019988</td>\n",
       "      <td>ion curelaba</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bill algeo</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>0.012652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pedro munhoz</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>chris gutierrez</td>\n",
       "      <td>0.039473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clay guida</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>rafa garcia</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>0.015134</td>\n",
       "      <td>azamat murzakanov</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>billy quarantillo</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arnold allen</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bruna brasil</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>denise gomes</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gillian robertson</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>piera rodriguez</td>\n",
       "      <td>0.019541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>brandon royval</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>matheus nicolau</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zak cummings</td>\n",
       "      <td>0.025549</td>\n",
       "      <td>ed herman</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FighterName  fighter_bet       OpponentName  opponent_bet\n",
       "0    daniel zellhuber     0.030442      lando vannata      0.000000\n",
       "1    joselyne edwards     0.000000     lucie pudilova      0.001872\n",
       "2        tanner boser     0.019988       ion curelaba      0.000000\n",
       "3          bill algeo     0.000000           tj brown      0.012652\n",
       "4        pedro munhoz     0.000000    chris gutierrez      0.039473\n",
       "5          clay guida     0.000000        rafa garcia      0.000000\n",
       "6       dustin jacoby     0.015134  azamat murzakanov      0.000000\n",
       "7   billy quarantillo     0.001273      edson barboza      0.000000\n",
       "8        arnold allen     0.004134       max holloway      0.000000\n",
       "9        bruna brasil     0.000000       denise gomes      0.000000\n",
       "10  gillian robertson     0.000000    piera rodriguez      0.019541\n",
       "11     brandon royval     0.003198    matheus nicolau      0.000000\n",
       "12       zak cummings     0.025549          ed herman      0.000000"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_selection.metrics import MultiKellyPM\n",
    "\n",
    "pm = MultiKellyPM(aug_preds_df, max_bankroll_fraction=0.05,\n",
    "                  fighter_ml_col=\"DraftKings_fighter\",\n",
    "                    opponent_ml_col=\"DraftKings_opponent\",\n",
    "                  parse_ml=True)\n",
    "pw = pm.get_portfolio_weights().merge(preds_df[[\"FighterID_espn\", \"OpponentID_espn\", \"FighterName\", \"OpponentName\"]])\n",
    "pw[[\"FighterName\", \"fighter_bet\", \"OpponentName\", \"opponent_bet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['DraftKings_fighter', 'DraftKings_opponent'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/john/play/sports/EXPERIMENTS/2023-04-10_base_template.ipynb Cell 54\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/john/play/sports/EXPERIMENTS/2023-04-10_base_template.ipynb#Y203sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m pw[[\u001b[39m\"\u001b[39;49m\u001b[39mFighterName\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfighter_bet\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mDraftKings_fighter\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mOpponentName\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mopponent_bet\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mDraftKings_opponent\u001b[39;49m\u001b[39m\"\u001b[39;49m]]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/john/play/sports/EXPERIMENTS/2023-04-10_base_template.ipynb#Y203sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m a[\u001b[39m\"\u001b[39m\u001b[39mfighter_bet\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\u001b[39m*\u001b[39ma[\u001b[39m\"\u001b[39m\u001b[39mfighter_bet\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/john/play/sports/EXPERIMENTS/2023-04-10_base_template.ipynb#Y203sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m a[\u001b[39m\"\u001b[39m\u001b[39mopponent_bet\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\u001b[39m*\u001b[39ma[\u001b[39m\"\u001b[39m\u001b[39mopponent_bet\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sports_pystan2/lib/python3.9/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sports_pystan2/lib/python3.9/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sports_pystan2/lib/python3.9/site-packages/pandas/core/indexes/base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['DraftKings_fighter', 'DraftKings_opponent'] not in index\""
     ]
    }
   ],
   "source": [
    "a = pw[[\"FighterName\", \"fighter_bet\", \"DraftKings_fighter\", \"OpponentName\", \"opponent_bet\", \"DraftKings_opponent\"]].copy()\n",
    "a[\"fighter_bet\"] = 100*a[\"fighter_bet\"]\n",
    "a[\"opponent_bet\"] = 100*a[\"opponent_bet\"]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sports_pystan2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a237f2fbfa4eeeaf420965c4b3f40ac3440be1ed8d868d43cc135fc4be38fee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
