{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting some quick picks for 2023-04-08\n",
    "\n",
    "http://ufcstats.com/event-details/3dc3022232b79c7a\n",
    "\n",
    "https://www.bestfightodds.com/events/ufc-287-2760\n",
    "\n",
    "Unfortunately I forgot to run the full script prior to this, so it's a bit jank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/john/play/sports/') # add parent directory to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 248)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>FighterResult</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Rnd</th>\n",
       "      <th>Time</th>\n",
       "      <th>Event</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>TSL</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_weight</th>\n",
       "      <th>FighterID_espn_opp</th>\n",
       "      <th>n_career_fights_opp</th>\n",
       "      <th>n_ufc_fights_opp</th>\n",
       "      <th>t_since_first_fight_opp</th>\n",
       "      <th>t_since_prev_fight_opp</th>\n",
       "      <th>total_ufc_cage_time_opp</th>\n",
       "      <th>min_weight_opp</th>\n",
       "      <th>max_weight_opp</th>\n",
       "      <th>prev_weight_opp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>1991-09-26</td>\n",
       "      <td>L</td>\n",
       "      <td>TKO (Injury)</td>\n",
       "      <td>1</td>\n",
       "      <td>4:42</td>\n",
       "      <td>Desafio: Jiu-Jitsu vs. Luta Livre</td>\n",
       "      <td>2354059</td>\n",
       "      <td>2558095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2354059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>1991-09-26</td>\n",
       "      <td>W</td>\n",
       "      <td>TKO (Injury)</td>\n",
       "      <td>1</td>\n",
       "      <td>4:42</td>\n",
       "      <td>Desafio: Jiu-Jitsu vs. Luta Livre</td>\n",
       "      <td>2558095</td>\n",
       "      <td>2354059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2558095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>W</td>\n",
       "      <td>Submission (Rear Naked Choke)</td>\n",
       "      <td>1</td>\n",
       "      <td>7:03</td>\n",
       "      <td>Desafio: Gracie Vale Tudo</td>\n",
       "      <td>2501396</td>\n",
       "      <td>2354119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2501396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>L</td>\n",
       "      <td>Submission (Rear Naked Choke)</td>\n",
       "      <td>1</td>\n",
       "      <td>7:03</td>\n",
       "      <td>Desafio: Gracie Vale Tudo</td>\n",
       "      <td>2354119</td>\n",
       "      <td>2501396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2354119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993-08-29_2354132_3107994</td>\n",
       "      <td>1993-08-29</td>\n",
       "      <td>W</td>\n",
       "      <td>Submission (Strikes)</td>\n",
       "      <td>1</td>\n",
       "      <td>2:46</td>\n",
       "      <td>CP X CB: Capoeira vs. Chute Boxe</td>\n",
       "      <td>3107994</td>\n",
       "      <td>2354132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3107994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fight_id       Date FighterResult  \\\n",
       "0  1991-09-26_2354059_2558095 1991-09-26             L   \n",
       "1  1991-09-26_2354059_2558095 1991-09-26             W   \n",
       "2  1992-01-01_2354119_2501396 1992-01-01             W   \n",
       "3  1992-01-01_2354119_2501396 1992-01-01             L   \n",
       "4  1993-08-29_2354132_3107994 1993-08-29             W   \n",
       "\n",
       "                        Decision Rnd  Time                              Event  \\\n",
       "0                   TKO (Injury)   1  4:42  Desafio: Jiu-Jitsu vs. Luta Livre   \n",
       "1                   TKO (Injury)   1  4:42  Desafio: Jiu-Jitsu vs. Luta Livre   \n",
       "2  Submission (Rear Naked Choke)   1  7:03          Desafio: Gracie Vale Tudo   \n",
       "3  Submission (Rear Naked Choke)   1  7:03          Desafio: Gracie Vale Tudo   \n",
       "4           Submission (Strikes)   1  2:46   CP X CB: Capoeira vs. Chute Boxe   \n",
       "\n",
       "  OpponentID_espn FighterID_espn  TSL  ...  prev_weight  FighterID_espn_opp  \\\n",
       "0         2354059        2558095  NaN  ...          NaN             2354059   \n",
       "1         2558095        2354059  NaN  ...          NaN             2558095   \n",
       "2         2501396        2354119  NaN  ...          NaN             2501396   \n",
       "3         2354119        2501396  NaN  ...          NaN             2354119   \n",
       "4         3107994        2354132  NaN  ...          NaN             3107994   \n",
       "\n",
       "   n_career_fights_opp n_ufc_fights_opp  t_since_first_fight_opp  \\\n",
       "0                    0                0                        0   \n",
       "1                    0                0                        0   \n",
       "2                    0                0                        0   \n",
       "3                    0                0                        0   \n",
       "4                    0                0                        0   \n",
       "\n",
       "   t_since_prev_fight_opp  total_ufc_cage_time_opp  min_weight_opp  \\\n",
       "0                     NaN                      0.0           185.0   \n",
       "1                     NaN                      0.0             NaN   \n",
       "2                     NaN                      0.0           185.0   \n",
       "3                     NaN                      0.0           170.0   \n",
       "4                     NaN                      0.0             NaN   \n",
       "\n",
       "   max_weight_opp  prev_weight_opp  \n",
       "0           185.0              NaN  \n",
       "1             NaN              NaN  \n",
       "2           185.0              NaN  \n",
       "3           170.0              NaN  \n",
       "4             NaN              NaN  \n",
       "\n",
       "[5 rows x 248 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from db import base_db_interface\n",
    "\n",
    "raw_df = base_db_interface.read(\"bfo_espn_ufc_features\")\n",
    "for dt_col in [\"Date\", \"DOB\", \"DOB_opp\"]:\n",
    "    raw_df[dt_col] = pd.to_datetime(raw_df[dt_col])\n",
    "raw_df[[\"FighterOpen\", \"OpponentOpen\"]] = raw_df[[\"FighterOpen\", \"OpponentOpen\"]]\\\n",
    "    .astype(float)\n",
    "\n",
    "raw_df = raw_df.drop_duplicates(subset=[\"FighterID_espn\", \"OpponentID_espn\", \"fight_id\"])\n",
    "raw_df[\"FighterID_espn\"] = raw_df[\"FighterID_espn\"].fillna(\"unknown\")\n",
    "raw_df[\"OpponentID_espn\"] = raw_df[\"OpponentID_espn\"].fillna(\"unknown\")\n",
    "print(raw_df.shape)\n",
    "raw_df.head() # show the first 5 rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awful, Ugly, Stinky, No-Good Hack\n",
    "\n",
    "Necessary in order to get data for the upcoming fights. The join is very difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 17)\n",
      "(30, 19)\n",
      "(30, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>EventHref</th>\n",
       "      <th>Date</th>\n",
       "      <th>FighterID_bfo</th>\n",
       "      <th>OpponentID_bfo</th>\n",
       "      <th>FighterName</th>\n",
       "      <th>OpponentName</th>\n",
       "      <th>FighterOpen</th>\n",
       "      <th>OpponentOpen</th>\n",
       "      <th>FighterCloseLeft</th>\n",
       "      <th>...</th>\n",
       "      <th>BioName_opp</th>\n",
       "      <th>FighterID_espn_opp</th>\n",
       "      <th>Country_opp</th>\n",
       "      <th>WT Class_opp</th>\n",
       "      <th>Team_opp</th>\n",
       "      <th>Nickname_opp</th>\n",
       "      <th>ReachInches_opp</th>\n",
       "      <th>WeightPounds_opp</th>\n",
       "      <th>HeightInches_opp</th>\n",
       "      <th>DOB_opp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Aaron-Phillips-4905</td>\n",
       "      <td>Gaston-Bolanos-6991</td>\n",
       "      <td>aaron phillips</td>\n",
       "      <td>gaston bolanos</td>\n",
       "      <td>+140</td>\n",
       "      <td>-160</td>\n",
       "      <td>+150</td>\n",
       "      <td>...</td>\n",
       "      <td>gaston bolaÃ±os</td>\n",
       "      <td>4393818</td>\n",
       "      <td>USA</td>\n",
       "      <td>Bantamweight</td>\n",
       "      <td>Combat Sports Academy</td>\n",
       "      <td>The Dreamkiller</td>\n",
       "      <td>69.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1992-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Arnold-Allen-4218</td>\n",
       "      <td>Max-Holloway-3090</td>\n",
       "      <td>arnold allen</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>+125</td>\n",
       "      <td>-145</td>\n",
       "      <td>+145</td>\n",
       "      <td>...</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>2614933</td>\n",
       "      <td>USA</td>\n",
       "      <td>Featherweight</td>\n",
       "      <td>Gracie Technics</td>\n",
       "      <td>Blessed</td>\n",
       "      <td>69.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1991-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Azamat-Murzakanov-7264</td>\n",
       "      <td>Dustin-Jacoby-2939</td>\n",
       "      <td>azamat murzakanov</td>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>+170</td>\n",
       "      <td>-200</td>\n",
       "      <td>+125</td>\n",
       "      <td>...</td>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>2594871</td>\n",
       "      <td>USA</td>\n",
       "      <td>Light Heavyweight</td>\n",
       "      <td>FactoryX Muay Thai</td>\n",
       "      <td>The Hanyak</td>\n",
       "      <td>76.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1988-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Bill-Algeo-9171</td>\n",
       "      <td>Tj-Brown-10260</td>\n",
       "      <td>bill algeo</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>-139</td>\n",
       "      <td>+119</td>\n",
       "      <td>-210</td>\n",
       "      <td>...</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>4063667</td>\n",
       "      <td>USA</td>\n",
       "      <td>Featherweight</td>\n",
       "      <td>Westside Fight Team</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>72.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1990-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>/events/ufc-fight-night-holloway-vs-allen-2796</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Billy-Quarantillo-4159</td>\n",
       "      <td>Edson-Barboza-2099</td>\n",
       "      <td>billy quarantillo</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>-155</td>\n",
       "      <td>+135</td>\n",
       "      <td>-190</td>\n",
       "      <td>...</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>2526299</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Featherweight</td>\n",
       "      <td>American Top Team</td>\n",
       "      <td>Junior</td>\n",
       "      <td>75.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1986-01-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Event  \\\n",
       "0  UFC Fight Night: Holloway vs. Allen   \n",
       "1  UFC Fight Night: Holloway vs. Allen   \n",
       "2  UFC Fight Night: Holloway vs. Allen   \n",
       "3  UFC Fight Night: Holloway vs. Allen   \n",
       "4  UFC Fight Night: Holloway vs. Allen   \n",
       "\n",
       "                                        EventHref       Date  \\\n",
       "0  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "1  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "2  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "3  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "4  /events/ufc-fight-night-holloway-vs-allen-2796 2023-04-15   \n",
       "\n",
       "            FighterID_bfo       OpponentID_bfo        FighterName  \\\n",
       "0     Aaron-Phillips-4905  Gaston-Bolanos-6991     aaron phillips   \n",
       "1       Arnold-Allen-4218    Max-Holloway-3090       arnold allen   \n",
       "2  Azamat-Murzakanov-7264   Dustin-Jacoby-2939  azamat murzakanov   \n",
       "3         Bill-Algeo-9171       Tj-Brown-10260         bill algeo   \n",
       "4  Billy-Quarantillo-4159   Edson-Barboza-2099  billy quarantillo   \n",
       "\n",
       "     OpponentName FighterOpen OpponentOpen FighterCloseLeft  ...  \\\n",
       "0  gaston bolanos        +140         -160             +150  ...   \n",
       "1    max holloway        +125         -145             +145  ...   \n",
       "2   dustin jacoby        +170         -200             +125  ...   \n",
       "3        tj brown        -139         +119             -210  ...   \n",
       "4   edson barboza        -155         +135             -190  ...   \n",
       "\n",
       "      BioName_opp FighterID_espn_opp Country_opp       WT Class_opp  \\\n",
       "0  gaston bolaÃ±os            4393818         USA       Bantamweight   \n",
       "1    max holloway            2614933         USA      Featherweight   \n",
       "2   dustin jacoby            2594871         USA  Light Heavyweight   \n",
       "3        tj brown            4063667         USA      Featherweight   \n",
       "4   edson barboza            2526299      Brazil      Featherweight   \n",
       "\n",
       "                Team_opp     Nickname_opp  ReachInches_opp WeightPounds_opp  \\\n",
       "0  Combat Sports Academy  The Dreamkiller             69.0            135.0   \n",
       "1        Gracie Technics          Blessed             69.0            146.0   \n",
       "2     FactoryX Muay Thai       The Hanyak             76.0            206.0   \n",
       "3    Westside Fight Team         Downtown             72.0            145.0   \n",
       "4      American Top Team           Junior             75.0            145.0   \n",
       "\n",
       "  HeightInches_opp    DOB_opp  \n",
       "0             67.0 1992-09-14  \n",
       "1             71.0 1991-12-04  \n",
       "2             75.0 1988-04-04  \n",
       "3             69.0 1990-05-22  \n",
       "4             71.0 1986-01-21  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wrangle.clean_espn_data import EspnDataCleaner\n",
    "\n",
    "# Get odds for upcoming fight\n",
    "bfo_df = base_db_interface.read(\"clean_fighter_odds_data\")\n",
    "bfo_df[\"Date\"] = pd.to_datetime(bfo_df[\"Date\"])\n",
    "bfo_to_espn_map = base_db_interface.read(\"bfo_to_espn_map\")\n",
    "upcoming_bfo_df = bfo_df.query(\"EventHref == \\\n",
    "                               '/events/ufc-fight-night-holloway-vs-allen-2796'\")\n",
    "upcoming_bfo_df = upcoming_bfo_df.rename(\n",
    "    columns={\"FighterID\": \"FighterID_bfo\", \"OpponentID\": \"OpponentID_bfo\"}\n",
    ")\n",
    "print(upcoming_bfo_df.shape)\n",
    "upcoming_bfo_df = upcoming_bfo_df.merge(\n",
    "    bfo_to_espn_map[[\"FighterID_bfo\", \"FighterID_espn\"]].drop_duplicates(),\n",
    "    on=[\"FighterID_bfo\"],\n",
    "    how=\"left\"\n",
    ").merge(\n",
    "    bfo_to_espn_map[[\"OpponentID_bfo\", \"OpponentID_espn\"]].drop_duplicates(),\n",
    "    on=[\"OpponentID_bfo\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(upcoming_bfo_df.shape)\n",
    "# Get bios for fighters in upcoming fight\n",
    "espn_dc = EspnDataCleaner()\n",
    "espn_dc._parse_bios()\n",
    "espn_dc.clean_bio_df\n",
    "bio_df = espn_dc.clean_bio_df.rename(columns={\n",
    "    \"FighterID\":\"FighterID_espn\", \"Name\": \"BioName\",\n",
    "})\n",
    "upcoming_bfo_df = upcoming_bfo_df.merge(\n",
    "    bio_df,\n",
    "    left_on=\"FighterID_espn\",\n",
    "    right_on=\"FighterID_espn\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_dropme\", \"\")\n",
    ").merge(\n",
    "    bio_df,\n",
    "    left_on=\"OpponentID_espn\",\n",
    "    right_on=\"FighterID_espn\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_opp\")\n",
    ")\n",
    "print(upcoming_bfo_df.shape)\n",
    "\n",
    "upcoming_bfo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 248) (133102, 250)\n",
      "shape of tonight's fight: (26, 250)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>FighterResult</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Rnd</th>\n",
       "      <th>Time</th>\n",
       "      <th>Event</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>TSL</th>\n",
       "      <th>...</th>\n",
       "      <th>n_career_fights_opp</th>\n",
       "      <th>n_ufc_fights_opp</th>\n",
       "      <th>t_since_first_fight_opp</th>\n",
       "      <th>t_since_prev_fight_opp</th>\n",
       "      <th>total_ufc_cage_time_opp</th>\n",
       "      <th>min_weight_opp</th>\n",
       "      <th>max_weight_opp</th>\n",
       "      <th>prev_weight_opp</th>\n",
       "      <th>BioName</th>\n",
       "      <th>BioName_opp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132984</th>\n",
       "      <td>2023-04-15_3949555_4863327</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3949555</td>\n",
       "      <td>4863327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>3990</td>\n",
       "      <td>357.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.0</td>\n",
       "      <td>daniel zellhuber</td>\n",
       "      <td>lando vannata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132985</th>\n",
       "      <td>2023-04-15_4040197_4397782</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4040197</td>\n",
       "      <td>4397782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>3347</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>joselyne edwards</td>\n",
       "      <td>lucie pudilova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132986</th>\n",
       "      <td>2023-04-15_3994033_4232775</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3994033</td>\n",
       "      <td>4232775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>4027</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2719.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205.0</td>\n",
       "      <td>tanner boser</td>\n",
       "      <td>ion cutelaba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132987</th>\n",
       "      <td>2023-04-15_4063667_4076472</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4063667</td>\n",
       "      <td>4076472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>3444</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1818.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>bill algeo</td>\n",
       "      <td>tj brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132988</th>\n",
       "      <td>2023-04-15_3045734_3961293</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3961293</td>\n",
       "      <td>3045734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>3591</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>pedro munhoz</td>\n",
       "      <td>chris gutierrez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fight_id       Date FighterResult Decision   Rnd  \\\n",
       "132984  2023-04-15_3949555_4863327 2023-04-15          None     None  None   \n",
       "132985  2023-04-15_4040197_4397782 2023-04-15          None     None  None   \n",
       "132986  2023-04-15_3994033_4232775 2023-04-15          None     None  None   \n",
       "132987  2023-04-15_4063667_4076472 2023-04-15          None     None  None   \n",
       "132988  2023-04-15_3045734_3961293 2023-04-15          None     None  None   \n",
       "\n",
       "        Time                                Event OpponentID_espn  \\\n",
       "132984  None  UFC Fight Night: Holloway vs. Allen         3949555   \n",
       "132985  None  UFC Fight Night: Holloway vs. Allen         4040197   \n",
       "132986  None  UFC Fight Night: Holloway vs. Allen         3994033   \n",
       "132987  None  UFC Fight Night: Holloway vs. Allen         4063667   \n",
       "132988  None  UFC Fight Night: Holloway vs. Allen         3961293   \n",
       "\n",
       "       FighterID_espn  TSL  ...  n_career_fights_opp  n_ufc_fights_opp  \\\n",
       "132984        4863327  NaN  ...                   20                12   \n",
       "132985        4397782  NaN  ...                   21                 8   \n",
       "132986        4232775  NaN  ...                   27                13   \n",
       "132987        4076472  NaN  ...                   26                 6   \n",
       "132988        3045734  NaN  ...                   24                 8   \n",
       "\n",
       "        t_since_first_fight_opp t_since_prev_fight_opp  \\\n",
       "132984                     3990                  357.0   \n",
       "132985                     3347                  238.0   \n",
       "132986                     4027                  147.0   \n",
       "132987                     3444                  126.0   \n",
       "132988                     3591                  154.0   \n",
       "\n",
       "        total_ufc_cage_time_opp  min_weight_opp  max_weight_opp  \\\n",
       "132984                   3089.0             NaN             NaN   \n",
       "132985                   2124.0             NaN             NaN   \n",
       "132986                   2719.0             NaN             NaN   \n",
       "132987                   1818.0             NaN             NaN   \n",
       "132988                   2294.0             NaN             NaN   \n",
       "\n",
       "        prev_weight_opp           BioName      BioName_opp  \n",
       "132984            155.0  daniel zellhuber    lando vannata  \n",
       "132985            135.0  joselyne edwards   lucie pudilova  \n",
       "132986            205.0      tanner boser     ion cutelaba  \n",
       "132987            145.0        bill algeo         tj brown  \n",
       "132988            135.0      pedro munhoz  chris gutierrez  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't like this line, \n",
    "df = raw_df.merge(\n",
    "    upcoming_bfo_df,\n",
    "    on=[\"FighterID_espn\", \"OpponentID_espn\", \"Date\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_dropme\")\n",
    ")\n",
    "drop_cols = df.columns[df.columns.str.endswith(\"_dropme\")]\n",
    "for drop_col in drop_cols:\n",
    "    col = drop_col[:-len(\"_dropme\")]\n",
    "    df[col] = df[col].fillna(df[drop_col])\n",
    "df = df.drop(columns=drop_cols)\n",
    "print(raw_df.shape, df.shape)\n",
    "foo = df.query(\"EventHref == '/events/ufc-fight-night-holloway-vs-allen-2796'\")\n",
    "print(\"shape of tonight's fight:\", foo.shape)\n",
    "foo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# OKAY PCA HAPPENS HERE. Just do everything in-sample for now. \n",
    "stat_cols = [\n",
    "    'TSL', 'TSA', 'SSL',\n",
    "    'SSA', #'TSL-TSA', \n",
    "    'KD', #'%BODY', '%HEAD', '%LEG', \n",
    "    'SCBL',\n",
    "    'SCBA', 'SCHL', 'SCHA', 'SCLL', 'SCLA', 'RV', 'TDL', 'TDA', 'TDS',\n",
    "    # 'TK ACC', 'SR', # I don't believe in ratio features in PCA, \n",
    "    # # because of the possibility of division by zero and heteroskedasticity\n",
    "    'SGBL', 'SGBA', 'SGHL', 'SGHA', 'SGLL', 'SGLA', 'AD', 'ADTB',\n",
    "    'ADHG', 'ADTM', 'ADTS', 'SM', 'SDBL', 'SDBA', 'SDHL',\n",
    "    'SDHA', 'SDLL', 'SDLA',\n",
    "    #'time_seconds',\n",
    "    # 'TD_fails', #'submission_rate',\n",
    "    'TD_fail', # formerly 'TD_fails'\n",
    "    'SDL', 'SCL', # formerly 'distance_strikes_landed', 'clinch_strikes_landed',\n",
    "    #'KD_power', \n",
    "    'SGL', # formerly 'ground_strikes_landed'\n",
    "]\n",
    "df[[\"KD\", \"KD_opp\"]] = df[[\"KD\", \"KD_opp\"]].astype(float) \n",
    "# convert from string to float. rather annoying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_diff_df = {\n",
    "    \"FighterID_espn\": df[\"FighterID_espn\"],\n",
    "    \"OpponentID_espn\": df[\"OpponentID_espn\"],\n",
    "    \"Date\": df[\"Date\"],\n",
    "    \"gender\": df[\"gender\"],\n",
    "    \"fight_id\": df[\"fight_id\"],\n",
    "}\n",
    "diff_cols = [col+\"_diff\" for col in stat_cols]\n",
    "for col, diff_col in zip(stat_cols, diff_cols):\n",
    "    stat_diff_df[diff_col] = (\n",
    "        np.sqrt(df[col]) - np.sqrt(df[col+\"_opp\"])\n",
    "    )\n",
    "# stat_diff_df = pd.DataFrame(stat_diff_df).dropna(subset=diff_cols).reset_index()\n",
    "stat_diff_df = pd.DataFrame(stat_diff_df).reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elo estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pca = 14\n",
    "# n_pca = 1 # just for testing\n",
    "bin_elo_alpha = 0.45\n",
    "acc_elo_alpha = 0.45\n",
    "pca_elo_alpha = 0.45\n",
    "real_elo_alpha = 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 782.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 799.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 807.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 811.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 811.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 810.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 804.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 800.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 803.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 802.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 786.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 802.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 800.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for PC_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 794.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>fight_id</th>\n",
       "      <th>PC_0</th>\n",
       "      <th>pred_elo_PC_0</th>\n",
       "      <th>fighter_elo_PC_0</th>\n",
       "      <th>opponent_elo_PC_0</th>\n",
       "      <th>updated_fighter_elo_PC_0</th>\n",
       "      <th>updated_opponent_elo_PC_0</th>\n",
       "      <th>PC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>fighter_elo_PC_12</th>\n",
       "      <th>opponent_elo_PC_12</th>\n",
       "      <th>updated_fighter_elo_PC_12</th>\n",
       "      <th>updated_opponent_elo_PC_12</th>\n",
       "      <th>PC_13</th>\n",
       "      <th>pred_elo_PC_13</th>\n",
       "      <th>fighter_elo_PC_13</th>\n",
       "      <th>opponent_elo_PC_13</th>\n",
       "      <th>updated_fighter_elo_PC_13</th>\n",
       "      <th>updated_opponent_elo_PC_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2558095</td>\n",
       "      <td>2354059</td>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2354059</td>\n",
       "      <td>2558095</td>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2354119</td>\n",
       "      <td>2501396</td>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2501396</td>\n",
       "      <td>2354119</td>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2354132</td>\n",
       "      <td>3107994</td>\n",
       "      <td>1993-08-29_2354132_3107994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133097</th>\n",
       "      <td>2512976</td>\n",
       "      <td>3146944</td>\n",
       "      <td>2023-05-13_2512976_3146944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.619807</td>\n",
       "      <td>-0.109493</td>\n",
       "      <td>0.510314</td>\n",
       "      <td>-0.109493</td>\n",
       "      <td>0.510314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314846</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>-0.314846</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>0.639975</td>\n",
       "      <td>0.317220</td>\n",
       "      <td>0.639975</td>\n",
       "      <td>0.317220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133098</th>\n",
       "      <td>2516131</td>\n",
       "      <td>2951361</td>\n",
       "      <td>2023-06-10_2516131_2951361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.443042</td>\n",
       "      <td>1.176898</td>\n",
       "      <td>0.733856</td>\n",
       "      <td>1.176898</td>\n",
       "      <td>0.733856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610091</td>\n",
       "      <td>0.349301</td>\n",
       "      <td>-0.260790</td>\n",
       "      <td>0.349301</td>\n",
       "      <td>-0.260790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133099</th>\n",
       "      <td>2951361</td>\n",
       "      <td>2516131</td>\n",
       "      <td>2023-06-10_2516131_2951361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.443042</td>\n",
       "      <td>0.733856</td>\n",
       "      <td>1.176898</td>\n",
       "      <td>0.733856</td>\n",
       "      <td>1.176898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.610091</td>\n",
       "      <td>-0.260790</td>\n",
       "      <td>0.349301</td>\n",
       "      <td>-0.260790</td>\n",
       "      <td>0.349301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133100</th>\n",
       "      <td>2560746</td>\n",
       "      <td>3027545</td>\n",
       "      <td>2023-07-08_2560746_3027545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.415478</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.393125</td>\n",
       "      <td>-0.492688</td>\n",
       "      <td>-0.393125</td>\n",
       "      <td>-0.492688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.131069</td>\n",
       "      <td>0.107960</td>\n",
       "      <td>0.239029</td>\n",
       "      <td>0.107960</td>\n",
       "      <td>0.239029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133101</th>\n",
       "      <td>3027545</td>\n",
       "      <td>2560746</td>\n",
       "      <td>2023-07-08_2560746_3027545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.415478</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492688</td>\n",
       "      <td>-0.393125</td>\n",
       "      <td>-0.492688</td>\n",
       "      <td>-0.393125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.131069</td>\n",
       "      <td>0.239029</td>\n",
       "      <td>0.107960</td>\n",
       "      <td>0.239029</td>\n",
       "      <td>0.107960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133102 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FighterID_espn OpponentID_espn                    fight_id  PC_0  \\\n",
       "0             2558095         2354059  1991-09-26_2354059_2558095   NaN   \n",
       "1             2354059         2558095  1991-09-26_2354059_2558095   NaN   \n",
       "2             2354119         2501396  1992-01-01_2354119_2501396   NaN   \n",
       "3             2501396         2354119  1992-01-01_2354119_2501396   NaN   \n",
       "4             2354132         3107994  1993-08-29_2354132_3107994   NaN   \n",
       "...               ...             ...                         ...   ...   \n",
       "133097        2512976         3146944  2023-05-13_2512976_3146944   NaN   \n",
       "133098        2516131         2951361  2023-06-10_2516131_2951361   NaN   \n",
       "133099        2951361         2516131  2023-06-10_2516131_2951361   NaN   \n",
       "133100        2560746         3027545  2023-07-08_2560746_3027545   NaN   \n",
       "133101        3027545         2560746  2023-07-08_2560746_3027545   NaN   \n",
       "\n",
       "        pred_elo_PC_0  fighter_elo_PC_0  opponent_elo_PC_0  \\\n",
       "0            0.000000          0.000000           0.000000   \n",
       "1            0.000000          0.000000           0.000000   \n",
       "2            0.000000          0.000000           0.000000   \n",
       "3            0.000000          0.000000           0.000000   \n",
       "4            0.000000          0.000000           0.000000   \n",
       "...               ...               ...                ...   \n",
       "133097      -0.619807         -0.109493           0.510314   \n",
       "133098       0.443042          1.176898           0.733856   \n",
       "133099      -0.443042          0.733856           1.176898   \n",
       "133100      -0.415478          0.355464           0.770942   \n",
       "133101       0.415478          0.770942           0.355464   \n",
       "\n",
       "        updated_fighter_elo_PC_0  updated_opponent_elo_PC_0  PC_1  ...  \\\n",
       "0                       0.000000                   0.000000   NaN  ...   \n",
       "1                       0.000000                   0.000000   NaN  ...   \n",
       "2                       0.000000                   0.000000   NaN  ...   \n",
       "3                       0.000000                   0.000000   NaN  ...   \n",
       "4                       0.000000                   0.000000   NaN  ...   \n",
       "...                          ...                        ...   ...  ...   \n",
       "133097                 -0.109493                   0.510314   NaN  ...   \n",
       "133098                  1.176898                   0.733856   NaN  ...   \n",
       "133099                  0.733856                   1.176898   NaN  ...   \n",
       "133100                  0.355464                   0.770942   NaN  ...   \n",
       "133101                  0.770942                   0.355464   NaN  ...   \n",
       "\n",
       "        fighter_elo_PC_12  opponent_elo_PC_12  updated_fighter_elo_PC_12  \\\n",
       "0                0.000000            0.000000                   0.000000   \n",
       "1                0.000000            0.000000                   0.000000   \n",
       "2                0.000000            0.000000                   0.000000   \n",
       "3                0.000000            0.000000                   0.000000   \n",
       "4                0.000000            0.000000                   0.000000   \n",
       "...                   ...                 ...                        ...   \n",
       "133097          -0.314846            0.003451                  -0.314846   \n",
       "133098           0.127486            0.230649                   0.127486   \n",
       "133099           0.230649            0.127486                   0.230649   \n",
       "133100          -0.393125           -0.492688                  -0.393125   \n",
       "133101          -0.492688           -0.393125                  -0.492688   \n",
       "\n",
       "        updated_opponent_elo_PC_12  PC_13  pred_elo_PC_13  fighter_elo_PC_13  \\\n",
       "0                         0.000000    NaN        0.000000           0.000000   \n",
       "1                         0.000000    NaN        0.000000           0.000000   \n",
       "2                         0.000000    NaN        0.000000           0.000000   \n",
       "3                         0.000000    NaN        0.000000           0.000000   \n",
       "4                         0.000000    NaN        0.000000           0.000000   \n",
       "...                            ...    ...             ...                ...   \n",
       "133097                    0.003451    NaN        0.322755           0.639975   \n",
       "133098                    0.230649    NaN        0.610091           0.349301   \n",
       "133099                    0.127486    NaN       -0.610091          -0.260790   \n",
       "133100                   -0.492688    NaN       -0.131069           0.107960   \n",
       "133101                   -0.393125    NaN        0.131069           0.239029   \n",
       "\n",
       "        opponent_elo_PC_13  updated_fighter_elo_PC_13  \\\n",
       "0                 0.000000                   0.000000   \n",
       "1                 0.000000                   0.000000   \n",
       "2                 0.000000                   0.000000   \n",
       "3                 0.000000                   0.000000   \n",
       "4                 0.000000                   0.000000   \n",
       "...                    ...                        ...   \n",
       "133097            0.317220                   0.639975   \n",
       "133098           -0.260790                   0.349301   \n",
       "133099            0.349301                  -0.260790   \n",
       "133100            0.239029                   0.107960   \n",
       "133101            0.107960                   0.239029   \n",
       "\n",
       "        updated_opponent_elo_PC_13  \n",
       "0                         0.000000  \n",
       "1                         0.000000  \n",
       "2                         0.000000  \n",
       "3                         0.000000  \n",
       "4                         0.000000  \n",
       "...                            ...  \n",
       "133097                    0.317220  \n",
       "133098                   -0.260790  \n",
       "133099                    0.349301  \n",
       "133100                    0.239029  \n",
       "133101                    0.107960  \n",
       "\n",
       "[133102 rows x 87 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.mma_features import PcaEloWrapper, BinaryEloWrapper\n",
    "\n",
    "pca_ew = PcaEloWrapper(\n",
    "    n_pca=n_pca, target_cols=diff_cols, alpha=pca_elo_alpha,\n",
    "    conditional_var_col=None, # for consistency\n",
    ")\n",
    "pca_elo_feat_df = pca_ew.fit_transform_all(stat_diff_df)\n",
    "pca_elo_feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FighterID_espn                133102\n",
       " OpponentID_espn               133102\n",
       " fight_id                      133102\n",
       " PC_0                            7928\n",
       " pred_elo_PC_0                 133102\n",
       "                                ...  \n",
       " pred_elo_PC_13                133102\n",
       " fighter_elo_PC_13             133102\n",
       " opponent_elo_PC_13            133102\n",
       " updated_fighter_elo_PC_13     133102\n",
       " updated_opponent_elo_PC_13    133102\n",
       " Length: 87, dtype: int64,\n",
       " index              133102\n",
       " FighterID_espn     133102\n",
       " OpponentID_espn    133102\n",
       " Date               133102\n",
       " gender             133102\n",
       " fight_id           133102\n",
       " TSL_diff            18156\n",
       " TSA_diff            18156\n",
       " SSL_diff            18156\n",
       " SSA_diff            18156\n",
       " KD_diff             18156\n",
       " SCBL_diff            7942\n",
       " SCBA_diff            7942\n",
       " SCHL_diff            7942\n",
       " SCHA_diff            7942\n",
       " SCLL_diff            7942\n",
       " SCLA_diff            7942\n",
       " RV_diff             18156\n",
       " TDL_diff            18156\n",
       " TDA_diff            18156\n",
       " TDS_diff             7942\n",
       " SGBL_diff            7942\n",
       " SGBA_diff            7942\n",
       " SGHL_diff            7942\n",
       " SGHA_diff            7942\n",
       " SGLL_diff            7942\n",
       " SGLA_diff            7942\n",
       " AD_diff              7942\n",
       " ADTB_diff            7942\n",
       " ADHG_diff            7942\n",
       " ADTM_diff            7942\n",
       " ADTS_diff            7942\n",
       " SM_diff             18156\n",
       " SDBL_diff            7942\n",
       " SDBA_diff            7942\n",
       " SDHL_diff            7942\n",
       " SDHA_diff            7942\n",
       " SDLL_diff            7942\n",
       " SDLA_diff            7942\n",
       " TD_fail_diff        18156\n",
       " SDL_diff            18142\n",
       " SCL_diff            18142\n",
       " SGL_diff            18142\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_elo_feat_df.notnull().sum(), stat_diff_df.notnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some targets for Elo estimators along the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    65262\n",
       "1.0    65262\n",
       "NaN     2578\n",
       "Name: win_target, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"win_target\"] = df[\"FighterResult\"].replace({\"W\":1, \"L\":0, \"D\":np.nan})\n",
    "df[\"win_target\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    45420\n",
       "1.0    45420\n",
       "NaN    42262\n",
       "Name: win_target_finish, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have to parse the decision column to get the detailed result\n",
    "def parse_decision(s):\n",
    "    if (s.startswith(\"submission\") or \n",
    "        s.startswith(\"sumission\") or\n",
    "        s.startswith(\"technical submission\")\n",
    "    ):\n",
    "        return \"submission\"\n",
    "    if (s.startswith(\"tko\") or \n",
    "        s.startswith(\"ko\") or\n",
    "        (s == 'could not continue')\n",
    "    ):\n",
    "        return \"tko_ko\"\n",
    "    if \"decision\" in s:\n",
    "        return \"decision\"\n",
    "    return \"other\"\n",
    "\n",
    "temp_decision = df[\"Decision\"].fillna(\"-\").str.lower().str.strip()\n",
    "decision_clean = temp_decision.apply(parse_decision)\n",
    "result_sign = df[\"FighterResult\"].map({\"W\": 1, \"L\":-1, \"D\": 0})\n",
    "decision_score = decision_clean.map({\"tko_ko\":2, \"submission\":2, \n",
    "                                                    \"decision\":1, \"other\":0})\n",
    "df[\"ordinal_fighter_result\"] = result_sign * decision_score\n",
    "submission_score = decision_clean.map({\"submission\":1, \"decision\":0, \n",
    "                                            \"other\":0, \"tko_ko\":0})\n",
    "tko_ko_score = decision_clean.map({\"submission\":0, \"decision\":0, \n",
    "                                            \"other\":0, \"tko_ko\":1})\n",
    "decision_score = decision_clean.map({\"submission\":0, \"decision\":1, \n",
    "                                            \"other\":0, \"tko_ko\":0})\n",
    "finish_score = decision_clean.map({\"submission\":1, \"decision\":0, \n",
    "                                            \"other\":0, \"tko_ko\":1})\n",
    "df[\"submission_fighter_result\"] = result_sign * submission_score\n",
    "df[\"tko_ko_fighter_result\"] = result_sign * tko_ko_score\n",
    "df[\"decision_fighter_result\"] = result_sign * decision_score\n",
    "df[\"finish_fighter_result\"] = result_sign * finish_score\n",
    "\n",
    "df[\"win_target_finish\"] = df[\"win_target\"] * decision_clean.map({\n",
    "    \"submission\":1, \"tko_ko\":1,\n",
    "    \"decision\":np.nan, \"other\":np.nan, \n",
    "})\n",
    "df[\"win_target_finish\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9891662033628346"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_fight_time(row):\n",
    "    if not np.isnan(row[\"time_dur\"]):\n",
    "        return row[\"time_dur\"]\n",
    "    if row[\"Rnd\"] == \"-\":\n",
    "        return np.nan\n",
    "    if row[\"Time\"] == \"-\":\n",
    "        # assuming 5 minute rounds\n",
    "        # fill in something for now\n",
    "        return int(row[\"Rnd\"]) * 5 * 60\n",
    "    n_rounds = row[\"Rnd\"].strip()\n",
    "    min, sec = row[\"Time\"].strip().split(\":\")\n",
    "    if n_rounds == \"-\":\n",
    "        return np.nan\n",
    "    n_rounds = int(n_rounds) - 1\n",
    "    if (min == \"-\") | (sec == \"-\"):\n",
    "        return np.nan\n",
    "    min = int(min)\n",
    "    sec = int(sec)\n",
    "    # assuming 5 minute rounds\n",
    "    return (n_rounds * 5 * 60) + min * 60 + sec\n",
    "    \n",
    "df[\"Rnd\"] = df[\"Rnd\"].fillna(\"-\")\n",
    "df[\"Time\"] = df[\"Time\"].fillna(\"-\")\n",
    "df[\"fight_time\"] = df.apply(parse_fight_time, axis=1)\n",
    "df[\"fight_time\"].notnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = (-1)**df[\"win_target\"]\n",
    "# restrict btw 1 and 25 minutes (length of a title fight)\n",
    "# short fight times -> big outliers\n",
    "clipped_time_dur = df[\"fight_time\"].clip(60, (5*5*60))\n",
    "df[\"signed_inverse_fight_time\"] = y / clipped_time_dur\n",
    "df[\"signed_inverse_sqrt_fight_time\"] = y / np.sqrt(clipped_time_dur)\n",
    "df[\"signed_inverse_log_fight_time\"] = y / np.log(clipped_time_dur)\n",
    "\n",
    "df[\"signed_inverse_fight_time\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for signed_inverse_fight_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 783.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 9)\n",
      "getting elo features for win_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 787.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting elo features for win_target_finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5194/5194 [00:06<00:00, 785.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>fight_id</th>\n",
       "      <th>win_target</th>\n",
       "      <th>pred_elo_win_target</th>\n",
       "      <th>fighter_elo_win_target</th>\n",
       "      <th>opponent_elo_win_target</th>\n",
       "      <th>updated_fighter_elo_win_target</th>\n",
       "      <th>updated_opponent_elo_win_target</th>\n",
       "      <th>win_target_finish</th>\n",
       "      <th>pred_elo_win_target_finish</th>\n",
       "      <th>fighter_elo_win_target_finish</th>\n",
       "      <th>opponent_elo_win_target_finish</th>\n",
       "      <th>updated_fighter_elo_win_target_finish</th>\n",
       "      <th>updated_opponent_elo_win_target_finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2558095</td>\n",
       "      <td>2354059</td>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2354059</td>\n",
       "      <td>2558095</td>\n",
       "      <td>1991-09-26_2354059_2558095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2354119</td>\n",
       "      <td>2501396</td>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2501396</td>\n",
       "      <td>2354119</td>\n",
       "      <td>1992-01-01_2354119_2501396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2354132</td>\n",
       "      <td>3107994</td>\n",
       "      <td>1993-08-29_2354132_3107994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>-0.1125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FighterID_espn OpponentID_espn                    fight_id  win_target  \\\n",
       "0        2558095         2354059  1991-09-26_2354059_2558095         0.0   \n",
       "1        2354059         2558095  1991-09-26_2354059_2558095         1.0   \n",
       "2        2354119         2501396  1992-01-01_2354119_2501396         1.0   \n",
       "3        2501396         2354119  1992-01-01_2354119_2501396         0.0   \n",
       "4        2354132         3107994  1993-08-29_2354132_3107994         1.0   \n",
       "\n",
       "   pred_elo_win_target  fighter_elo_win_target  opponent_elo_win_target  \\\n",
       "0                  0.5                     0.0                      0.0   \n",
       "1                  0.5                     0.0                      0.0   \n",
       "2                  0.5                     0.0                      0.0   \n",
       "3                  0.5                     0.0                      0.0   \n",
       "4                  0.5                     0.0                      0.0   \n",
       "\n",
       "   updated_fighter_elo_win_target  updated_opponent_elo_win_target  \\\n",
       "0                         -0.1125                           0.1125   \n",
       "1                          0.1125                          -0.1125   \n",
       "2                          0.1125                          -0.1125   \n",
       "3                         -0.1125                           0.1125   \n",
       "4                          0.1125                          -0.1125   \n",
       "\n",
       "   win_target_finish  pred_elo_win_target_finish  \\\n",
       "0                0.0                         0.5   \n",
       "1                1.0                         0.5   \n",
       "2                1.0                         0.5   \n",
       "3                0.0                         0.5   \n",
       "4                1.0                         0.5   \n",
       "\n",
       "   fighter_elo_win_target_finish  opponent_elo_win_target_finish  \\\n",
       "0                            0.0                             0.0   \n",
       "1                            0.0                             0.0   \n",
       "2                            0.0                             0.0   \n",
       "3                            0.0                             0.0   \n",
       "4                            0.0                             0.0   \n",
       "\n",
       "   updated_fighter_elo_win_target_finish  \\\n",
       "0                                -0.1125   \n",
       "1                                 0.1125   \n",
       "2                                 0.1125   \n",
       "3                                -0.1125   \n",
       "4                                 0.1125   \n",
       "\n",
       "   updated_opponent_elo_win_target_finish  \n",
       "0                                  0.1125  \n",
       "1                                 -0.1125  \n",
       "2                                 -0.1125  \n",
       "3                                  0.1125  \n",
       "4                                 -0.1125  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.mma_features import RealEloWrapper\n",
    "\n",
    "real_elo_target_cols = [\n",
    "#     \"fighter_result_time_left\", \n",
    "#     \"ml_logit_mvmt\",\n",
    "    # \"ordinal_fighter_result\",\n",
    "    # \"submission_fighter_result\",\n",
    "    # \"tko_ko_fighter_result\",\n",
    "    # \"decision_fighter_result\",\n",
    "    # \"finish_fighter_result\",\n",
    "    \"signed_inverse_fight_time\",\n",
    "    # \"signed_inverse_sqrt_fight_time\",\n",
    "    # \"signed_inverse_log_fight_time\",\n",
    "]\n",
    "diff_elo_target_cols = [\n",
    "]\n",
    "\n",
    "binary_elo_target_cols = [\"win_target\", \"win_target_finish\"]\n",
    "\n",
    "elo_alphas = {\n",
    "    col: real_elo_alpha \n",
    "    for col in (real_elo_target_cols + diff_elo_target_cols)\n",
    "}\n",
    "# elo_alphas[\"ml_logit_mvmt\"] = 0.225\n",
    "\n",
    "real_ew = RealEloWrapper(elo_alphas=elo_alphas)\n",
    "real_elo_feat_df = real_ew.fit_transform_all(df)\n",
    "print(real_elo_feat_df.shape)\n",
    "real_elo_feat_df.head()\n",
    "\n",
    "elo_alphas = {\n",
    "    col: bin_elo_alpha for col in binary_elo_target_cols\n",
    "}\n",
    "bin_ew = BinaryEloWrapper(elo_alphas=elo_alphas)\n",
    "bin_elo_feat_df = bin_ew.fit_transform_all(df)\n",
    "print(bin_elo_feat_df.shape)\n",
    "bin_elo_feat_df.head()\n",
    "# feat_ml_df[\"log_height_diff\"] = np.log(feat_ml_df[\"imp_height\"]) - np.log(feat_ml_df[\"imp_height_opp\"])\n",
    "# feat_ml_df[\"log_age_diff\"] = np.log(feat_ml_df[\"age\"]) - np.log(feat_ml_df[\"age_opp\"])\n",
    "# feat_ml_df[\"log_reach_diff\"] = np.log(feat_ml_df[\"imp_reach\"]) - np.log(feat_ml_df[\"imp_reach_opp\"])\n",
    "# feat_ml_df[\"log_reach_diff\"] = feat_ml_df[\"log_reach_diff\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 360)\n"
     ]
    }
   ],
   "source": [
    "elo_feat_df = df.merge(\n",
    "    pca_elo_feat_df, \n",
    "    how=\"left\", \n",
    "    on=[\"fight_id\", \"FighterID_espn\", \"OpponentID_espn\"],\n",
    ").merge(\n",
    "    real_elo_feat_df.drop(columns=real_elo_target_cols),\n",
    "    how=\"left\",\n",
    "    on=[\"fight_id\", \"FighterID_espn\", \"OpponentID_espn\"],\n",
    ").merge(\n",
    "    bin_elo_feat_df.drop(columns=binary_elo_target_cols),\n",
    "    how=\"left\",\n",
    "    on=[\"fight_id\", \"FighterID_espn\", \"OpponentID_espn\"],\n",
    ")\n",
    "print(elo_feat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fight_id                                  133102\n",
       "Date                                      133102\n",
       "FighterResult                             132984\n",
       "Decision                                  132984\n",
       "Rnd                                       133102\n",
       "                                           ...  \n",
       "pred_elo_win_target_finish                133102\n",
       "fighter_elo_win_target_finish             133102\n",
       "opponent_elo_win_target_finish            133102\n",
       "updated_fighter_elo_win_target_finish     133102\n",
       "updated_opponent_elo_win_target_finish    133102\n",
       "Length: 360, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elo_feat_df.notnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpler features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133102, 20) (133102, 360)\n"
     ]
    }
   ],
   "source": [
    "from model.mma_elo_model import unknown_fighter_id\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_simple_features(df):\n",
    "    # simple things that i needn't get from the fighter stats page\n",
    "    # eg number of fights, t_since_last_fight\n",
    "    assert (df[\"fight_id\"].value_counts() == 2).all()\n",
    "    df = df.assign(\n",
    "        is_ufc=df[\"Event\"].fillna(\"\").str.contains(\"UFC\"),\n",
    "        Date=pd.to_datetime(df[\"Date\"]),\n",
    "    )\n",
    "    feat_df = df.sort_values(\"Date\").copy()[[\n",
    "        \"fight_id\", \"FighterID_espn\", \"OpponentID_espn\", \"Date\", \"is_ufc\"\n",
    "    ]]\n",
    "    # Rolling features over fighter_careers\n",
    "    # because the data is doubled, we can simply group by the fighter id\n",
    "    feat_df[\"dummy\"] = 1\n",
    "    # total fights\n",
    "    feat_df[\"total_fights\"] = feat_df.groupby(\"FighterID_espn\")[\"dummy\"].cumsum()\n",
    "    feat_df[\"total_fights_opp\"] = feat_df.groupby(\"OpponentID_espn\")[\"dummy\"].cumsum()\n",
    "    # total ufc fights\n",
    "    feat_df[\"total_ufc_fights\"] = feat_df.groupby(\"FighterID_espn\")[\"is_ufc\"].cumsum()\n",
    "    feat_df[\"total_ufc_fights_opp\"] = feat_df.groupby(\"OpponentID_espn\")[\"is_ufc\"].cumsum()\n",
    "    # time since last fight\n",
    "    feat_df[\"t_since_last_fight\"] = feat_df.groupby(\"FighterID_espn\")[\"Date\"].diff().dt.days\n",
    "    feat_df[\"t_since_last_fight_opp\"] = feat_df.groupby(\"OpponentID_espn\")[\"Date\"].diff().dt.days\n",
    "    fill_val = 2*365 # arbitrarily say 2 years\n",
    "    feat_df[\"t_since_last_fight\"] = np.maximum(fill_val, feat_df[\"t_since_last_fight\"].fillna(fill_val))   \n",
    "    feat_df[\"t_since_last_fight_opp\"] = np.maximum(fill_val, feat_df[\"t_since_last_fight_opp\"].fillna(fill_val)) \n",
    "    # time since first fight\n",
    "    feat_df[\"t_since_first_fight\"] = (feat_df[\"Date\"] - feat_df.groupby(\"FighterID_espn\")[\"Date\"].transform(\"min\")).dt.days\n",
    "    feat_df[\"t_since_first_fight_opp\"] = (feat_df[\"Date\"] - feat_df.groupby(\"OpponentID_espn\")[\"Date\"].transform(\"min\")).dt.days\n",
    "    # compute diffs\n",
    "    feat_df[\"t_since_last_fight_diff\"] = (feat_df[\"t_since_last_fight\"] - \n",
    "                                            feat_df[\"t_since_last_fight_opp\"])\n",
    "    feat_df[\"t_since_last_fight_log_diff\"] = (np.log(feat_df[\"t_since_last_fight\"]) - \n",
    "                                                np.log(feat_df[\"t_since_last_fight_opp\"]))\n",
    "    feat_df[\"total_fights_diff\"] = (feat_df[\"total_fights\"] - \n",
    "                                    feat_df[\"total_fights_opp\"])\n",
    "    feat_df[\"total_fights_sqrt_diff\"] = (np.sqrt(feat_df[\"total_fights\"]) - \n",
    "                                        np.sqrt(feat_df[\"total_fights_opp\"]))\n",
    "    feat_df[\"total_ufc_fights_diff\"] = (feat_df[\"total_ufc_fights\"] - \n",
    "                                        feat_df[\"total_ufc_fights_opp\"])\n",
    "    feat_df[\"total_ufc_fights_sqrt_diff\"] = (np.sqrt(feat_df[\"total_ufc_fights\"]) - \n",
    "                                                np.sqrt(feat_df[\"total_ufc_fights_opp\"]))\n",
    "    return feat_df\n",
    "\n",
    "simple_feat_df = get_simple_features(elo_feat_df)\n",
    "print(simple_feat_df.shape, elo_feat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fight_id', 'FighterID_espn', 'OpponentID_espn', 'Date', 'is_ufc',\n",
       "       'dummy', 'total_fights', 'total_fights_opp', 'total_ufc_fights',\n",
       "       'total_ufc_fights_opp', 't_since_last_fight', 't_since_last_fight_opp',\n",
       "       't_since_first_fight', 't_since_first_fight_opp',\n",
       "       't_since_last_fight_diff', 't_since_last_fight_log_diff',\n",
       "       'total_fights_diff', 'total_fights_sqrt_diff', 'total_ufc_fights_diff',\n",
       "       'total_ufc_fights_sqrt_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_feat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pred_elo_PC_0',\n",
       " 'pred_elo_PC_1',\n",
       " 'pred_elo_PC_2',\n",
       " 'pred_elo_PC_3',\n",
       " 'pred_elo_PC_4',\n",
       " 'pred_elo_PC_5',\n",
       " 'pred_elo_PC_6',\n",
       " 'pred_elo_PC_7',\n",
       " 'pred_elo_PC_8',\n",
       " 'pred_elo_PC_9',\n",
       " 'pred_elo_PC_10',\n",
       " 'pred_elo_PC_11',\n",
       " 'pred_elo_PC_12',\n",
       " 'pred_elo_PC_13',\n",
       " 'pred_elo_signed_inverse_fight_time',\n",
       " 'pred_elo_win_target',\n",
       " 'pred_elo_win_target_finish',\n",
       " 'age_diff',\n",
       " 'log_reach_diff',\n",
       " 'weight_diff',\n",
       " 'height_diff',\n",
       " 'log_t_since_prev_fight_diff',\n",
       " 'log_t_since_first_fight_diff',\n",
       " 'total_fights_diff',\n",
       " 'usa_diff',\n",
       " 'russia_diff',\n",
       " 'stance_diff']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_ml_df = elo_feat_df.merge(\n",
    "    simple_feat_df, \n",
    "    how=\"left\",\n",
    "    on=[\"FighterID_espn\", \"OpponentID_espn\", \"Date\"],\n",
    "    suffixes=(\"_legacy\", \"\"),\n",
    ")\n",
    "\n",
    "feat_ml_df[\"age_diff\"] = (feat_ml_df[\"DOB\"] - feat_ml_df[\"DOB_opp\"]).dt.days / 365\n",
    "feat_ml_df[\"age_diff\"] = feat_ml_df[\"age_diff\"].fillna(0)\n",
    "\n",
    "feat_ml_df[\"log_reach_diff\"] = (\n",
    "    np.log(feat_ml_df[\"ReachInches\"]) - np.log(feat_ml_df[\"ReachInches_opp\"])\n",
    ").fillna(0)\n",
    "feat_ml_df[\"weight_diff\"] = (\n",
    "    feat_ml_df[\"min_weight\"] - feat_ml_df[\"min_weight_opp\"]\n",
    ").fillna(0)\n",
    "feat_ml_df[\"height_diff\"] = (\n",
    "    feat_ml_df[\"HeightInches\"] - feat_ml_df[\"HeightInches_opp\"]\n",
    ").fillna(0)\n",
    "\n",
    "feat_ml_df[\"t_since_first_fight_diff\"] = (\n",
    "    feat_ml_df[\"t_since_first_fight\"] - feat_ml_df[\"t_since_first_fight_opp\"]\n",
    ").fillna(0)\n",
    "feat_ml_df[\"log_t_since_first_fight_diff\"] = (\n",
    "    np.log(1 + feat_ml_df[\"t_since_first_fight\"]) - \n",
    "    np.log(1 + feat_ml_df[\"t_since_first_fight_opp\"])\n",
    ").fillna(0)\n",
    "\n",
    "feat_ml_df[\"log_t_since_prev_fight_diff\"] = (\n",
    "    np.log(1 + feat_ml_df[\"t_since_prev_fight\"]) -\n",
    "    np.log(1 + feat_ml_df[\"t_since_prev_fight_opp\"])\n",
    ").fillna(0)\n",
    "\n",
    "# whether or not the fighter is from the USA\n",
    "feat_ml_df[\"usa_diff\"] = (\n",
    "    feat_ml_df[\"Country\"].str.strip().str.lower().str.contains(\"usa\") -\n",
    "    feat_ml_df[\"Country_opp\"].str.strip().str.lower().str.contains(\"usa\")\n",
    ").fillna(0)\n",
    "\n",
    "feat_ml_df[\"russia_diff\"] = (\n",
    "    feat_ml_df[\"Country\"].str.strip().str.lower().str.contains(\"russia\") -\n",
    "    feat_ml_df[\"Country_opp\"].str.strip().str.lower().str.contains(\"russia\")\n",
    ").fillna(0)\n",
    "\n",
    "stance_fighter_clean = feat_ml_df[\"Stance\"].fillna(\"orthodox\").str.strip().str.lower()\n",
    "stance_fighter_clean.loc[~stance_fighter_clean.isin([\"southpaw\", \"switch\"])] = \"orthodox\"\n",
    "stance_opp_clean = feat_ml_df[\"Stance_opp\"].fillna(\"orthodox\").str.strip().str.lower()\n",
    "stance_opp_clean.loc[~stance_opp_clean.isin([\"southpaw\", \"switch\"])] = \"orthodox\"\n",
    "\n",
    "# advantage to fighter with the weirder stance\n",
    "feat_ml_df[\"stance_diff\"] = (\n",
    "    (stance_fighter_clean == \"southpaw\") & (stance_opp_clean == \"orthodox\") |\n",
    "    (stance_fighter_clean == \"switch\") & (stance_opp_clean == \"orthodox\")\n",
    ").astype(int) - (\n",
    "    (stance_fighter_clean == \"orthodox\") & (stance_opp_clean == \"southpaw\") |\n",
    "    (stance_fighter_clean == \"orthodox\") & (stance_opp_clean == \"switch\")\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# number of professional fights by fighters on that team, at that time\n",
    "# feat_ml_df[\"team_count_diff\"] = (\n",
    "#     feat_ml_df.groupby(\"Team\")[\"dummy\"].cumsum() -\n",
    "#     feat_ml_df.groupby(\"Team_opp\")[\"dummy\"].cumsum()\n",
    "# ).fillna(0)\n",
    "\n",
    "real_elo_target_cols = [\n",
    "#     \"fighter_result_time_left\", \n",
    "#     \"ml_logit_mvmt\",\n",
    "#     \"ordinal_fighter_result\",\n",
    "#     \"submission_fighter_result\",\n",
    "#     \"tko_ko_fighter_result\",\n",
    "#     \"decision_fighter_result\",\n",
    "    \"signed_inverse_fight_time\",\n",
    "    # \"finish_fighter_result\",\n",
    "    # *[col for col in stat_pca_df.columns \n",
    "    #   if col not in [\"FighterID_espn\", \"OpponentID_espn\", \"Date\"]],\n",
    "]\n",
    "\n",
    "feat_cols = [\n",
    "    *[f\"pred_elo_PC_{i}\" for i in range(n_pca)],\n",
    "\n",
    "    *[\"pred_elo_\"+c for c in [*diff_elo_target_cols, \n",
    "                               *real_elo_target_cols, \n",
    "                               *binary_elo_target_cols]],\n",
    "    \n",
    "    # \"t_since_last_fight_log_diff\", \n",
    "#     \"fights_per_day_diff\",\n",
    "#     \"t_since_last_fight_diff\",\n",
    "#     \"total_fights_sqrt_diff\", \n",
    "#     \"total_ufc_fights_diff\",\n",
    "    \n",
    "    \"age_diff\", \n",
    "#     \"log_age_diff\",\n",
    "#     \"reach_diff\", \n",
    "    \"log_reach_diff\",\n",
    "    \"weight_diff\", \n",
    "#     \"log_weight_diff\",\n",
    "    \"height_diff\",\n",
    "#     \"log_height_diff\",\n",
    "#     \"ml_logit_mvmt\",\n",
    "    \"log_t_since_prev_fight_diff\",\n",
    "    \"log_t_since_first_fight_diff\",\n",
    "    \"total_fights_diff\",\n",
    "#     \"quad_log_t_since_first_fight_diff\",\n",
    "    \"usa_diff\",\n",
    "    \"russia_diff\",\n",
    "    \"stance_diff\",\n",
    "    # \"team_count_diff\",\n",
    "]\n",
    "\n",
    "# new_feat_cols = [*feat_cols, \"ml_logit\"]\n",
    "feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pred_elo_PC_0', 'pred_elo_PC_1', 'pred_elo_PC_2', 'pred_elo_PC_3',\n",
       "       'pred_elo_PC_4', 'pred_elo_PC_5', 'pred_elo_PC_6', 'pred_elo_PC_7',\n",
       "       'pred_elo_PC_8', 'pred_elo_PC_9', 'pred_elo_PC_10', 'pred_elo_PC_11',\n",
       "       'pred_elo_PC_12', 'pred_elo_PC_13',\n",
       "       'pred_elo_signed_inverse_fight_time', 'pred_elo_win_target',\n",
       "       'pred_elo_win_target_finish'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_ml_df.columns[feat_ml_df.columns.str.contains(\"pred_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_elo_PC_0                         133102\n",
       "pred_elo_PC_1                         133102\n",
       "pred_elo_PC_2                         133102\n",
       "pred_elo_PC_3                         133102\n",
       "pred_elo_PC_4                         133102\n",
       "pred_elo_PC_5                         133102\n",
       "pred_elo_PC_6                         133102\n",
       "pred_elo_PC_7                         133102\n",
       "pred_elo_PC_8                         133102\n",
       "pred_elo_PC_9                         133102\n",
       "pred_elo_PC_10                        133102\n",
       "pred_elo_PC_11                        133102\n",
       "pred_elo_PC_12                        133102\n",
       "pred_elo_PC_13                        133102\n",
       "pred_elo_signed_inverse_fight_time    133102\n",
       "pred_elo_win_target                   133102\n",
       "pred_elo_win_target_finish            133102\n",
       "age_diff                              133102\n",
       "log_reach_diff                        133102\n",
       "weight_diff                           133102\n",
       "height_diff                           133102\n",
       "log_t_since_prev_fight_diff           133102\n",
       "log_t_since_first_fight_diff          133102\n",
       "total_fights_diff                     133102\n",
       "usa_diff                              133102\n",
       "russia_diff                           133102\n",
       "stance_diff                           133102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see how much data we have for each feature\n",
    "feat_ml_df[feat_cols].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_elo_PC_0                         66551\n",
      "pred_elo_PC_1                         66551\n",
      "pred_elo_PC_2                         66551\n",
      "pred_elo_PC_3                         66551\n",
      "pred_elo_PC_4                         66551\n",
      "pred_elo_PC_5                         66551\n",
      "pred_elo_PC_6                         66551\n",
      "pred_elo_PC_7                         66551\n",
      "pred_elo_PC_8                         66551\n",
      "pred_elo_PC_9                         66551\n",
      "pred_elo_PC_10                        66551\n",
      "pred_elo_PC_11                        66551\n",
      "pred_elo_PC_12                        66551\n",
      "pred_elo_PC_13                        66551\n",
      "pred_elo_signed_inverse_fight_time    66551\n",
      "pred_elo_win_target                   66551\n",
      "pred_elo_win_target_finish            66551\n",
      "age_diff                              66551\n",
      "log_reach_diff                        66551\n",
      "weight_diff                           66551\n",
      "height_diff                           66551\n",
      "log_t_since_prev_fight_diff           66551\n",
      "log_t_since_first_fight_diff          66551\n",
      "total_fights_diff                     66551\n",
      "usa_diff                              66551\n",
      "russia_diff                           66551\n",
      "stance_diff                           66551\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(66551, 387)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_ml_df = feat_ml_df.drop_duplicates(subset=[\"fight_id\"])\n",
    "print(feat_ml_df[feat_cols].notnull().sum())\n",
    "feat_ml_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation - opening line\n",
    "\n",
    "Note that this isn't realistic. Don't get your hopes up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fighter_implied_col = \"p_fighter_open_implied\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.mma_log_reg_stan import SimpleSymmetricModel\n",
    "\n",
    "mod = SimpleSymmetricModel(\n",
    "    feat_cols=feat_cols, target_col=\"win_target\", \n",
    "    p_fighter_implied_col=p_fighter_implied_col,\n",
    "    beta_prior_std=1.0, mcmc=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on date range: 2007-07-07 2020-12-31\n",
      "Initial log joint probability = -31471.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5872.93    0.00601282       3.77401           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -5872.92   0.000136324     0.0754736           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-01-16\n",
      "Initial log joint probability = -24014.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5880.85    0.00067619      0.730692           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5880.85    0.00036048     0.0455301           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-01-20\n",
      "Initial log joint probability = -16802.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5888.73   0.000928377       2.22994      0.5718      0.5718       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5888.73   0.000225032      0.104213           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-01-23\n",
      "Initial log joint probability = -23049.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5896.94    0.00738844       3.23732           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5896.94   0.000388759     0.0760236           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-01-30\n",
      "Initial log joint probability = -21756.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5904.67   0.000266139      0.444304      0.7399      0.7399       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -5904.67   0.000189649     0.0993148           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-05\n",
      "Initial log joint probability = -22125\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5905.26    0.00070352      0.346504           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5905.26   0.000397481     0.0879026           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-06\n",
      "Initial log joint probability = -18801\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -5914.6   0.000753709      0.686946           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20       -5914.6    0.00039745      0.172321      0.7421      0.7421       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-12\n",
      "Initial log joint probability = -23627.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5918.99     0.0722488       2.24475           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -5918.98   0.000102377     0.0526845      0.6753      0.6753       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-13\n",
      "Initial log joint probability = -17463.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5923.95    0.00293753      0.259349      0.9969      0.9969       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5923.95   0.000174229     0.0521989           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-19\n",
      "Initial log joint probability = -30239.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5926.56   0.000914155      0.991711      0.9068      0.9068       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -5926.56   8.05112e-05     0.0164804      0.9605      0.9605       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-20\n",
      "Initial log joint probability = -23846.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5935.96    0.00409272       2.06416           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5935.95   0.000125163      0.110729       0.396      0.9585       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-23\n",
      "Initial log joint probability = -18779.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5935.99     0.0016686       1.53674           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5935.99   0.000518366      0.132618           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-26\n",
      "Initial log joint probability = -24433.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5936.85    0.00322947      0.730539       0.997       0.997       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5936.85   0.000154614      0.119646           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-02-27\n",
      "Initial log joint probability = -23212\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5942.49    0.00197032      0.475467      0.9791      0.9791       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5942.49   0.000228811     0.0793061           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-05\n",
      "Initial log joint probability = -22573\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5943.09     0.0103263       3.93847      0.9501      0.9501       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -5943.08   0.000222489     0.0588961           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-06\n",
      "Initial log joint probability = -20068.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5953.76    0.00359248      0.797326           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5953.76   0.000680392     0.0519371           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-11\n",
      "Initial log joint probability = -18816.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5954.67   0.000575706      0.501436           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -5954.67   0.000155674      0.157627      0.7705      0.7705       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-12\n",
      "Initial log joint probability = -16277.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5956.61    0.00267784       1.36031       0.981       0.981       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5956.61   0.000251713      0.121738           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-13\n",
      "Initial log joint probability = -22749.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5963.27   0.000694307      0.393395      0.9143      0.9143       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5963.27   0.000122979     0.0627262           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-18\n",
      "Initial log joint probability = -17684.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5967.27     0.0014216      0.404251           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5967.27   7.08051e-05      0.169575      0.5784      0.5784       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-19\n",
      "Initial log joint probability = -20612.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5977.32    0.00203339       1.15145           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -5977.32   7.46141e-05     0.0388672      0.9256      0.9256       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-20\n",
      "Initial log joint probability = -22326.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -5989.4   0.000279497      0.532866           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -5989.4   4.34073e-05      0.133043      0.4703      0.4703       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-26\n",
      "Initial log joint probability = -19255.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5991.85     0.0136617       7.27681      0.6009      0.6009       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -5991.84   0.000227143      0.158256      0.7405      0.7405       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-03-27\n",
      "Initial log joint probability = -18331\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -5998.18    0.00468548      0.759983      0.8073      0.8073       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -5998.18   0.000228539     0.0435189           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-01\n",
      "Initial log joint probability = -21077.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6002.75    0.00162577       4.35102      0.8312      0.8312       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6002.75    4.2265e-05      0.082885      0.6068      0.6068       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-02\n",
      "Initial log joint probability = -22996.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6010.32    0.00201707      0.816217      0.7384      0.7384       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6010.32   0.000102548      0.107607           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-07\n",
      "Initial log joint probability = -20412.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6012.5    0.00202763      0.539073           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20       -6012.5   0.000276051      0.176524       0.829       0.829       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-09\n",
      "Initial log joint probability = -26846.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6019.03    0.00425104      0.563499           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6019.03   4.53371e-05     0.0349897      0.3542      0.9155       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-10\n",
      "Initial log joint probability = -26361.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6027.54   0.000545751      0.342692           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6027.54   0.000253796      0.107726           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-14\n",
      "Initial log joint probability = -21450\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6028.16    0.00213787       1.16912           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6028.16    6.4533e-05     0.0441209       0.871       0.871       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-16\n",
      "Initial log joint probability = -24915.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6038.08    0.00330233      0.555568           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6038.08   0.000132696     0.0997364           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-17\n",
      "Initial log joint probability = -19311.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6045.09    0.00174824      0.169766           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-21\n",
      "Initial log joint probability = -20575\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6045.79   0.000755444      0.412515      0.9346      0.9346       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6045.79   0.000207666     0.0854946           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-23\n",
      "Initial log joint probability = -23499.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6058.82    0.00193011       0.95423           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6058.82   0.000168457     0.0792798      0.5252           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-24\n",
      "Initial log joint probability = -15932.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6069.47     0.0142083      0.505523           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6069.47   0.000205329     0.0892776      0.4715      0.9912       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-28\n",
      "Initial log joint probability = -23015.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6073.02    0.00132196      0.208756      0.9874      0.9874       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6073.02   0.000199105     0.0712657      0.9397      0.9397       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-29\n",
      "Initial log joint probability = -20517.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6076.28    0.00403491       2.35624      0.7791      0.7791       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6076.28   6.77728e-05     0.0502032      0.4609      0.9564       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-04-30\n",
      "Initial log joint probability = -21248.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6078.9     0.0110113        1.9391           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -6078.9    0.00012227      0.145171      0.3687           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-01\n",
      "Initial log joint probability = -20209.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6086.52     0.0107661       3.73064      0.9563      0.9563       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6086.51   0.000119742      0.125862           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-06\n",
      "Initial log joint probability = -20836\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6093.5     0.0109003       2.60517           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -6093.5   0.000271563      0.105272           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-07\n",
      "Initial log joint probability = -22204.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6102.08   0.000878091      0.433507      0.6655      0.6655       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6102.08   0.000419157     0.0988135           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-08\n",
      "Initial log joint probability = -22265.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6109.86    0.00218481       1.45051           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6109.85   0.000233706     0.0682154      0.9987      0.9987       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-14\n",
      "Initial log joint probability = -23073\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6111.66   0.000877117      0.577995           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6111.66   0.000412802      0.121448           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-15\n",
      "Initial log joint probability = -21567.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6118.03    0.00160132       1.00839      0.7247      0.7247       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6118.03   0.000124021     0.0477271           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-21\n",
      "Initial log joint probability = -23631.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6133.3    0.00552564       1.16787           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -6133.3   0.000701652      0.020285           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-22\n",
      "Initial log joint probability = -22564.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6141.47     0.0014879      0.255939           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6141.47   0.000243451      0.040083           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-28\n",
      "Initial log joint probability = -19746.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6142.68    0.00118455      0.574667           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6142.68   0.000173242      0.100282       0.754       0.754       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-05-29\n",
      "Initial log joint probability = -23106.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6144.15     0.0053486       1.13187           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6144.15   0.000231101      0.203335           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-04\n",
      "Initial log joint probability = -24219.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6148.13    0.00810536       7.13823           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6148.11   0.000254582      0.118839           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-05\n",
      "Initial log joint probability = -21575\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6159.48    0.00700129       3.54438      0.9593      0.9593       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6159.48   0.000378595      0.101875           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-10\n",
      "Initial log joint probability = -20187.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6164.63    0.00469514       1.70898       0.969       0.969       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6164.63   0.000224173      0.167823           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-11\n",
      "Initial log joint probability = -20890.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6171.58    0.00517701       2.01825           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6171.58   0.000195278      0.141133           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-12\n",
      "Initial log joint probability = -18608\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6181.04   0.000411257      0.334423           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6181.04   0.000176701     0.0529643           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-17\n",
      "Initial log joint probability = -23137.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6188.87    0.00297356      0.785267      0.4499      0.9478       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6188.87   0.000530752     0.0949584           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-18\n",
      "Initial log joint probability = -28276.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6190.87    0.00427099       2.74808      0.8766      0.8766       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6190.87    0.00050444      0.100865           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-19\n",
      "Initial log joint probability = -24013.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6203.04    0.00188283      0.469282           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6203.04   0.000194426     0.0500874           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-24\n",
      "Initial log joint probability = -22216.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6207.26    0.00215547      0.371918           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6207.26   0.000393272      0.095773      0.8079      0.8079       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-25\n",
      "Initial log joint probability = -21553.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6222.85    0.00405193      0.586668           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6222.85   0.000176248      0.160519      0.5057      0.5057       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-06-26\n",
      "Initial log joint probability = -19985.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6235.18    0.00189483      0.987276           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6235.18   0.000119512      0.110614      0.6744      0.6744       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-02\n",
      "Initial log joint probability = -24603.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6238.23    0.00484022       4.25872           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6238.22   0.000151252     0.0627416           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-03\n",
      "Initial log joint probability = -21501.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6238.83   0.000809967      0.790518           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6238.83    0.00013415      0.137336           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-04\n",
      "Initial log joint probability = -24433.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -6239   0.000662762       1.80606      0.7455      0.7455       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23         -6239   0.000131363      0.123901      0.9527      0.9527       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-10\n",
      "Initial log joint probability = -19929\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6245.22   0.000986297      0.181209           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-16\n",
      "Initial log joint probability = -25457.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6254.2    0.00395908        4.4843           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6254.19   0.000150211     0.0888918           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-17\n",
      "Initial log joint probability = -25042.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6261.57    0.00396433      0.413884      0.8432      0.8432       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6261.57   0.000840878     0.0628626           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-18\n",
      "Initial log joint probability = -24345\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6263.35    0.00141072       1.30195           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6263.35   0.000119195      0.040311           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-24\n",
      "Initial log joint probability = -27074.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6274.73   0.000934403       0.52678           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6274.73   6.05257e-05      0.103194       0.705       0.705       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-25\n",
      "Initial log joint probability = -25528.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6276.3    0.00418645       2.77674           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6276.29   0.000460409     0.0578151           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-30\n",
      "Initial log joint probability = -26580.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6282.21     0.0673772       3.03619           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23       -6282.2   0.000109865     0.0377095      0.9606      0.9606       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-07-31\n",
      "Initial log joint probability = -23232.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6293.32    0.00108147      0.524421           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6293.32   0.000189356     0.0890645           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-01\n",
      "Initial log joint probability = -25741.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6294.63    0.00447081       1.54162           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6294.63   0.000278039     0.0467463           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-06\n",
      "Initial log joint probability = -27374.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6298.07   0.000580867      0.822622      0.3449      0.3449       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6298.07    0.00120672      0.102425           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-07\n",
      "Initial log joint probability = -28178.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6305.04    0.00159679       1.64318      0.7954      0.7954       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6305.04   0.000167023      0.106496           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-13\n",
      "Initial log joint probability = -27749\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6311.86   0.000873068        2.1169      0.7501      0.7501       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6311.86   0.000334119      0.136287           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-14\n",
      "Initial log joint probability = -21833.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6315.24    0.00070037      0.539147           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6315.24   9.92212e-05     0.0616805      0.9696      0.9696       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-19\n",
      "Initial log joint probability = -20293\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6317.61   0.000316253      0.656114       0.712       0.712       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6317.61   0.000124112     0.0890044           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-20\n",
      "Initial log joint probability = -22173.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6322.24     0.0107861       1.10712           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6322.24    0.00031496      0.128001           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-21\n",
      "Initial log joint probability = -22363.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6330.9   0.000257931      0.201813           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20       -6330.9   0.000135699     0.0571533           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-27\n",
      "Initial log joint probability = -24374.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6347.27    0.00838991       3.79039           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6347.27   0.000239559      0.120656      0.8199      0.8199       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-28\n",
      "Initial log joint probability = -27350.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6355.36    0.00128814      0.611438      0.8053      0.8053       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6355.36   0.000138554       0.11159           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-29\n",
      "Initial log joint probability = -26686.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6355.5    0.00216655       1.92317      0.9768      0.9768       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -6355.5   0.000150897     0.0752733           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-08-31\n",
      "Initial log joint probability = -21029.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6357.34   0.000832548      0.665031           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6357.34   0.000108488     0.0587956      0.9703      0.9703       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-04\n",
      "Initial log joint probability = -24334.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6367.08    0.00494201       2.25526           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6367.08   4.50334e-05      0.112404      0.4618      0.4618       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-05\n",
      "Initial log joint probability = -17848.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6369.57     0.0232978       1.72842           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6369.57   0.000177062      0.106705      0.8743      0.8743       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-07\n",
      "Initial log joint probability = -25212.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6373.94   0.000296946      0.379725           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6373.94   0.000133101     0.0436927           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-11\n",
      "Initial log joint probability = -25755.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6379.83    0.00251259      0.756176           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6379.83   0.000280026     0.0581783           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-14\n",
      "Initial log joint probability = -28909.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6382.51     0.0605123       3.75787           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6382.51   0.000158141     0.0344437           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-16\n",
      "Initial log joint probability = -22723.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6383.64   0.000921623       0.96025      0.7401      0.7401       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6383.64   0.000170925     0.0674379           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-17\n",
      "Initial log joint probability = -22833.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6385.92    0.00415733       1.30134           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6385.92   0.000110596      0.120461      0.4518      0.9395       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-18\n",
      "Initial log joint probability = -25191\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6402.67     0.0112885       7.91625           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6402.66   0.000222683      0.122983           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-21\n",
      "Initial log joint probability = -25913.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6405.76    0.00699907       2.93984           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6405.76   5.53762e-05      0.150677      0.6535      0.6535       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-24\n",
      "Initial log joint probability = -24893\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6407.38    0.00101849      0.974284           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6407.38   0.000397301      0.115924           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-25\n",
      "Initial log joint probability = -22263\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -6417    0.00458484       2.43483           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22         -6417   0.000678675       0.10626           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-28\n",
      "Initial log joint probability = -25492.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6419.69   0.000661852      0.397402           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6419.69   0.000295889      0.182364           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-09-30\n",
      "Initial log joint probability = -19788.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6424.43    0.00507778       3.38182           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6424.43   0.000200193      0.062027           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-01\n",
      "Initial log joint probability = -29468.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6432.37     0.0800319       3.94218           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6432.37   0.000892586      0.116516           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-02\n",
      "Initial log joint probability = -22807.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6441.69   0.000618067      0.424291      0.7643      0.7643       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6441.69   0.000253015      0.121652           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-05\n",
      "Initial log joint probability = -26159\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6444.81    0.00277768       0.22662           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6444.81   0.000116032      0.111219           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-09\n",
      "Initial log joint probability = -21438.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6449.96     0.0122163       3.28314           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6449.95   0.000154539     0.0650811           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-12\n",
      "Initial log joint probability = -23468.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6451.3     0.0115143       1.72465           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -6451.3   0.000199086      0.112652      0.5075      0.9817       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-16\n",
      "Initial log joint probability = -26027.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6467.09    0.00262038      0.812812           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6467.09   0.000133559     0.0182598           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-17\n",
      "Initial log joint probability = -22283.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6469.53    0.00305891      0.681951           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6469.53    0.00015697     0.0767399      0.6775      0.6775       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-19\n",
      "Initial log joint probability = -27843.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6472.79    0.00306906       4.01754      0.8281      0.8281       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6472.79   0.000220024     0.0691605           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-22\n",
      "Initial log joint probability = -28288.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6475.28    0.00269378      0.476293           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6475.28   0.000505653      0.166063           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-23\n",
      "Initial log joint probability = -25120.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6495.63    0.00345779      0.511928           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6495.63   0.000200674      0.198063      0.4169      0.9811       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-26\n",
      "Initial log joint probability = -21309.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6496.01    0.00853704        1.4409           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6496.01   0.000652668     0.0816562           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-27\n",
      "Initial log joint probability = -21775.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6503.09   0.000161306     0.0814746           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-29\n",
      "Initial log joint probability = -23124.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6507.58   0.000917986      0.574757      0.9323      0.9323       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6507.58   0.000156892     0.0680799           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-10-30\n",
      "Initial log joint probability = -20537.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6516.81    0.00137764      0.962514      0.7936      0.7936       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6516.81   0.000124491     0.0931395           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-02\n",
      "Initial log joint probability = -22635.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6520.46    0.00052785      0.256827           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6520.46   0.000217075      0.101321           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-05\n",
      "Initial log joint probability = -24350.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6527.71       0.14391       5.94442           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24       -6527.7   0.000187145     0.0592046           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-06\n",
      "Initial log joint probability = -22940.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6538.46    0.00305758       2.58297           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6538.46   0.000143188     0.0261107           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-07\n",
      "Initial log joint probability = -22342.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6538.97    0.00167216       1.27106           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6538.97   0.000203107     0.0559444           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-12\n",
      "Initial log joint probability = -29166.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6543.25     0.0167656       1.34686           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6543.25   0.000129565     0.0458547           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-13\n",
      "Initial log joint probability = -21563.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6550.24    0.00142399      0.310245           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6550.24   6.46593e-05      0.137493      0.6031      0.6031       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-14\n",
      "Initial log joint probability = -30168.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6555.55    0.00382501       1.38079      0.5063      0.5063       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6555.55   0.000182325     0.0241166           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-19\n",
      "Initial log joint probability = -35505.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6559.75    0.00800832        3.4039           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6559.75   0.000383419     0.0991671           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-20\n",
      "Initial log joint probability = -23777\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6566.33    0.00190291      0.257898           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6566.33   0.000240539     0.0798296           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-21\n",
      "Initial log joint probability = -21175.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6568.19   0.000419555      0.229425           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6568.19   0.000222697     0.0515899           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-11-27\n",
      "Initial log joint probability = -25047.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6568.53    0.00228581       3.13902           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6568.53   0.000218144     0.0800055           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-03\n",
      "Initial log joint probability = -29241.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6576.71     0.0100388       3.06759           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6576.71   0.000154735       0.18757      0.5888      0.5888       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-04\n",
      "Initial log joint probability = -15898.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6586.33   0.000875604      0.641076      0.6961      0.6961       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6586.33   0.000461015     0.0791645           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-10\n",
      "Initial log joint probability = -18219.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6594.81    0.00941382       4.00018      0.9735      0.9735       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6594.81   0.000260126        0.1797           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-11\n",
      "Initial log joint probability = -24077.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6610.34    0.00174592       3.34675      0.5906      0.5906       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6610.34   0.000709575     0.0995664           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-17\n",
      "Initial log joint probability = -23494.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6614.28    0.00140659       1.02129           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6614.28   0.000188531     0.0925821           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-18\n",
      "Initial log joint probability = -25130.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6625.16   0.000554443      0.549808      0.9448      0.9448       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6625.16   0.000443222      0.149023           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-19\n",
      "Initial log joint probability = -25303.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6626.25     0.0139459       3.74297           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6626.24   0.000110392     0.0178327           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2021-12-30\n",
      "Initial log joint probability = -27777\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6626.79    0.00516391       3.28793           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6626.79    0.00023083      0.121268           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-12\n",
      "Initial log joint probability = -32921.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6629.89    0.00984647       3.64915           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6629.88   0.000160502      0.118813       0.742       0.742       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-14\n",
      "Initial log joint probability = -21775.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6632.37    0.00038271      0.372108           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6632.37    6.9584e-05      0.121828      0.5044           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-15\n",
      "Initial log joint probability = -28641.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6642.85     0.0134791       3.68765           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6642.85   0.000238747      0.144624           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-21\n",
      "Initial log joint probability = -26929.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6647.17    0.00248545      0.732238           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6647.17    6.2635e-05      0.121158      0.6469      0.6469       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-22\n",
      "Initial log joint probability = -23756.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6655.08    0.00363493       1.74669           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6655.08   0.000275229      0.100294           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-28\n",
      "Initial log joint probability = -20911.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6661.37     0.0101022       0.83842           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6661.37   0.000717263     0.0332411           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-01-29\n",
      "Initial log joint probability = -32394.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6669.61    0.00433981       1.91007      0.9658      0.9658       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6669.61   0.000329217     0.0989578           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-03\n",
      "Initial log joint probability = -27116.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6670.54    0.00786984       8.07508      0.9823      0.9823       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6670.53   0.000251354     0.0749287           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-04\n",
      "Initial log joint probability = -28652.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6673.08    0.00101806      0.493109           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6673.08   0.000110474     0.0682184      0.7614      0.7614       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-05\n",
      "Initial log joint probability = -27880.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6677.32   0.000596344      0.493073      0.9879      0.9879       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6677.32   0.000191067     0.0594273           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-06\n",
      "Initial log joint probability = -26337.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6680.71    0.00532885       1.31185           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6680.71   4.55678e-05      0.117857      0.5027      0.5027       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-11\n",
      "Initial log joint probability = -26555.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6683.77   0.000264453      0.546265           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6683.77   0.000118503     0.0502965           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-12\n",
      "Initial log joint probability = -24264.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6691.51     0.0113406       1.76025           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6691.51   0.000961862     0.0596763           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-18\n",
      "Initial log joint probability = -28065.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6694.35    0.00204642       3.05614      0.4114      0.4114       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6694.35   0.000267698      0.167003           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-19\n",
      "Initial log joint probability = -26114.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6708.39    0.00126934      0.754422      0.8749      0.8749       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6708.39    0.00013598     0.0855657           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-23\n",
      "Initial log joint probability = -28245.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6708.63   0.000800287      0.458204           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6708.63   0.000183213      0.122967      0.7895      0.7895       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-25\n",
      "Initial log joint probability = -29342.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6718.66    0.00680196       1.39907           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6718.66   0.000287331      0.145189           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-26\n",
      "Initial log joint probability = -28390.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6731.81     0.0155114       1.83149           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6731.81   0.000255837      0.160708      0.4071       0.925       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-02-27\n",
      "Initial log joint probability = -21039.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6732.17     0.0100136       1.81108           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6732.17     0.0001809      0.145145           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-04\n",
      "Initial log joint probability = -20212.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6737.69    0.00327662      0.784581           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6737.69   0.000183188     0.0624909           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-05\n",
      "Initial log joint probability = -21887.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6748.33    0.00177839      0.515686      0.8818      0.8818       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6748.33   0.000215027      0.151832           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-09\n",
      "Initial log joint probability = -22249.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6751.66    0.00414858       7.25471           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6751.64   0.000579489     0.0569266      0.9845      0.9845       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-11\n",
      "Initial log joint probability = -23839.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6760.59     0.0040747      0.628181           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6760.59   7.04132e-05      0.127761      0.5679      0.5679       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-12\n",
      "Initial log joint probability = -31162.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6772.59    0.00467821      0.759268           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6772.59   0.000242701      0.157431      0.7191      0.7191       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-17\n",
      "Initial log joint probability = -21516.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6775.02    0.00677132       3.42831           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6775.02   0.000232458      0.186906      0.3365      0.9923       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-18\n",
      "Initial log joint probability = -21865.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6780.94    0.00110659       1.09827           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6780.94   0.000225088     0.0882673           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-19\n",
      "Initial log joint probability = -31360.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6791.06    0.00400342       1.51647           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6791.06    8.8741e-05      0.128762      0.5469      0.5469       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-25\n",
      "Initial log joint probability = -25269\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6800.15    0.00213346       1.79344           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6800.15   0.000162099      0.114387      0.8982      0.8982       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-26\n",
      "Initial log joint probability = -26760.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6808.4   0.000833105       2.47312      0.5359      0.5359       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20       -6808.4   0.000906883      0.162247           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-03-27\n",
      "Initial log joint probability = -22024.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6811.73    0.00213495       1.35555           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6811.73   0.000119688      0.141844      0.6955      0.6955       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-01\n",
      "Initial log joint probability = -20214.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6817.35   0.000346675      0.387972      0.8062      0.8062       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6817.35   0.000141906      0.165955           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-02\n",
      "Initial log joint probability = -21941.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6826.41    0.00040308      0.261516           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6826.41   0.000608601      0.154679           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-08\n",
      "Initial log joint probability = -23244.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6828.74   0.000641012      0.821417           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6828.74   0.000121553       0.12873           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-09\n",
      "Initial log joint probability = -25529.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6837.07   0.000591784      0.339091      0.9558      0.9558       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6837.07    0.00010037      0.155479      0.8774      0.8774       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-15\n",
      "Initial log joint probability = -23661.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6846.26   0.000229222      0.298875           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6846.26   5.05039e-05      0.135843      0.5507      0.5507       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-16\n",
      "Initial log joint probability = -27096.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6855.18   0.000690052      0.299507           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6855.18   0.000121988     0.0695687      0.8616      0.8616       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-20\n",
      "Initial log joint probability = -26121.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6861.63    0.00265853       1.04995           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6861.63   0.000190951      0.106431      0.8291      0.8291       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-22\n",
      "Initial log joint probability = -28875.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6863.49    0.00532542      0.289991           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6863.49   0.000143208      0.119384           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-23\n",
      "Initial log joint probability = -26309.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6880.94     0.0035561       9.96617      0.6049      0.6049       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -6880.93   6.04645e-05      0.127917      0.6268      0.6268       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-24\n",
      "Initial log joint probability = -26863\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6882.14     0.0138602       3.95058       0.433      0.8947       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6882.13   0.000241555      0.136184      0.8445      0.8445       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-28\n",
      "Initial log joint probability = -24074.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6885.83    0.00079781       1.70386      0.6865      0.6865       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6885.83   0.000366575     0.0767713           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-04-30\n",
      "Initial log joint probability = -27370.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6891.9     0.0224299       9.38752           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6891.88   0.000373488       0.10712           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-06\n",
      "Initial log joint probability = -19308.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6911.16     0.0058303       1.67253           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6911.16   0.000289466      0.092267           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-07\n",
      "Initial log joint probability = -24207.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6923.13    0.00201006      0.937362      0.9463      0.9463       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6923.13   0.000249389      0.108994           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-11\n",
      "Initial log joint probability = -20792\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6928.19   0.000836837       3.21166      0.5859      0.5859       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6928.19   0.000263267     0.0926845           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-13\n",
      "Initial log joint probability = -27578.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6936.75      0.019063       6.86359           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6936.73   0.000285795      0.111124           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-14\n",
      "Initial log joint probability = -28427.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6945.24    0.00280926      0.855314           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6945.24   0.000218107     0.0766806      0.7621      0.7621       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-20\n",
      "Initial log joint probability = -30993\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6951.86    0.00389541       6.38381      0.5913      0.5913       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6951.85   0.000149483      0.102055      0.3447           1       29   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-21\n",
      "Initial log joint probability = -23400.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6957.81   0.000256085      0.210412      0.9943      0.9943       20   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-22\n",
      "Initial log joint probability = -24157.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6957.94     0.0055211       3.65605      0.5152      0.5152       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -6957.94   0.000486204     0.0638191           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-27\n",
      "Initial log joint probability = -25330.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6959.37    0.00217944       7.39604      0.6069      0.6069       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6959.37   0.000848423      0.112413           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-05-28\n",
      "Initial log joint probability = -29249.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6964.53     0.0365204       4.64736           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -6964.52   0.000494218      0.186421       0.443           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-03\n",
      "Initial log joint probability = -24442.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6969.81   0.000834662       2.27856       0.407       0.407       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6969.81     0.0012267      0.158889           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-04\n",
      "Initial log joint probability = -20048.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6975.91    0.00239023      0.641856           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -6975.91   0.000469419      0.173672      0.9436      0.9436       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-09\n",
      "Initial log joint probability = -31213.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6979.75    0.00107846       1.22184           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6979.75   0.000114537      0.134391      0.4068           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-10\n",
      "Initial log joint probability = -30683.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6988.63    0.00408275       6.21206      0.5208      0.5208       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6988.62   0.000288449      0.196478           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-11\n",
      "Initial log joint probability = -30576.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -6992.78   0.000752281      0.463462           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -6992.78   0.000139896      0.108513      0.8274      0.8274       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-17\n",
      "Initial log joint probability = -26214\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -6999.8   0.000943037      0.766344           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -6999.8   5.65874e-05     0.0518528      0.4473      0.9857       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-18\n",
      "Initial log joint probability = -33373.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7011.36    0.00427666       1.07076           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7011.36   0.000714863      0.130274           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-24\n",
      "Initial log joint probability = -34220.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7025.04    0.00167153       1.07966      0.3209           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7025.04    0.00106204     0.0406289      0.9752      0.9752       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-25\n",
      "Initial log joint probability = -25675.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7037.07    0.00901024       12.0011      0.7024      0.7024       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      28      -7037.04   0.000362202      0.174454      0.4026           1       32   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-06-26\n",
      "Initial log joint probability = -19193.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7038.33   0.000357343      0.310472      0.9028      0.9028       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7038.33   6.80076e-05       0.13328        0.73        0.73       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-01\n",
      "Initial log joint probability = -34274.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7043.33    0.00310663       2.25499           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7043.33    0.00018575     0.0904722           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-02\n",
      "Initial log joint probability = -28210.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7053.86   0.000236702      0.648391      0.7524      0.7524       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7053.86   0.000208921      0.153171           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-03\n",
      "Initial log joint probability = -23865.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7054.03    0.00729329       4.40061      0.3452           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7054.03   0.000186396      0.048001           1           1       29   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-08\n",
      "Initial log joint probability = -24984.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7057.91    0.00134278       1.17028           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7057.91    5.2032e-05      0.117357      0.5977      0.5977       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-09\n",
      "Initial log joint probability = -31701.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7064.88     0.0112079       4.18154       0.833       0.833       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7064.87    0.00246104      0.191698      0.9958      0.9958       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-14\n",
      "Initial log joint probability = -26510.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7066.83    0.00227161      0.839736      0.8295      0.8295       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7066.83   0.000194076      0.101793           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-15\n",
      "Initial log joint probability = -33624.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7068.02    0.00727389       7.40347           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7068.02   0.000199132     0.0888902           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-16\n",
      "Initial log joint probability = -29183.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7075.91    0.00327734       7.19158     0.08393           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23       -7075.9   0.000279221     0.0417423           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-20\n",
      "Initial log joint probability = -25508.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7079.97    0.00126251       1.97356      0.9601      0.9601       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7079.97   0.000263473      0.200212           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-22\n",
      "Initial log joint probability = -26328.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7094.09    0.00155903      0.728308           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7094.09   0.000103921       0.12239      0.7148      0.7148       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-23\n",
      "Initial log joint probability = -29443.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7112.02   0.000377056      0.496658           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7112.02   0.000353767      0.151944           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-26\n",
      "Initial log joint probability = -22236\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7115.26    0.00026999       0.29159      0.9892      0.9892       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7115.26   0.000288096       0.16366           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-29\n",
      "Initial log joint probability = -28178.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7122.6   0.000387208      0.278819           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20       -7122.6   0.000232274     0.0950862           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-07-30\n",
      "Initial log joint probability = -21295.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7128.15   0.000701328       1.56813      0.7204      0.7204       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7128.15   0.000276057       0.13771           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-02\n",
      "Initial log joint probability = -30516\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7130.79   0.000760403      0.500107       0.762       0.762       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7130.79   0.000288164      0.107914        0.84        0.84       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-05\n",
      "Initial log joint probability = -28978.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7140.39    0.00750762       3.45497           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7140.39   0.000180074     0.0726187           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-06\n",
      "Initial log joint probability = -26226.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7145.38    0.00397086       1.03244       0.908       0.908       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7145.38   0.000230301     0.0986494           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-09\n",
      "Initial log joint probability = -25498.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7147.63    0.00845962       4.94369      0.4818      0.4818       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7147.62   0.000374983     0.0623688           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-12\n",
      "Initial log joint probability = -24019.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7152.27    0.00431175      0.937981      0.9452      0.9452       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7152.27   7.83811e-05     0.0873846           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-13\n",
      "Initial log joint probability = -28281.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7175.83      0.124078       9.75519           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24       -7175.8   0.000301237     0.0759897      0.7762      0.7762       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-16\n",
      "Initial log joint probability = -30561.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7179.75    0.00033576      0.258412           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7179.75   0.000178288     0.0788766           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-19\n",
      "Initial log joint probability = -30694.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7182.29    0.00594215       8.50657           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7182.28   0.000523215      0.090285           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-20\n",
      "Initial log joint probability = -21642.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7199.15    0.00580602       2.32456           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7199.15   0.000132909     0.0705751           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-23\n",
      "Initial log joint probability = -30211.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7203.26    0.00897219       2.72283           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7203.26   0.000224859     0.0608235           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-26\n",
      "Initial log joint probability = -27468.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7208.51    0.00570586       2.68582           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7208.51   0.000101059     0.0877945      0.7413      0.7413       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-08-30\n",
      "Initial log joint probability = -26595.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7212.28    0.00168144       1.09952           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7212.28   0.000126655      0.104507           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-02\n",
      "Initial log joint probability = -25832.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7212.88    0.00863472       2.15061           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7212.88   0.000425983      0.158981           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-03\n",
      "Initial log joint probability = -28236.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7219.19    0.00284732      0.553009           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7219.19   0.000240754      0.078661      0.9545      0.9545       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-06\n",
      "Initial log joint probability = -24823.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7222.56    0.00316165       4.98488       0.378       0.378       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7222.55   8.02603e-05      0.141442      0.6718      0.6718       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-09\n",
      "Initial log joint probability = -24972.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7228.35     0.0119328       2.88403           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7228.35   9.79512e-05     0.0369321           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-10\n",
      "Initial log joint probability = -22722.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7239.19   0.000153481      0.104623           1           1       20   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-13\n",
      "Initial log joint probability = -33866.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7241.49    0.00934763       3.05426           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7241.49   0.000355002     0.0929164           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-16\n",
      "Initial log joint probability = -24181.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7243.97     0.0076239       2.58044           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7243.97   9.35281e-05     0.0314955           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-17\n",
      "Initial log joint probability = -28263.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7258.08   0.000990788      0.871423      0.8297      0.8297       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7258.08   0.000327607      0.144605           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-20\n",
      "Initial log joint probability = -28569.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7260.44    0.00247788        1.1865           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7260.44   0.000115403     0.0697648           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-23\n",
      "Initial log joint probability = -29447.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7273.83     0.0864563       8.01531           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24       -7273.8   0.000424538      0.105125       0.998       0.998       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-27\n",
      "Initial log joint probability = -34105.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7275.28    0.00974765       2.91504           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7275.28   5.98539e-05      0.204336      0.5334      0.5334       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-28\n",
      "Initial log joint probability = -28697.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7279.44    0.00517697       2.85133           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7279.43   0.000201388     0.0301138           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-29\n",
      "Initial log joint probability = -24343.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7281.55    0.00352127        2.4801      0.9792      0.9792       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7281.55   7.40148e-05      0.201047      0.5663      0.5663       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-09-30\n",
      "Initial log joint probability = -28539.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7285.89      0.015322       6.15914           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7285.88   0.000128742     0.0733503      0.9326      0.9326       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-01\n",
      "Initial log joint probability = -25405.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7299.38   0.000297828      0.297887           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7299.38   0.000150064      0.145733           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-07\n",
      "Initial log joint probability = -26459.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7301.57    0.00156731        1.0276           1           1       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7301.57   0.000145889       0.20083      0.6621      0.6621       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-08\n",
      "Initial log joint probability = -30922.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7301.68    0.00387963        3.1332           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7301.68   5.07195e-05      0.192662      0.5693      0.5693       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-12\n",
      "Initial log joint probability = -25949.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7303.29    0.00129583       3.35891      0.6252      0.6252       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7303.29   0.000282628      0.138564           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-14\n",
      "Initial log joint probability = -27290.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7310.14    0.00112501      0.808286           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7310.14   0.000290605      0.103119           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-15\n",
      "Initial log joint probability = -28324\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7315.36   0.000364692      0.295616           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7315.36   0.000121781     0.0408665      0.9185      0.9185       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-19\n",
      "Initial log joint probability = -27205.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7315.82    0.00497876      0.695452      0.8885      0.8885       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7315.82    0.00010949      0.117879      0.9606      0.9606       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-20\n",
      "Initial log joint probability = -24134\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7318.1   0.000285697      0.471233           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -7318.1   0.000110661      0.196791      0.8619      0.8619       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-21\n",
      "Initial log joint probability = -28504.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7322.69    0.00123644         1.788       0.454       0.454       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7322.69   5.92448e-05      0.137596      0.5651      0.5651       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-22\n",
      "Initial log joint probability = -25008.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7328.63    0.00417672       6.44348      0.3752      0.3752       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7328.61   0.000288322     0.0774202           1           1       28   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-23\n",
      "Initial log joint probability = -30089.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7331.79    0.00155507      0.627875      0.9135      0.9135       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7331.79   8.14129e-05     0.0858386      0.4502           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-28\n",
      "Initial log joint probability = -32054.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -7332     0.0163352         5.517           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7331.99   0.000115259     0.0957594           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-10-29\n",
      "Initial log joint probability = -30233.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7346.3    0.00252124       2.04963      0.8928      0.8928       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -7346.3   0.000363483      0.134282           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-03\n",
      "Initial log joint probability = -25931.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7346.77    0.00110576      0.220479           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-04\n",
      "Initial log joint probability = -28789.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7352.9    0.00309682       2.27879           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7352.89   0.000220674     0.0888951           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-05\n",
      "Initial log joint probability = -29273.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7357.02    0.00397937       2.05512           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7357.02   0.000105211      0.076024       0.413      0.9964       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-10\n",
      "Initial log joint probability = -35256.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7358.32    0.00424162      0.328235      0.9695      0.9695       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7358.32   0.000111541      0.056481           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-12\n",
      "Initial log joint probability = -30847.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7374.89   0.000441529      0.232726           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7374.89   0.000216517     0.0966885           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-16\n",
      "Initial log joint probability = -22477.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7379.42    0.00214549      0.837094      0.8715      0.8715       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7379.42   0.000427354       0.14813           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-17\n",
      "Initial log joint probability = -21564.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7379.61    0.00536813         2.736           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7379.61   0.000644181      0.128344           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-18\n",
      "Initial log joint probability = -19956.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7389.73    0.00336196       1.22613           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7389.73   0.000243342     0.0487337           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-19\n",
      "Initial log joint probability = -27324.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7397.96    0.00170176       1.58256      0.7721      0.7721       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7397.96   0.000240619      0.122865           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-20\n",
      "Initial log joint probability = -27784.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7400.56    0.00291018       2.37451           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7400.56   5.72022e-05      0.123065      0.7714      0.7714       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-25\n",
      "Initial log joint probability = -26773.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7407.53    0.00351083       1.55698           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7407.53   0.000188889      0.132602           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-11-26\n",
      "Initial log joint probability = -28117.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7407.63    0.00328264       1.93519      0.5232      0.5232       24   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7407.63   0.000266642     0.0944075           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-03\n",
      "Initial log joint probability = -26193.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7418.52      0.110343        5.2376           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7418.51   0.000619319      0.118578      0.9307      0.9307       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-08\n",
      "Initial log joint probability = -26723\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7419.68    0.00499449       5.85091      0.9391      0.9391       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7419.67   0.000227355      0.134784           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-09\n",
      "Initial log joint probability = -24727.6\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7432.82     0.0114828       4.68896           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7432.81    0.00054866     0.0786894           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-10\n",
      "Initial log joint probability = -26662.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7438.55   0.000312149      0.441206           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7438.55   0.000310365     0.0966742           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-12\n",
      "Initial log joint probability = -28356\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7438.71    0.00622154      0.670401      0.9774      0.9774       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7438.71   0.000283304      0.119986      0.7743      0.7743       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-17\n",
      "Initial log joint probability = -23231.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7449.51     0.0109923       4.27336           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7449.51   0.000202229     0.0644746           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-18\n",
      "Initial log joint probability = -27174.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7449.72    0.00167798       2.01821           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7449.72   9.38239e-05      0.113093      0.4345      0.4345       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2022-12-31\n",
      "Initial log joint probability = -26887.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7456.78   0.000864236       1.67016       0.572       0.572       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7456.78   0.000545283      0.172949           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-06\n",
      "Initial log joint probability = -28570.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7457.99   0.000743537      0.458342           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7457.99   0.000278046       0.14303      0.8969      0.8969       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-13\n",
      "Initial log joint probability = -26545.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7461.42    0.00200101       1.18798           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7461.42   0.000150661     0.0403481           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-14\n",
      "Initial log joint probability = -25176.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7467.56    0.00641926       1.28759           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7467.56   0.000111934     0.0698304      0.9883      0.9883       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-18\n",
      "Initial log joint probability = -33458.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7470.56    0.00350852       1.06377           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7470.56   0.000747958      0.113774           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-20\n",
      "Initial log joint probability = -24057.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7470.8   0.000518153       0.89968      0.7771      0.7771       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21       -7470.8   0.000197231      0.162727           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-21\n",
      "Initial log joint probability = -24939.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7481.2    0.00133922       3.48291       0.602       0.602       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -7481.2   0.000459642      0.137347           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-27\n",
      "Initial log joint probability = -30038.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7484.8    0.00357769       4.98011      0.7753      0.7753       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7484.79   0.000192367      0.217132           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-01-28\n",
      "Initial log joint probability = -37804.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7486.54     0.0127975       4.60061           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7486.54   0.000112275     0.0948241           1           1       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-03\n",
      "Initial log joint probability = -23783.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7486.63   0.000813391      0.710437      0.7864      0.7864       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7486.63   0.000233109     0.0860421           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-04\n",
      "Initial log joint probability = -30368.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7501.93    0.00662554       2.84768           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7501.93   0.000682985      0.051096           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-10\n",
      "Initial log joint probability = -22883.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7502.57   0.000929338       1.13211           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7502.57    0.00015777      0.157829      0.6796      0.6796       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-11\n",
      "Initial log joint probability = -30265.8\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7505.03    0.00268339         10.98      0.5563      0.5563       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      24      -7505.02   5.37824e-05      0.192726      0.5382      0.5382       27   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-17\n",
      "Initial log joint probability = -29154.5\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7510.97    0.00146602      0.506357       0.774       0.774       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7510.97   0.000342185      0.117781      0.8527      0.8527       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-18\n",
      "Initial log joint probability = -34300.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7516.69    0.00127197       2.88147      0.5537      0.5537       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7516.69   0.000141647       0.13183           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-24\n",
      "Initial log joint probability = -34300.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7521.38    0.00733488       4.79085      0.8268      0.8268       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7521.37    0.00239756      0.145091           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-02-25\n",
      "Initial log joint probability = -25657.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7536.39    0.00329218       1.26164           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7536.39   9.33077e-05     0.0870384      0.4144           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-03\n",
      "Initial log joint probability = -24722.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7539.49   0.000594923      0.472252           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7539.49   0.000218145     0.0521371           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-04\n",
      "Initial log joint probability = -22190.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7546.61   0.000453346      0.465023      0.5123           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7546.61   0.000189364      0.227266      0.5174      0.5174       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-10\n",
      "Initial log joint probability = -25949.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7554.67   0.000582766       1.11448           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7554.67   8.76939e-05     0.0882811      0.2682      0.9908       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-11\n",
      "Initial log joint probability = -26071.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7564.7    0.00139282       1.22714           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22       -7564.7   0.000115741      0.165753           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-15\n",
      "Initial log joint probability = -24933.3\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7567.79    0.00949722       7.00889           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7567.78     0.0010315       0.11978           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-17\n",
      "Initial log joint probability = -38173.4\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19       -7572.2   0.000528057      0.239097           1           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20       -7572.2   0.000181291       0.14217           1           1       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-18\n",
      "Initial log joint probability = -28186.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7582.33    0.00173888       0.82978           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7582.33   5.56773e-05     0.0702534      0.7325      0.7325       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-24\n",
      "Initial log joint probability = -28186.9\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7591.89    0.00171206      0.489893      0.4525           1       23   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7591.89   0.000181705     0.0296854           1           1       25   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-25\n",
      "Initial log joint probability = -30388.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7601.18   0.000544137      0.457631           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      22      -7601.18   4.32297e-05      0.163108      0.5104      0.5104       24   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-03-31\n",
      "Initial log joint probability = -30721.1\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19         -7613    0.00139761       2.73909           1           1       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21         -7613   0.000306214      0.224098           1           1       22   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-04-01\n",
      "Initial log joint probability = -29682.2\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7619.88   0.000492523      0.651052           1           1       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7619.88   0.000791741      0.104287           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-04-07\n",
      "Initial log joint probability = -25047.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7625.73   0.000317645      0.637156      0.9522      0.9522       20   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      20      -7625.73   0.000498326      0.143347           1           1       21   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "training on date range: 2007-07-07 2023-04-08\n",
      "Initial log joint probability = -23575.7\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7633.64   0.000328404      0.299992           1           1       21   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      21      -7633.64   0.000132502     0.0490495           1           1       23   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "from model_selection.cross_val_pipeline import TimeSeriesCrossVal\n",
    "\n",
    "tscv = TimeSeriesCrossVal(min_test_date=pd.to_datetime(\"2021-01-01\"), \n",
    "                          n_dates_per_fold=1, \n",
    "                          p_fighter_implied_col=p_fighter_implied_col)\n",
    "preds_df = tscv.get_cross_val_preds(\n",
    "    mod, \n",
    "    feat_ml_df.dropna(subset=[\n",
    "        *feat_cols, \"win_target\", p_fighter_implied_col,\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:      0.6872931833223032\n",
      "Moneyline accuracy:  0.6671078755790867\n"
     ]
    }
   ],
   "source": [
    "mod_pred = preds_df[\"y_pred\"].round()\n",
    "ml_pred = preds_df[p_fighter_implied_col].round()\n",
    "print(\"Model accuracy:     \", (mod_pred == preds_df[\"win_target\"]).mean())\n",
    "print(\"Moneyline accuracy: \", (ml_pred == preds_df[\"win_target\"]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model log loss    : 0.5842126888803446\n",
      "Moneyline log loss: 0.6093059101142347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "xce = log_loss(y_true=preds_df[\"win_target\"], y_pred=preds_df[\"y_pred\"])\n",
    "xce_ml = log_loss(y_true=preds_df[\"win_target\"], y_pred=preds_df[p_fighter_implied_col])\n",
    "\n",
    "print(f\"model log loss    : {xce}\")\n",
    "print(f\"Moneyline log loss: {xce_ml}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pred_elo_PC_0', 0.12692266126523014),\n",
       " ('pred_elo_PC_1', -0.00607351590357124),\n",
       " ('pred_elo_PC_2', 0.011390872800529807),\n",
       " ('pred_elo_PC_3', 0.014745384663850754),\n",
       " ('pred_elo_PC_4', 0.026891482602178277),\n",
       " ('pred_elo_PC_5', -0.016858051901774213),\n",
       " ('pred_elo_PC_6', 0.0157363853000452),\n",
       " ('pred_elo_PC_7', -0.027054117037258695),\n",
       " ('pred_elo_PC_8', 0.0032927078121352854),\n",
       " ('pred_elo_PC_9', 0.018330779273314814),\n",
       " ('pred_elo_PC_10', 0.019742145673792507),\n",
       " ('pred_elo_PC_11', -0.011541903468166706),\n",
       " ('pred_elo_PC_12', -0.014030449349378481),\n",
       " ('pred_elo_PC_13', 0.04503259196367915),\n",
       " ('pred_elo_signed_inverse_fight_time', -0.06810929714948435),\n",
       " ('pred_elo_win_target', 0.4106580682500054),\n",
       " ('pred_elo_win_target_finish', -0.406010021186982),\n",
       " ('age_diff', 0.2453182226152809),\n",
       " ('log_reach_diff', 0.048954109997998006),\n",
       " ('weight_diff', 0.009505251979826154),\n",
       " ('height_diff', 0.025067252990634423),\n",
       " ('log_t_since_prev_fight_diff', -0.16908464459747627),\n",
       " ('log_t_since_first_fight_diff', 0.23753627086597198),\n",
       " ('total_fights_diff', 0.00041870518208808773),\n",
       " ('usa_diff', -0.04651730090947012),\n",
       " ('russia_diff', 0.07060301342579814),\n",
       " ('stance_diff', 0.07584625437480437)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(mod.feat_cols, mod.fit['beta']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"week\"] = preds_df[\"Date\"].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight_id</th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>FighterOpen</th>\n",
       "      <th>OpponentOpen</th>\n",
       "      <th>fighter_dec_odds</th>\n",
       "      <th>opponent_dec_odds</th>\n",
       "      <th>p_fighter_rf</th>\n",
       "      <th>p_opponent_rf</th>\n",
       "      <th>fighter_stake</th>\n",
       "      <th>...</th>\n",
       "      <th>p_bankroll_opponent</th>\n",
       "      <th>fighter_possible_collect</th>\n",
       "      <th>opponent_possible_collect</th>\n",
       "      <th>win_target</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>fight_profit</th>\n",
       "      <th>fighter_profit</th>\n",
       "      <th>opponent_profit</th>\n",
       "      <th>week</th>\n",
       "      <th>final_portfolio_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-06_4807972_4916248</td>\n",
       "      <td>4807972</td>\n",
       "      <td>4916248</td>\n",
       "      <td>-150.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.703034</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-16_2614933_3164030</td>\n",
       "      <td>3164030</td>\n",
       "      <td>2614933</td>\n",
       "      <td>115.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>1.740741</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334689</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>2</td>\n",
       "      <td>1.008077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-16_4065639_4397782</td>\n",
       "      <td>4065639</td>\n",
       "      <td>4397782</td>\n",
       "      <td>-240.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>3.050000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.629759</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>2</td>\n",
       "      <td>1.008077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-16_4257695_4566145</td>\n",
       "      <td>4566145</td>\n",
       "      <td>4257695</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>1.952381</td>\n",
       "      <td>1.869565</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457533</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>2</td>\n",
       "      <td>1.008077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-16_4354426_4570669</td>\n",
       "      <td>4354426</td>\n",
       "      <td>4570669</td>\n",
       "      <td>225.0</td>\n",
       "      <td>-265.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>1.377358</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335418</td>\n",
       "      <td>-0.000906</td>\n",
       "      <td>-0.000906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.008077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>2022-12-31_4906245_4915407</td>\n",
       "      <td>4915407</td>\n",
       "      <td>4906245</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>6.454515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>2022-12-31_3164799_4280789</td>\n",
       "      <td>4280789</td>\n",
       "      <td>3164799</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434067</td>\n",
       "      <td>0.037675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037675</td>\n",
       "      <td>52</td>\n",
       "      <td>6.454515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>2022-12-31_5122234_5122235</td>\n",
       "      <td>5122234</td>\n",
       "      <td>5122235</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.157159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.624391</td>\n",
       "      <td>0.204307</td>\n",
       "      <td>0.204307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>6.454515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>2022-12-31_5015120_5068813</td>\n",
       "      <td>5015120</td>\n",
       "      <td>5068813</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215546</td>\n",
       "      <td>0.062356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062356</td>\n",
       "      <td>52</td>\n",
       "      <td>6.454515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>2022-12-31_4972538_4981352</td>\n",
       "      <td>4981352</td>\n",
       "      <td>4972538</td>\n",
       "      <td>230.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>6.454515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3022 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fight_id FighterID_espn OpponentID_espn FighterOpen  \\\n",
       "0     2023-01-06_4807972_4916248        4807972         4916248      -150.0   \n",
       "1     2021-01-16_2614933_3164030        3164030         2614933       115.0   \n",
       "2     2021-01-16_4065639_4397782        4065639         4397782      -240.0   \n",
       "3     2021-01-16_4257695_4566145        4566145         4257695      -105.0   \n",
       "4     2021-01-16_4354426_4570669        4354426         4570669       225.0   \n",
       "...                          ...            ...             ...         ...   \n",
       "3017  2022-12-31_4906245_4915407        4915407         4906245      -180.0   \n",
       "3018  2022-12-31_3164799_4280789        4280789         3164799      -120.0   \n",
       "3019  2022-12-31_5122234_5122235        5122234         5122235       130.0   \n",
       "3020  2022-12-31_5015120_5068813        5015120         5068813       180.0   \n",
       "3021  2022-12-31_4972538_4981352        4981352         4972538       230.0   \n",
       "\n",
       "     OpponentOpen  fighter_dec_odds  opponent_dec_odds  p_fighter_rf  \\\n",
       "0           120.0          1.666667           2.200000      0.600000   \n",
       "1          -135.0          2.150000           1.740741      0.465116   \n",
       "2           205.0          1.416667           3.050000      0.705882   \n",
       "3          -115.0          1.952381           1.869565      0.512195   \n",
       "4          -265.0          3.250000           1.377358      0.307692   \n",
       "...           ...               ...                ...           ...   \n",
       "3017        150.0          1.555556           2.500000      0.642857   \n",
       "3018       -110.0          1.833333           1.909091      0.545455   \n",
       "3019       -160.0          2.300000           1.625000      0.434783   \n",
       "3020       -225.0          2.800000           1.444444      0.357143   \n",
       "3021       -300.0          3.300000           1.333333      0.303030   \n",
       "\n",
       "      p_opponent_rf fighter_stake  ... p_bankroll_opponent  \\\n",
       "0          0.454545          0.05  ...                 0.0   \n",
       "1          0.574468           0.0  ...            0.005083   \n",
       "2          0.327869           0.0  ...            0.001501   \n",
       "3          0.534884           0.0  ...            0.000388   \n",
       "4          0.726027      0.000906  ...                 0.0   \n",
       "...             ...           ...  ...                 ...   \n",
       "3017       0.400000           0.0  ...                 0.0   \n",
       "3018       0.523810           0.0  ...            0.006805   \n",
       "3019       0.615385      0.157159  ...                 0.0   \n",
       "3020       0.692308           0.0  ...            0.023036   \n",
       "3021       0.750000           0.0  ...                 0.0   \n",
       "\n",
       "     fighter_possible_collect opponent_possible_collect win_target    y_pred  \\\n",
       "0                    0.083333                       0.0        0.0  0.703034   \n",
       "1                         0.0                  0.008406        0.0  0.334689   \n",
       "2                         0.0                  0.004349        0.0  0.629759   \n",
       "3                         0.0                  0.000689        0.0  0.457533   \n",
       "4                    0.002944                       0.0        0.0  0.335418   \n",
       "...                       ...                       ...        ...       ...   \n",
       "3017                      0.0                       0.0        0.0  0.606487   \n",
       "3018                      0.0                  0.079117        0.0  0.434067   \n",
       "3019                 0.361467                       0.0        1.0  0.624391   \n",
       "3020                      0.0                  0.202656        0.0  0.215546   \n",
       "3021                      0.0                       0.0        0.0  0.256220   \n",
       "\n",
       "      fight_profit  fighter_profit  opponent_profit  week  \\\n",
       "0        -0.050000       -0.050000         0.000000     1   \n",
       "1         0.003577        0.000000         0.003577     2   \n",
       "2         0.002923        0.000000         0.002923     2   \n",
       "3         0.000321        0.000000         0.000321     2   \n",
       "4        -0.000906       -0.000906         0.000000     2   \n",
       "...            ...             ...              ...   ...   \n",
       "3017      0.000000        0.000000         0.000000    52   \n",
       "3018      0.037675        0.000000         0.037675    52   \n",
       "3019      0.204307        0.204307         0.000000    52   \n",
       "3020      0.062356        0.000000         0.062356    52   \n",
       "3021      0.000000        0.000000         0.000000    52   \n",
       "\n",
       "      final_portfolio_value  \n",
       "0                  0.950000  \n",
       "1                  1.008077  \n",
       "2                  1.008077  \n",
       "3                  1.008077  \n",
       "4                  1.008077  \n",
       "...                     ...  \n",
       "3017               6.454515  \n",
       "3018               6.454515  \n",
       "3019               6.454515  \n",
       "3020               6.454515  \n",
       "3021               6.454515  \n",
       "\n",
       "[3022 rows x 22 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_selection.backtesting import MultiKellyPortfolioManager, TradingSimulator\n",
    "\n",
    "fighter_ml_col = \"FighterOpen\"\n",
    "opponent_ml_col = \"OpponentOpen\"\n",
    "\n",
    "kwargs = {\n",
    "    \"fighter_ml_col\": fighter_ml_col,\n",
    "    \"opponent_ml_col\": opponent_ml_col,\n",
    "}\n",
    "\n",
    "kelly_pm = MultiKellyPortfolioManager(max_bankroll_fraction=0.05, **kwargs)\n",
    "ts = TradingSimulator(kelly_pm, **kwargs)\n",
    "ts.simulate_trading(preds_df, bet_ts_col=\"week\", payout_ts_col=\"week\")\n",
    "ts.returns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts.plot_diagnostics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kelly_pm0 = MultiKellyPortfolioManager(max_bankroll_fraction=0.05, **kwargs)\n",
    "ts0 = TradingSimulator(kelly_pm0, **kwargs)\n",
    "ts0.simulate_trading(preds_df.query(\"is_ufc == 0\"), bet_ts_col=\"week\", payout_ts_col=\"week\")\n",
    "ts0.plot_diagnostics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kelly_pm1 = MultiKellyPortfolioManager(max_bankroll_fraction=0.05, **kwargs)\n",
    "ts1 = TradingSimulator(kelly_pm1, **kwargs)\n",
    "ts1.simulate_trading(preds_df.query(\"is_ufc == 1\"), bet_ts_col=\"week\", payout_ts_col=\"week\")\n",
    "ts1.plot_diagnostics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation - BetMGM, DraftKings, BetFair\n",
    "\n",
    "I think something's fishy here, this can't be right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16250, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "match_id               0.000000\n",
       "EventHref              0.000000\n",
       "DraftKings_fighter     0.765046\n",
       "BetMGM_fighter         0.792862\n",
       "Caesars_fighter        0.786954\n",
       "BetRivers_fighter      0.863877\n",
       "FanDuel_fighter        0.764554\n",
       "PointsBet_fighter      0.904000\n",
       "Unibet_fighter         0.813908\n",
       "BetWay_fighter         0.658954\n",
       "5D_fighter             0.086154\n",
       "Ref_fighter            0.018338\n",
       "FighterID_bfo          0.000000\n",
       "Bet365_fighter         0.902031\n",
       "DraftKings_opponent    0.765046\n",
       "BetMGM_opponent        0.792862\n",
       "Caesars_opponent       0.786954\n",
       "BetRivers_opponent     0.863877\n",
       "FanDuel_opponent       0.764554\n",
       "PointsBet_opponent     0.904000\n",
       "Unibet_opponent        0.813908\n",
       "BetWay_opponent        0.658954\n",
       "5D_opponent            0.086154\n",
       "Ref_opponent           0.018338\n",
       "OpponentID_bfo         0.000000\n",
       "Bet365_opponent        0.902031\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_df = base_db_interface.read(\"clean_bfo_close_data\")\n",
    "# double the data\n",
    "fighter_cols = [c for c in close_df.columns if c.endswith(\"_fighter\")]\n",
    "opponent_cols = [c[:-len(\"_fighter\")] + \"_opponent\" for c in fighter_cols]\n",
    "for col in fighter_cols + opponent_cols:\n",
    "    close_df[col] = close_df[col].str.replace(\"â–²\", \"\")\\\n",
    "        .str.replace(\"â–¼\", \"\")\\\n",
    "        .astype(float)\n",
    "    \n",
    "close_df_complement = close_df.rename(columns={\n",
    "    \"FighterID\": \"OpponentID\",\n",
    "    \"OpponentID\": \"FighterID\",\n",
    "    **{f: o for f, o in zip(fighter_cols, opponent_cols)},\n",
    "    **{o: f for f, o in zip(fighter_cols, opponent_cols)},\n",
    "})\n",
    "close_df = pd.concat([close_df, close_df_complement], axis=0)\\\n",
    "    .drop_duplicates(subset=[\"FighterID\", \"OpponentID\", \"EventHref\"])\\\n",
    "    .dropna(subset=[\"FighterID\", \"OpponentID\", \"EventHref\"])\\\n",
    "    .rename(columns={\"FighterID\": \"FighterID_bfo\", \"OpponentID\": \"OpponentID_bfo\"})\\\n",
    "    .drop(columns=[\"FighterName\", \"OpponentName\"])\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "print(close_df.shape)\n",
    "close_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122872            Calvin-Kattar-717\n",
       "122873                Wu-Yanan-8993\n",
       "122874             Justin-Tafa-9315\n",
       "122875           Jacob-Kilburn-8472\n",
       "122876           Ramazan-Emeev-7452\n",
       "                    ...            \n",
       "132966    Christian-Rodriquez-15110\n",
       "132967      Gerald-Meerschaert-3628\n",
       "132971        Cynthia-Calvillo-6940\n",
       "132980       Magomed-Umalatov-11254\n",
       "132981            David-Zawada-5347\n",
       "Name: FighterID_bfo, Length: 3022, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df[\"FighterID_bfo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fight_id_legacy    0.000000\n",
       "Date               0.000000\n",
       "FighterResult      0.000000\n",
       "Decision           0.000000\n",
       "Rnd                0.000000\n",
       "                     ...   \n",
       "Unibet_opponent    0.573461\n",
       "BetWay_opponent    0.269689\n",
       "5D_opponent        0.425215\n",
       "Ref_opponent       0.271013\n",
       "Bet365_opponent    0.795169\n",
       "Length: 413, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_preds_df = preds_df.merge(\n",
    "    close_df,\n",
    "    how=\"left\",\n",
    "    on=[\"FighterID_bfo\", \"OpponentID_bfo\", \"EventHref\"],\n",
    ")\n",
    "aug_preds_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DraftKings_fighter</th>\n",
       "      <th>BetMGM_fighter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16245</th>\n",
       "      <td>-365.0</td>\n",
       "      <td>-450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16246</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16247</th>\n",
       "      <td>-435.0</td>\n",
       "      <td>-450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16248</th>\n",
       "      <td>575.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16249</th>\n",
       "      <td>-900.0</td>\n",
       "      <td>-1200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16250 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DraftKings_fighter  BetMGM_fighter\n",
       "0                     NaN             NaN\n",
       "1                     NaN             NaN\n",
       "2                     NaN             NaN\n",
       "3                     NaN             NaN\n",
       "4                     NaN             NaN\n",
       "...                   ...             ...\n",
       "16245              -365.0          -450.0\n",
       "16246                 NaN          -450.0\n",
       "16247              -435.0          -450.0\n",
       "16248               575.0           600.0\n",
       "16249              -900.0         -1200.0\n",
       "\n",
       "[16250 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_df[[\"DraftKings_fighter\", \"BetMGM_fighter\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122872    115.0\n",
       "122873   -240.0\n",
       "122874   -105.0\n",
       "122875    225.0\n",
       "122876   -210.0\n",
       "          ...  \n",
       "132966    210.0\n",
       "132967    250.0\n",
       "132971    275.0\n",
       "132980   -900.0\n",
       "132981    125.0\n",
       "Name: FighterOpen, Length: 3022, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df[fighter_ml_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "market = \"DraftKings\"\n",
    "# market = \"BetMGM\"\n",
    "\n",
    "kwargs = {\n",
    "    \"fighter_ml_col\": f\"{market}_fighter\",\n",
    "    \"opponent_ml_col\": f\"{market}_opponent\",\n",
    "}\n",
    "\n",
    "temp_preds_df = aug_preds_df.dropna(subset=[\n",
    "    f\"{market}_fighter\", f\"{market}_opponent\"\n",
    "])\n",
    "temp_preds_df\n",
    "\n",
    "# print(\"overall winnings\")\n",
    "# pm = MultiKellyPM(temp_preds_df, **kwargs)\n",
    "# event_return_df = pm.get_all_returns()\n",
    "# pm.plot_diagnostics(event_return_df, x_col=\"week\")\n",
    "\n",
    "# print(\"ufc winnings\")\n",
    "# pm = MultiKellyPM(temp_preds_df.query(\"is_ufc == 1\"), **kwargs)\n",
    "# event_return_df = pm.get_all_returns()\n",
    "# pm.plot_diagnostics(event_return_df, x_col=\"week\")\n",
    "\n",
    "# print(\"non-ufc winnings\")\n",
    "# pm = MultiKellyPM(temp_preds_df.query(\"is_ufc == 0\"), **kwargs)\n",
    "# event_return_df = pm.get_all_returns()\n",
    "# pm.plot_diagnostics(event_return_df, x_col=\"week\")\n",
    "\n",
    "kelly_pm_close = MultiKellyPortfolioManager(max_bankroll_fraction=0.05, **kwargs)\n",
    "ts_close = TradingSimulator(kelly_pm_close, **kwargs)\n",
    "ts_close.simulate_trading(temp_preds_df, bet_ts_col=\"week\", payout_ts_col=\"week\")\n",
    "ts_close.plot_diagnostics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for upcoming fights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>pred_elo_PC_0</th>\n",
       "      <th>pred_elo_PC_1</th>\n",
       "      <th>pred_elo_PC_2</th>\n",
       "      <th>pred_elo_PC_3</th>\n",
       "      <th>pred_elo_PC_4</th>\n",
       "      <th>pred_elo_PC_5</th>\n",
       "      <th>pred_elo_PC_6</th>\n",
       "      <th>pred_elo_PC_7</th>\n",
       "      <th>...</th>\n",
       "      <th>age_diff</th>\n",
       "      <th>log_reach_diff</th>\n",
       "      <th>weight_diff</th>\n",
       "      <th>height_diff</th>\n",
       "      <th>log_t_since_prev_fight_diff</th>\n",
       "      <th>log_t_since_first_fight_diff</th>\n",
       "      <th>total_fights_diff</th>\n",
       "      <th>usa_diff</th>\n",
       "      <th>russia_diff</th>\n",
       "      <th>stance_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132984</th>\n",
       "      <td>4863327</td>\n",
       "      <td>3949555</td>\n",
       "      <td>-0.195705</td>\n",
       "      <td>-0.249167</td>\n",
       "      <td>-0.068994</td>\n",
       "      <td>0.682357</td>\n",
       "      <td>0.265850</td>\n",
       "      <td>0.332739</td>\n",
       "      <td>-0.606089</td>\n",
       "      <td>0.157302</td>\n",
       "      <td>...</td>\n",
       "      <td>7.317808</td>\n",
       "      <td>0.081126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.528675</td>\n",
       "      <td>-0.510659</td>\n",
       "      <td>-7</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132985</th>\n",
       "      <td>4397782</td>\n",
       "      <td>4040197</td>\n",
       "      <td>0.112259</td>\n",
       "      <td>0.714654</td>\n",
       "      <td>0.967333</td>\n",
       "      <td>-1.279557</td>\n",
       "      <td>0.390686</td>\n",
       "      <td>-0.224637</td>\n",
       "      <td>0.238147</td>\n",
       "      <td>0.725284</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295890</td>\n",
       "      <td>0.036368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084218</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132986</th>\n",
       "      <td>4232775</td>\n",
       "      <td>3994033</td>\n",
       "      <td>0.202585</td>\n",
       "      <td>0.976380</td>\n",
       "      <td>0.029361</td>\n",
       "      <td>-1.416281</td>\n",
       "      <td>-0.196303</td>\n",
       "      <td>-0.420252</td>\n",
       "      <td>0.437974</td>\n",
       "      <td>-0.305062</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.369863</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.354646</td>\n",
       "      <td>-0.046496</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132987</th>\n",
       "      <td>4076472</td>\n",
       "      <td>4063667</td>\n",
       "      <td>0.210980</td>\n",
       "      <td>0.391183</td>\n",
       "      <td>-0.089732</td>\n",
       "      <td>-0.591662</td>\n",
       "      <td>-0.648010</td>\n",
       "      <td>0.036722</td>\n",
       "      <td>0.744049</td>\n",
       "      <td>-0.196450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.950685</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.507671</td>\n",
       "      <td>0.142094</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132988</th>\n",
       "      <td>3045734</td>\n",
       "      <td>3961293</td>\n",
       "      <td>-0.381281</td>\n",
       "      <td>-0.505066</td>\n",
       "      <td>0.555358</td>\n",
       "      <td>0.363368</td>\n",
       "      <td>0.224523</td>\n",
       "      <td>0.700904</td>\n",
       "      <td>0.680059</td>\n",
       "      <td>-0.225259</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.624658</td>\n",
       "      <td>-0.030305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.619535</td>\n",
       "      <td>0.358149</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132989</th>\n",
       "      <td>2335674</td>\n",
       "      <td>4690549</td>\n",
       "      <td>0.285680</td>\n",
       "      <td>-0.398737</td>\n",
       "      <td>0.437694</td>\n",
       "      <td>-1.458451</td>\n",
       "      <td>-0.138322</td>\n",
       "      <td>0.162732</td>\n",
       "      <td>-0.757358</td>\n",
       "      <td>-0.317639</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.665753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110348</td>\n",
       "      <td>0.809855</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132991</th>\n",
       "      <td>2594871</td>\n",
       "      <td>4227265</td>\n",
       "      <td>-0.194510</td>\n",
       "      <td>0.650643</td>\n",
       "      <td>-0.265063</td>\n",
       "      <td>-0.548014</td>\n",
       "      <td>0.247813</td>\n",
       "      <td>0.141773</td>\n",
       "      <td>0.096254</td>\n",
       "      <td>-1.325625</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.021918</td>\n",
       "      <td>0.061036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.375433</td>\n",
       "      <td>-0.061522</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132993</th>\n",
       "      <td>3900088</td>\n",
       "      <td>2526299</td>\n",
       "      <td>0.345742</td>\n",
       "      <td>0.411075</td>\n",
       "      <td>-0.050783</td>\n",
       "      <td>0.761484</td>\n",
       "      <td>-0.134104</td>\n",
       "      <td>-1.021289</td>\n",
       "      <td>-1.008232</td>\n",
       "      <td>0.382047</td>\n",
       "      <td>...</td>\n",
       "      <td>2.882192</td>\n",
       "      <td>-0.068993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.164626</td>\n",
       "      <td>-0.320020</td>\n",
       "      <td>-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132996</th>\n",
       "      <td>3902098</td>\n",
       "      <td>2614933</td>\n",
       "      <td>-0.981286</td>\n",
       "      <td>-0.950759</td>\n",
       "      <td>-0.842446</td>\n",
       "      <td>0.633129</td>\n",
       "      <td>-0.954096</td>\n",
       "      <td>-0.628756</td>\n",
       "      <td>0.892606</td>\n",
       "      <td>-0.476728</td>\n",
       "      <td>...</td>\n",
       "      <td>2.136986</td>\n",
       "      <td>0.014389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.533062</td>\n",
       "      <td>-0.133283</td>\n",
       "      <td>-10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132997</th>\n",
       "      <td>4394200</td>\n",
       "      <td>4963343</td>\n",
       "      <td>0.321315</td>\n",
       "      <td>0.165845</td>\n",
       "      <td>-0.302548</td>\n",
       "      <td>0.084098</td>\n",
       "      <td>0.106047</td>\n",
       "      <td>0.583619</td>\n",
       "      <td>-0.376468</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.315068</td>\n",
       "      <td>0.038915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.018780</td>\n",
       "      <td>0.409856</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132999</th>\n",
       "      <td>4089026</td>\n",
       "      <td>4816066</td>\n",
       "      <td>-1.073514</td>\n",
       "      <td>-0.620703</td>\n",
       "      <td>0.211283</td>\n",
       "      <td>-0.816519</td>\n",
       "      <td>0.877023</td>\n",
       "      <td>-0.425521</td>\n",
       "      <td>0.448058</td>\n",
       "      <td>0.218753</td>\n",
       "      <td>...</td>\n",
       "      <td>2.512329</td>\n",
       "      <td>-0.007905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.142372</td>\n",
       "      <td>0.183711</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133003</th>\n",
       "      <td>4239928</td>\n",
       "      <td>3020090</td>\n",
       "      <td>0.088705</td>\n",
       "      <td>0.837004</td>\n",
       "      <td>-0.081885</td>\n",
       "      <td>0.039529</td>\n",
       "      <td>-0.063510</td>\n",
       "      <td>-0.524971</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>-0.584603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391781</td>\n",
       "      <td>0.029853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.942802</td>\n",
       "      <td>-0.174199</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133004</th>\n",
       "      <td>2512055</td>\n",
       "      <td>2335754</td>\n",
       "      <td>0.532863</td>\n",
       "      <td>0.326385</td>\n",
       "      <td>0.068641</td>\n",
       "      <td>-0.647781</td>\n",
       "      <td>-0.200518</td>\n",
       "      <td>-0.350859</td>\n",
       "      <td>0.444590</td>\n",
       "      <td>-0.384626</td>\n",
       "      <td>...</td>\n",
       "      <td>3.835616</td>\n",
       "      <td>-0.026317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.442064</td>\n",
       "      <td>-0.259292</td>\n",
       "      <td>-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133010</th>\n",
       "      <td>4418784</td>\n",
       "      <td>4292349</td>\n",
       "      <td>-0.058534</td>\n",
       "      <td>0.294277</td>\n",
       "      <td>-0.205873</td>\n",
       "      <td>0.369073</td>\n",
       "      <td>1.105809</td>\n",
       "      <td>0.260411</td>\n",
       "      <td>0.249523</td>\n",
       "      <td>0.678917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206614</td>\n",
       "      <td>-0.514944</td>\n",
       "      <td>-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133011</th>\n",
       "      <td>3151289</td>\n",
       "      <td>3922491</td>\n",
       "      <td>-0.599303</td>\n",
       "      <td>1.475839</td>\n",
       "      <td>-0.967742</td>\n",
       "      <td>0.014702</td>\n",
       "      <td>0.082234</td>\n",
       "      <td>0.185902</td>\n",
       "      <td>-0.429443</td>\n",
       "      <td>0.737151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.253860</td>\n",
       "      <td>0.069939</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133012</th>\n",
       "      <td>2504643</td>\n",
       "      <td>4333158</td>\n",
       "      <td>0.096802</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>-0.012390</td>\n",
       "      <td>-0.223778</td>\n",
       "      <td>-0.185530</td>\n",
       "      <td>0.124228</td>\n",
       "      <td>-0.563981</td>\n",
       "      <td>-0.172217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153586</td>\n",
       "      <td>0.205259</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133013</th>\n",
       "      <td>3970873</td>\n",
       "      <td>4688408</td>\n",
       "      <td>0.064634</td>\n",
       "      <td>-0.146394</td>\n",
       "      <td>-0.327473</td>\n",
       "      <td>-0.314480</td>\n",
       "      <td>0.571793</td>\n",
       "      <td>-0.969727</td>\n",
       "      <td>-0.644147</td>\n",
       "      <td>-0.022577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889154</td>\n",
       "      <td>0.555333</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133014</th>\n",
       "      <td>5060394</td>\n",
       "      <td>4324623</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>-0.173635</td>\n",
       "      <td>-0.246236</td>\n",
       "      <td>0.611450</td>\n",
       "      <td>0.029376</td>\n",
       "      <td>-0.293469</td>\n",
       "      <td>-0.144704</td>\n",
       "      <td>0.112844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.497977</td>\n",
       "      <td>-0.736978</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133016</th>\n",
       "      <td>3922557</td>\n",
       "      <td>4217395</td>\n",
       "      <td>0.811043</td>\n",
       "      <td>-0.521314</td>\n",
       "      <td>0.688678</td>\n",
       "      <td>-0.772041</td>\n",
       "      <td>-0.924842</td>\n",
       "      <td>0.167326</td>\n",
       "      <td>0.041051</td>\n",
       "      <td>-0.088420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664368</td>\n",
       "      <td>0.064518</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133017</th>\n",
       "      <td>3309918</td>\n",
       "      <td>4277049</td>\n",
       "      <td>0.266692</td>\n",
       "      <td>-0.070910</td>\n",
       "      <td>-0.008271</td>\n",
       "      <td>0.098454</td>\n",
       "      <td>1.143072</td>\n",
       "      <td>-0.191985</td>\n",
       "      <td>0.049392</td>\n",
       "      <td>-0.488933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244263</td>\n",
       "      <td>0.361569</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133019</th>\n",
       "      <td>3894823</td>\n",
       "      <td>2502364</td>\n",
       "      <td>0.130970</td>\n",
       "      <td>-0.318741</td>\n",
       "      <td>0.264974</td>\n",
       "      <td>-0.204758</td>\n",
       "      <td>-0.554714</td>\n",
       "      <td>0.351630</td>\n",
       "      <td>1.418354</td>\n",
       "      <td>-0.401714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053653</td>\n",
       "      <td>-0.222785</td>\n",
       "      <td>-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133020</th>\n",
       "      <td>4339130</td>\n",
       "      <td>2503659</td>\n",
       "      <td>0.593418</td>\n",
       "      <td>0.810061</td>\n",
       "      <td>-1.324708</td>\n",
       "      <td>1.662906</td>\n",
       "      <td>-1.107296</td>\n",
       "      <td>0.308445</td>\n",
       "      <td>-0.269646</td>\n",
       "      <td>0.517220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.164308</td>\n",
       "      <td>-1.262711</td>\n",
       "      <td>-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133021</th>\n",
       "      <td>3089069</td>\n",
       "      <td>3030256</td>\n",
       "      <td>-0.657081</td>\n",
       "      <td>-0.592595</td>\n",
       "      <td>-0.228173</td>\n",
       "      <td>0.164238</td>\n",
       "      <td>0.157888</td>\n",
       "      <td>-0.295335</td>\n",
       "      <td>-1.117541</td>\n",
       "      <td>0.123758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.594022</td>\n",
       "      <td>-0.262904</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133022</th>\n",
       "      <td>4024488</td>\n",
       "      <td>5080935</td>\n",
       "      <td>-0.163086</td>\n",
       "      <td>0.291715</td>\n",
       "      <td>0.040737</td>\n",
       "      <td>-0.177596</td>\n",
       "      <td>-0.124726</td>\n",
       "      <td>-0.038337</td>\n",
       "      <td>0.315883</td>\n",
       "      <td>-0.280897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027292</td>\n",
       "      <td>0.355801</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133025</th>\n",
       "      <td>4815974</td>\n",
       "      <td>4389093</td>\n",
       "      <td>-0.657956</td>\n",
       "      <td>-0.746681</td>\n",
       "      <td>0.398674</td>\n",
       "      <td>0.335451</td>\n",
       "      <td>-0.073774</td>\n",
       "      <td>0.162743</td>\n",
       "      <td>0.178847</td>\n",
       "      <td>0.537192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712317</td>\n",
       "      <td>-0.901612</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133034</th>\n",
       "      <td>4375156</td>\n",
       "      <td>4686725</td>\n",
       "      <td>-0.019820</td>\n",
       "      <td>0.556889</td>\n",
       "      <td>0.191263</td>\n",
       "      <td>0.706798</td>\n",
       "      <td>-0.076375</td>\n",
       "      <td>0.164163</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.554404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.050603</td>\n",
       "      <td>-0.027378</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133035</th>\n",
       "      <td>4835137</td>\n",
       "      <td>4012999</td>\n",
       "      <td>-0.243549</td>\n",
       "      <td>0.132756</td>\n",
       "      <td>0.828913</td>\n",
       "      <td>0.262290</td>\n",
       "      <td>1.633730</td>\n",
       "      <td>-0.290362</td>\n",
       "      <td>0.412471</td>\n",
       "      <td>-0.497415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349184</td>\n",
       "      <td>-0.104183</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133036</th>\n",
       "      <td>2558075</td>\n",
       "      <td>4903365</td>\n",
       "      <td>0.147911</td>\n",
       "      <td>0.056638</td>\n",
       "      <td>0.130269</td>\n",
       "      <td>-1.129835</td>\n",
       "      <td>-0.065689</td>\n",
       "      <td>0.484352</td>\n",
       "      <td>0.012530</td>\n",
       "      <td>0.163817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121890</td>\n",
       "      <td>1.049269</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133037</th>\n",
       "      <td>4251462</td>\n",
       "      <td>2517186</td>\n",
       "      <td>0.165704</td>\n",
       "      <td>0.569984</td>\n",
       "      <td>-0.608713</td>\n",
       "      <td>-0.955094</td>\n",
       "      <td>0.774204</td>\n",
       "      <td>-0.695898</td>\n",
       "      <td>0.266996</td>\n",
       "      <td>0.132750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.835501</td>\n",
       "      <td>-0.461602</td>\n",
       "      <td>-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133039</th>\n",
       "      <td>4914568</td>\n",
       "      <td>4702563</td>\n",
       "      <td>0.219062</td>\n",
       "      <td>0.759179</td>\n",
       "      <td>-0.001518</td>\n",
       "      <td>0.400720</td>\n",
       "      <td>-0.156865</td>\n",
       "      <td>0.096837</td>\n",
       "      <td>0.471451</td>\n",
       "      <td>-0.102770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285991</td>\n",
       "      <td>-0.706106</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133040</th>\n",
       "      <td>4227055</td>\n",
       "      <td>4034272</td>\n",
       "      <td>0.457317</td>\n",
       "      <td>0.834310</td>\n",
       "      <td>-0.451403</td>\n",
       "      <td>0.590604</td>\n",
       "      <td>0.782637</td>\n",
       "      <td>-0.339107</td>\n",
       "      <td>-0.273679</td>\n",
       "      <td>0.292134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173272</td>\n",
       "      <td>0.208359</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133041</th>\n",
       "      <td>2988175</td>\n",
       "      <td>4406574</td>\n",
       "      <td>-0.043845</td>\n",
       "      <td>0.520167</td>\n",
       "      <td>0.217524</td>\n",
       "      <td>-0.965000</td>\n",
       "      <td>0.505374</td>\n",
       "      <td>-0.239545</td>\n",
       "      <td>-0.556433</td>\n",
       "      <td>-0.638585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.113944</td>\n",
       "      <td>0.503882</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133042</th>\n",
       "      <td>4426250</td>\n",
       "      <td>4684474</td>\n",
       "      <td>0.019640</td>\n",
       "      <td>-0.775182</td>\n",
       "      <td>0.577893</td>\n",
       "      <td>0.159711</td>\n",
       "      <td>-0.244184</td>\n",
       "      <td>-0.093082</td>\n",
       "      <td>1.441984</td>\n",
       "      <td>-0.586338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.835501</td>\n",
       "      <td>0.438607</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133043</th>\n",
       "      <td>4875506</td>\n",
       "      <td>4788300</td>\n",
       "      <td>-0.003243</td>\n",
       "      <td>-0.289146</td>\n",
       "      <td>0.241639</td>\n",
       "      <td>-0.335586</td>\n",
       "      <td>-0.151699</td>\n",
       "      <td>0.480890</td>\n",
       "      <td>0.339751</td>\n",
       "      <td>-0.014289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.027292</td>\n",
       "      <td>0.908553</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133046</th>\n",
       "      <td>4419372</td>\n",
       "      <td>3028863</td>\n",
       "      <td>0.882613</td>\n",
       "      <td>-0.245899</td>\n",
       "      <td>-0.084419</td>\n",
       "      <td>-1.801159</td>\n",
       "      <td>-0.421756</td>\n",
       "      <td>-0.629837</td>\n",
       "      <td>-0.266369</td>\n",
       "      <td>0.771705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232059</td>\n",
       "      <td>-0.546031</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133054</th>\n",
       "      <td>2951202</td>\n",
       "      <td>4081024</td>\n",
       "      <td>-0.122876</td>\n",
       "      <td>0.344964</td>\n",
       "      <td>-0.207511</td>\n",
       "      <td>-0.455348</td>\n",
       "      <td>0.505773</td>\n",
       "      <td>0.014431</td>\n",
       "      <td>-0.273535</td>\n",
       "      <td>0.666618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.221724</td>\n",
       "      <td>0.486626</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133055</th>\n",
       "      <td>4379258</td>\n",
       "      <td>4289516</td>\n",
       "      <td>0.313306</td>\n",
       "      <td>1.668011</td>\n",
       "      <td>0.238057</td>\n",
       "      <td>-0.932895</td>\n",
       "      <td>-0.193452</td>\n",
       "      <td>0.208198</td>\n",
       "      <td>0.587217</td>\n",
       "      <td>-0.659940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.671047</td>\n",
       "      <td>-0.198674</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133056</th>\n",
       "      <td>2504169</td>\n",
       "      <td>3085551</td>\n",
       "      <td>-0.175675</td>\n",
       "      <td>-0.268599</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.566623</td>\n",
       "      <td>0.537921</td>\n",
       "      <td>1.281252</td>\n",
       "      <td>0.577633</td>\n",
       "      <td>0.793715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117873</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133057</th>\n",
       "      <td>4032401</td>\n",
       "      <td>4421978</td>\n",
       "      <td>-0.377505</td>\n",
       "      <td>-1.312164</td>\n",
       "      <td>0.367624</td>\n",
       "      <td>-0.307423</td>\n",
       "      <td>-0.478049</td>\n",
       "      <td>-1.443996</td>\n",
       "      <td>0.521851</td>\n",
       "      <td>0.346934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.667093</td>\n",
       "      <td>0.184483</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133058</th>\n",
       "      <td>3953381</td>\n",
       "      <td>4245092</td>\n",
       "      <td>0.023338</td>\n",
       "      <td>-0.670303</td>\n",
       "      <td>-0.277535</td>\n",
       "      <td>-0.608048</td>\n",
       "      <td>0.641021</td>\n",
       "      <td>-0.186049</td>\n",
       "      <td>-0.890652</td>\n",
       "      <td>0.148667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.046213</td>\n",
       "      <td>-0.025136</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133059</th>\n",
       "      <td>3031559</td>\n",
       "      <td>3023388</td>\n",
       "      <td>0.630170</td>\n",
       "      <td>-0.044230</td>\n",
       "      <td>0.160650</td>\n",
       "      <td>-0.172191</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.184488</td>\n",
       "      <td>-0.466574</td>\n",
       "      <td>0.109992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.713478</td>\n",
       "      <td>0.247692</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133060</th>\n",
       "      <td>4245094</td>\n",
       "      <td>3971496</td>\n",
       "      <td>0.203367</td>\n",
       "      <td>-0.219879</td>\n",
       "      <td>-1.728134</td>\n",
       "      <td>0.602505</td>\n",
       "      <td>-0.470242</td>\n",
       "      <td>1.383190</td>\n",
       "      <td>-0.217612</td>\n",
       "      <td>0.632655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608110</td>\n",
       "      <td>-0.406027</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133065</th>\n",
       "      <td>5074126</td>\n",
       "      <td>4783385</td>\n",
       "      <td>-0.056904</td>\n",
       "      <td>-0.278366</td>\n",
       "      <td>0.242566</td>\n",
       "      <td>-0.321009</td>\n",
       "      <td>-0.185009</td>\n",
       "      <td>-0.059651</td>\n",
       "      <td>0.153842</td>\n",
       "      <td>0.123760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.519636</td>\n",
       "      <td>0.412738</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133066</th>\n",
       "      <td>4321051</td>\n",
       "      <td>5076593</td>\n",
       "      <td>-0.479688</td>\n",
       "      <td>-0.066555</td>\n",
       "      <td>0.989041</td>\n",
       "      <td>-0.253741</td>\n",
       "      <td>-0.123955</td>\n",
       "      <td>-0.148609</td>\n",
       "      <td>0.038582</td>\n",
       "      <td>0.302530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272779</td>\n",
       "      <td>0.096828</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133068</th>\n",
       "      <td>3913473</td>\n",
       "      <td>4684776</td>\n",
       "      <td>0.763423</td>\n",
       "      <td>0.183209</td>\n",
       "      <td>0.384434</td>\n",
       "      <td>-0.633261</td>\n",
       "      <td>0.194807</td>\n",
       "      <td>-0.317664</td>\n",
       "      <td>0.031905</td>\n",
       "      <td>0.013964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.216808</td>\n",
       "      <td>-0.180734</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133071</th>\n",
       "      <td>4275487</td>\n",
       "      <td>3024395</td>\n",
       "      <td>-0.625163</td>\n",
       "      <td>0.289565</td>\n",
       "      <td>0.255464</td>\n",
       "      <td>0.268661</td>\n",
       "      <td>-0.186597</td>\n",
       "      <td>-0.654163</td>\n",
       "      <td>-0.229661</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.027786</td>\n",
       "      <td>0.216503</td>\n",
       "      <td>-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133073</th>\n",
       "      <td>4687003</td>\n",
       "      <td>4881997</td>\n",
       "      <td>0.382454</td>\n",
       "      <td>-0.412174</td>\n",
       "      <td>0.419772</td>\n",
       "      <td>-0.704622</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>-0.067649</td>\n",
       "      <td>-0.587148</td>\n",
       "      <td>0.320651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.175009</td>\n",
       "      <td>-0.234475</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133078</th>\n",
       "      <td>4306125</td>\n",
       "      <td>4815998</td>\n",
       "      <td>0.430175</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>0.020797</td>\n",
       "      <td>0.122686</td>\n",
       "      <td>-0.342395</td>\n",
       "      <td>0.482577</td>\n",
       "      <td>1.142052</td>\n",
       "      <td>0.185939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.758530</td>\n",
       "      <td>0.615629</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133079</th>\n",
       "      <td>3115931</td>\n",
       "      <td>4021217</td>\n",
       "      <td>0.479946</td>\n",
       "      <td>1.099809</td>\n",
       "      <td>1.654416</td>\n",
       "      <td>-0.171943</td>\n",
       "      <td>0.203370</td>\n",
       "      <td>1.725225</td>\n",
       "      <td>-0.698627</td>\n",
       "      <td>0.767611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.328504</td>\n",
       "      <td>0.284359</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133080</th>\n",
       "      <td>3146944</td>\n",
       "      <td>2512976</td>\n",
       "      <td>0.619807</td>\n",
       "      <td>0.528609</td>\n",
       "      <td>0.260285</td>\n",
       "      <td>0.360597</td>\n",
       "      <td>-0.528526</td>\n",
       "      <td>-0.009197</td>\n",
       "      <td>0.713280</td>\n",
       "      <td>-0.306213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.935573</td>\n",
       "      <td>-0.479448</td>\n",
       "      <td>-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133081</th>\n",
       "      <td>4873640</td>\n",
       "      <td>4410084</td>\n",
       "      <td>0.019379</td>\n",
       "      <td>-0.697238</td>\n",
       "      <td>0.692133</td>\n",
       "      <td>-1.162415</td>\n",
       "      <td>0.314892</td>\n",
       "      <td>0.196571</td>\n",
       "      <td>0.023354</td>\n",
       "      <td>0.602986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.316037</td>\n",
       "      <td>-0.031966</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133082</th>\n",
       "      <td>4426312</td>\n",
       "      <td>4738092</td>\n",
       "      <td>-0.071143</td>\n",
       "      <td>-0.105174</td>\n",
       "      <td>0.226470</td>\n",
       "      <td>0.139899</td>\n",
       "      <td>0.096431</td>\n",
       "      <td>-0.010048</td>\n",
       "      <td>0.792512</td>\n",
       "      <td>-0.672556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984344</td>\n",
       "      <td>0.624639</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133084</th>\n",
       "      <td>3090893</td>\n",
       "      <td>4046059</td>\n",
       "      <td>-0.514279</td>\n",
       "      <td>0.045537</td>\n",
       "      <td>0.456830</td>\n",
       "      <td>-0.824749</td>\n",
       "      <td>-0.339423</td>\n",
       "      <td>0.332397</td>\n",
       "      <td>-0.178514</td>\n",
       "      <td>0.678643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.005953</td>\n",
       "      <td>0.332274</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133085</th>\n",
       "      <td>3088232</td>\n",
       "      <td>2500946</td>\n",
       "      <td>-0.363337</td>\n",
       "      <td>-0.168818</td>\n",
       "      <td>-1.722193</td>\n",
       "      <td>1.532001</td>\n",
       "      <td>0.190395</td>\n",
       "      <td>-1.475967</td>\n",
       "      <td>0.117545</td>\n",
       "      <td>-0.439120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.239779</td>\n",
       "      <td>-0.431805</td>\n",
       "      <td>-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133088</th>\n",
       "      <td>2335666</td>\n",
       "      <td>2504639</td>\n",
       "      <td>-0.262384</td>\n",
       "      <td>-0.043037</td>\n",
       "      <td>-0.112755</td>\n",
       "      <td>1.874633</td>\n",
       "      <td>-0.728907</td>\n",
       "      <td>1.372556</td>\n",
       "      <td>-1.303580</td>\n",
       "      <td>0.125084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226773</td>\n",
       "      <td>0.120628</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133089</th>\n",
       "      <td>4668069</td>\n",
       "      <td>3155846</td>\n",
       "      <td>-0.308709</td>\n",
       "      <td>-0.837457</td>\n",
       "      <td>0.404753</td>\n",
       "      <td>-0.200344</td>\n",
       "      <td>0.464319</td>\n",
       "      <td>0.783454</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>-0.674187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024015</td>\n",
       "      <td>-0.134321</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133092</th>\n",
       "      <td>4695736</td>\n",
       "      <td>4873642</td>\n",
       "      <td>0.640564</td>\n",
       "      <td>0.827686</td>\n",
       "      <td>0.150212</td>\n",
       "      <td>-0.497430</td>\n",
       "      <td>0.427796</td>\n",
       "      <td>-0.325431</td>\n",
       "      <td>-0.407120</td>\n",
       "      <td>-0.088253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482098</td>\n",
       "      <td>0.346808</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133098</th>\n",
       "      <td>2516131</td>\n",
       "      <td>2951361</td>\n",
       "      <td>0.443042</td>\n",
       "      <td>-0.700990</td>\n",
       "      <td>0.176203</td>\n",
       "      <td>-1.212771</td>\n",
       "      <td>-0.458434</td>\n",
       "      <td>-0.098586</td>\n",
       "      <td>1.531828</td>\n",
       "      <td>-0.365694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079714</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133100</th>\n",
       "      <td>2560746</td>\n",
       "      <td>3027545</td>\n",
       "      <td>-0.415478</td>\n",
       "      <td>-0.020843</td>\n",
       "      <td>0.940490</td>\n",
       "      <td>-0.412782</td>\n",
       "      <td>0.128540</td>\n",
       "      <td>0.924691</td>\n",
       "      <td>-0.142310</td>\n",
       "      <td>-0.718087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710743</td>\n",
       "      <td>0.269782</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FighterID_espn OpponentID_espn  pred_elo_PC_0  pred_elo_PC_1  \\\n",
       "132984        4863327         3949555      -0.195705      -0.249167   \n",
       "132985        4397782         4040197       0.112259       0.714654   \n",
       "132986        4232775         3994033       0.202585       0.976380   \n",
       "132987        4076472         4063667       0.210980       0.391183   \n",
       "132988        3045734         3961293      -0.381281      -0.505066   \n",
       "132989        2335674         4690549       0.285680      -0.398737   \n",
       "132991        2594871         4227265      -0.194510       0.650643   \n",
       "132993        3900088         2526299       0.345742       0.411075   \n",
       "132996        3902098         2614933      -0.981286      -0.950759   \n",
       "132997        4394200         4963343       0.321315       0.165845   \n",
       "132999        4089026         4816066      -1.073514      -0.620703   \n",
       "133003        4239928         3020090       0.088705       0.837004   \n",
       "133004        2512055         2335754       0.532863       0.326385   \n",
       "133010        4418784         4292349      -0.058534       0.294277   \n",
       "133011        3151289         3922491      -0.599303       1.475839   \n",
       "133012        2504643         4333158       0.096802       0.010190   \n",
       "133013        3970873         4688408       0.064634      -0.146394   \n",
       "133014        5060394         4324623       0.002017      -0.173635   \n",
       "133016        3922557         4217395       0.811043      -0.521314   \n",
       "133017        3309918         4277049       0.266692      -0.070910   \n",
       "133019        3894823         2502364       0.130970      -0.318741   \n",
       "133020        4339130         2503659       0.593418       0.810061   \n",
       "133021        3089069         3030256      -0.657081      -0.592595   \n",
       "133022        4024488         5080935      -0.163086       0.291715   \n",
       "133025        4815974         4389093      -0.657956      -0.746681   \n",
       "133034        4375156         4686725      -0.019820       0.556889   \n",
       "133035        4835137         4012999      -0.243549       0.132756   \n",
       "133036        2558075         4903365       0.147911       0.056638   \n",
       "133037        4251462         2517186       0.165704       0.569984   \n",
       "133039        4914568         4702563       0.219062       0.759179   \n",
       "133040        4227055         4034272       0.457317       0.834310   \n",
       "133041        2988175         4406574      -0.043845       0.520167   \n",
       "133042        4426250         4684474       0.019640      -0.775182   \n",
       "133043        4875506         4788300      -0.003243      -0.289146   \n",
       "133046        4419372         3028863       0.882613      -0.245899   \n",
       "133054        2951202         4081024      -0.122876       0.344964   \n",
       "133055        4379258         4289516       0.313306       1.668011   \n",
       "133056        2504169         3085551      -0.175675      -0.268599   \n",
       "133057        4032401         4421978      -0.377505      -1.312164   \n",
       "133058        3953381         4245092       0.023338      -0.670303   \n",
       "133059        3031559         3023388       0.630170      -0.044230   \n",
       "133060        4245094         3971496       0.203367      -0.219879   \n",
       "133065        5074126         4783385      -0.056904      -0.278366   \n",
       "133066        4321051         5076593      -0.479688      -0.066555   \n",
       "133068        3913473         4684776       0.763423       0.183209   \n",
       "133071        4275487         3024395      -0.625163       0.289565   \n",
       "133073        4687003         4881997       0.382454      -0.412174   \n",
       "133078        4306125         4815998       0.430175      -0.010858   \n",
       "133079        3115931         4021217       0.479946       1.099809   \n",
       "133080        3146944         2512976       0.619807       0.528609   \n",
       "133081        4873640         4410084       0.019379      -0.697238   \n",
       "133082        4426312         4738092      -0.071143      -0.105174   \n",
       "133084        3090893         4046059      -0.514279       0.045537   \n",
       "133085        3088232         2500946      -0.363337      -0.168818   \n",
       "133088        2335666         2504639      -0.262384      -0.043037   \n",
       "133089        4668069         3155846      -0.308709      -0.837457   \n",
       "133092        4695736         4873642       0.640564       0.827686   \n",
       "133098        2516131         2951361       0.443042      -0.700990   \n",
       "133100        2560746         3027545      -0.415478      -0.020843   \n",
       "\n",
       "        pred_elo_PC_2  pred_elo_PC_3  pred_elo_PC_4  pred_elo_PC_5  \\\n",
       "132984      -0.068994       0.682357       0.265850       0.332739   \n",
       "132985       0.967333      -1.279557       0.390686      -0.224637   \n",
       "132986       0.029361      -1.416281      -0.196303      -0.420252   \n",
       "132987      -0.089732      -0.591662      -0.648010       0.036722   \n",
       "132988       0.555358       0.363368       0.224523       0.700904   \n",
       "132989       0.437694      -1.458451      -0.138322       0.162732   \n",
       "132991      -0.265063      -0.548014       0.247813       0.141773   \n",
       "132993      -0.050783       0.761484      -0.134104      -1.021289   \n",
       "132996      -0.842446       0.633129      -0.954096      -0.628756   \n",
       "132997      -0.302548       0.084098       0.106047       0.583619   \n",
       "132999       0.211283      -0.816519       0.877023      -0.425521   \n",
       "133003      -0.081885       0.039529      -0.063510      -0.524971   \n",
       "133004       0.068641      -0.647781      -0.200518      -0.350859   \n",
       "133010      -0.205873       0.369073       1.105809       0.260411   \n",
       "133011      -0.967742       0.014702       0.082234       0.185902   \n",
       "133012      -0.012390      -0.223778      -0.185530       0.124228   \n",
       "133013      -0.327473      -0.314480       0.571793      -0.969727   \n",
       "133014      -0.246236       0.611450       0.029376      -0.293469   \n",
       "133016       0.688678      -0.772041      -0.924842       0.167326   \n",
       "133017      -0.008271       0.098454       1.143072      -0.191985   \n",
       "133019       0.264974      -0.204758      -0.554714       0.351630   \n",
       "133020      -1.324708       1.662906      -1.107296       0.308445   \n",
       "133021      -0.228173       0.164238       0.157888      -0.295335   \n",
       "133022       0.040737      -0.177596      -0.124726      -0.038337   \n",
       "133025       0.398674       0.335451      -0.073774       0.162743   \n",
       "133034       0.191263       0.706798      -0.076375       0.164163   \n",
       "133035       0.828913       0.262290       1.633730      -0.290362   \n",
       "133036       0.130269      -1.129835      -0.065689       0.484352   \n",
       "133037      -0.608713      -0.955094       0.774204      -0.695898   \n",
       "133039      -0.001518       0.400720      -0.156865       0.096837   \n",
       "133040      -0.451403       0.590604       0.782637      -0.339107   \n",
       "133041       0.217524      -0.965000       0.505374      -0.239545   \n",
       "133042       0.577893       0.159711      -0.244184      -0.093082   \n",
       "133043       0.241639      -0.335586      -0.151699       0.480890   \n",
       "133046      -0.084419      -1.801159      -0.421756      -0.629837   \n",
       "133054      -0.207511      -0.455348       0.505773       0.014431   \n",
       "133055       0.238057      -0.932895      -0.193452       0.208198   \n",
       "133056       0.608406       0.566623       0.537921       1.281252   \n",
       "133057       0.367624      -0.307423      -0.478049      -1.443996   \n",
       "133058      -0.277535      -0.608048       0.641021      -0.186049   \n",
       "133059       0.160650      -0.172191       0.131000       0.184488   \n",
       "133060      -1.728134       0.602505      -0.470242       1.383190   \n",
       "133065       0.242566      -0.321009      -0.185009      -0.059651   \n",
       "133066       0.989041      -0.253741      -0.123955      -0.148609   \n",
       "133068       0.384434      -0.633261       0.194807      -0.317664   \n",
       "133071       0.255464       0.268661      -0.186597      -0.654163   \n",
       "133073       0.419772      -0.704622       0.018410      -0.067649   \n",
       "133078       0.020797       0.122686      -0.342395       0.482577   \n",
       "133079       1.654416      -0.171943       0.203370       1.725225   \n",
       "133080       0.260285       0.360597      -0.528526      -0.009197   \n",
       "133081       0.692133      -1.162415       0.314892       0.196571   \n",
       "133082       0.226470       0.139899       0.096431      -0.010048   \n",
       "133084       0.456830      -0.824749      -0.339423       0.332397   \n",
       "133085      -1.722193       1.532001       0.190395      -1.475967   \n",
       "133088      -0.112755       1.874633      -0.728907       1.372556   \n",
       "133089       0.404753      -0.200344       0.464319       0.783454   \n",
       "133092       0.150212      -0.497430       0.427796      -0.325431   \n",
       "133098       0.176203      -1.212771      -0.458434      -0.098586   \n",
       "133100       0.940490      -0.412782       0.128540       0.924691   \n",
       "\n",
       "        pred_elo_PC_6  pred_elo_PC_7  ...   age_diff  log_reach_diff  \\\n",
       "132984      -0.606089       0.157302  ...   7.317808        0.081126   \n",
       "132985       0.238147       0.725284  ...   1.295890        0.036368   \n",
       "132986       0.437974      -0.305062  ...  -2.369863        0.006645   \n",
       "132987       0.744049      -0.196450  ...  -0.950685        0.013793   \n",
       "132988       0.680059      -0.225259  ...  -4.624658       -0.030305   \n",
       "132989      -0.757358      -0.317639  ... -12.665753        0.000000   \n",
       "132991       0.096254      -1.325625  ...  -1.021918        0.061036   \n",
       "132993      -1.008232       0.382047  ...   2.882192       -0.068993   \n",
       "132996       0.892606      -0.476728  ...   2.136986        0.014389   \n",
       "132997      -0.376468       0.366369  ...  -6.315068        0.038915   \n",
       "132999       0.448058       0.218753  ...   2.512329       -0.007905   \n",
       "133003       0.013639      -0.584603  ...  -0.391781        0.029853   \n",
       "133004       0.444590      -0.384626  ...   3.835616       -0.026317   \n",
       "133010       0.249523       0.678917  ...   0.000000        0.000000   \n",
       "133011      -0.429443       0.737151  ...   0.000000        0.000000   \n",
       "133012      -0.563981      -0.172217  ...   0.000000        0.000000   \n",
       "133013      -0.644147      -0.022577  ...   0.000000        0.000000   \n",
       "133014      -0.144704       0.112844  ...   0.000000        0.000000   \n",
       "133016       0.041051      -0.088420  ...   0.000000        0.000000   \n",
       "133017       0.049392      -0.488933  ...   0.000000        0.000000   \n",
       "133019       1.418354      -0.401714  ...   0.000000        0.000000   \n",
       "133020      -0.269646       0.517220  ...   0.000000        0.000000   \n",
       "133021      -1.117541       0.123758  ...   0.000000        0.000000   \n",
       "133022       0.315883      -0.280897  ...   0.000000        0.000000   \n",
       "133025       0.178847       0.537192  ...   0.000000        0.000000   \n",
       "133034       0.268000       0.554404  ...   0.000000        0.000000   \n",
       "133035       0.412471      -0.497415  ...   0.000000        0.000000   \n",
       "133036       0.012530       0.163817  ...   0.000000        0.000000   \n",
       "133037       0.266996       0.132750  ...   0.000000        0.000000   \n",
       "133039       0.471451      -0.102770  ...   0.000000        0.000000   \n",
       "133040      -0.273679       0.292134  ...   0.000000        0.000000   \n",
       "133041      -0.556433      -0.638585  ...   0.000000        0.000000   \n",
       "133042       1.441984      -0.586338  ...   0.000000        0.000000   \n",
       "133043       0.339751      -0.014289  ...   0.000000        0.000000   \n",
       "133046      -0.266369       0.771705  ...   0.000000        0.000000   \n",
       "133054      -0.273535       0.666618  ...   0.000000        0.000000   \n",
       "133055       0.587217      -0.659940  ...   0.000000        0.000000   \n",
       "133056       0.577633       0.793715  ...   0.000000        0.000000   \n",
       "133057       0.521851       0.346934  ...   0.000000        0.000000   \n",
       "133058      -0.890652       0.148667  ...   0.000000        0.000000   \n",
       "133059      -0.466574       0.109992  ...   0.000000        0.000000   \n",
       "133060      -0.217612       0.632655  ...   0.000000        0.000000   \n",
       "133065       0.153842       0.123760  ...   0.000000        0.000000   \n",
       "133066       0.038582       0.302530  ...   0.000000        0.000000   \n",
       "133068       0.031905       0.013964  ...   0.000000        0.000000   \n",
       "133071      -0.229661       0.006536  ...   0.000000        0.000000   \n",
       "133073      -0.587148       0.320651  ...   0.000000        0.000000   \n",
       "133078       1.142052       0.185939  ...   0.000000        0.000000   \n",
       "133079      -0.698627       0.767611  ...   0.000000        0.000000   \n",
       "133080       0.713280      -0.306213  ...   0.000000        0.000000   \n",
       "133081       0.023354       0.602986  ...   0.000000        0.000000   \n",
       "133082       0.792512      -0.672556  ...   0.000000        0.000000   \n",
       "133084      -0.178514       0.678643  ...   0.000000        0.000000   \n",
       "133085       0.117545      -0.439120  ...   0.000000        0.000000   \n",
       "133088      -1.303580       0.125084  ...   0.000000        0.000000   \n",
       "133089       0.113100      -0.674187  ...   0.000000        0.000000   \n",
       "133092      -0.407120      -0.088253  ...   0.000000        0.000000   \n",
       "133098       1.531828      -0.365694  ...   0.000000        0.000000   \n",
       "133100      -0.142310      -0.718087  ...   0.000000        0.000000   \n",
       "\n",
       "        weight_diff  height_diff  log_t_since_prev_fight_diff  \\\n",
       "132984          0.0          4.0                    -0.528675   \n",
       "132985          0.0          0.0                     0.084218   \n",
       "132986          0.0          1.0                     0.354646   \n",
       "132987          0.0          3.0                     0.507671   \n",
       "132988          0.0         -3.0                     0.619535   \n",
       "132989          0.0          0.0                     0.110348   \n",
       "132991          0.0          5.0                    -0.375433   \n",
       "132993          0.0         -1.0                    -1.164626   \n",
       "132996          0.0         -3.0                    -0.533062   \n",
       "132997          0.0          4.0                     0.018780   \n",
       "132999          0.0          2.0                     0.142372   \n",
       "133003          0.0          3.0                     0.942802   \n",
       "133004          0.0         -1.0                     0.442064   \n",
       "133010          0.0          0.0                     0.206614   \n",
       "133011          0.0          0.0                    -0.253860   \n",
       "133012          0.0          0.0                     0.153586   \n",
       "133013          0.0          0.0                     0.889154   \n",
       "133014          0.0          0.0                    -0.497977   \n",
       "133016          0.0          0.0                     0.664368   \n",
       "133017          0.0          0.0                     0.244263   \n",
       "133019          0.0          0.0                     0.053653   \n",
       "133020          0.0          0.0                    -1.164308   \n",
       "133021          0.0          0.0                    -0.594022   \n",
       "133022          0.0          0.0                     0.027292   \n",
       "133025          0.0          0.0                    -0.712317   \n",
       "133034          0.0          0.0                    -1.050603   \n",
       "133035          0.0          0.0                     0.349184   \n",
       "133036          0.0          0.0                     0.121890   \n",
       "133037          0.0          0.0                    -0.835501   \n",
       "133039          0.0          0.0                     0.285991   \n",
       "133040          0.0          0.0                     0.173272   \n",
       "133041          0.0          0.0                    -0.113944   \n",
       "133042          0.0          0.0                     0.835501   \n",
       "133043          0.0          0.0                    -0.027292   \n",
       "133046          0.0          0.0                    -0.232059   \n",
       "133054          0.0          0.0                    -0.221724   \n",
       "133055          0.0          0.0                    -0.671047   \n",
       "133056          0.0          0.0                     0.000000   \n",
       "133057          0.0          0.0                     1.667093   \n",
       "133058          0.0          0.0                    -0.046213   \n",
       "133059          0.0          0.0                    -1.713478   \n",
       "133060          0.0          0.0                     0.608110   \n",
       "133065          0.0          0.0                    -0.519636   \n",
       "133066          0.0          0.0                    -0.272779   \n",
       "133068          0.0          0.0                    -0.216808   \n",
       "133071          0.0          0.0                     1.027786   \n",
       "133073          0.0          0.0                    -0.175009   \n",
       "133078          0.0          0.0                     0.758530   \n",
       "133079          0.0          0.0                    -0.328504   \n",
       "133080          0.0          0.0                    -0.935573   \n",
       "133081          0.0          0.0                    -0.316037   \n",
       "133082          0.0          0.0                     0.984344   \n",
       "133084          0.0          0.0                     1.005953   \n",
       "133085          0.0          0.0                    -0.239779   \n",
       "133088          0.0          0.0                     0.226773   \n",
       "133089          0.0          0.0                     0.024015   \n",
       "133092          0.0          0.0                     0.482098   \n",
       "133098          0.0          0.0                     0.000000   \n",
       "133100          0.0          0.0                     0.710743   \n",
       "\n",
       "        log_t_since_first_fight_diff  total_fights_diff  usa_diff  \\\n",
       "132984                     -0.510659                 -7        -1   \n",
       "132985                     -0.146069                 -5         0   \n",
       "132986                     -0.046496                  3         0   \n",
       "132987                      0.142094                 -3         0   \n",
       "132988                      0.358149                  4        -1   \n",
       "132989                      0.809855                 39         1   \n",
       "132991                     -0.061522                 13         1   \n",
       "132993                     -0.320020                -12         1   \n",
       "132996                     -0.133283                -10        -1   \n",
       "132997                      0.409856                  3         0   \n",
       "132999                      0.183711                  9         0   \n",
       "133003                     -0.174199                 -3         1   \n",
       "133004                     -0.259292                -12         0   \n",
       "133010                     -0.514944                -10         0   \n",
       "133011                      0.069939                  5         0   \n",
       "133012                      0.205259                 -3         0   \n",
       "133013                      0.555333                 -1         0   \n",
       "133014                     -0.736978                 -6         0   \n",
       "133016                      0.064518                  3         0   \n",
       "133017                      0.361569                  3         0   \n",
       "133019                     -0.222785                -19         0   \n",
       "133020                     -1.262711                -26         0   \n",
       "133021                     -0.262904                 -1         0   \n",
       "133022                      0.355801                 -7         0   \n",
       "133025                     -0.901612                 -7         0   \n",
       "133034                     -0.027378                 -2         0   \n",
       "133035                     -0.104183                 -9         0   \n",
       "133036                      1.049269                 21         0   \n",
       "133037                     -0.461602                -23         0   \n",
       "133039                     -0.706106                 -3         0   \n",
       "133040                      0.208359                 -1         0   \n",
       "133041                      0.503882                  9         0   \n",
       "133042                      0.438607                 -1         0   \n",
       "133043                      0.908553                  5         0   \n",
       "133046                     -0.546031                 -1         0   \n",
       "133054                      0.486626                 24         0   \n",
       "133055                     -0.198674                 -1         0   \n",
       "133056                      0.117873                 16         0   \n",
       "133057                      0.184483                -14         0   \n",
       "133058                     -0.025136                 -1         0   \n",
       "133059                      0.247692                  7         0   \n",
       "133060                     -0.406027                 -7         0   \n",
       "133065                      0.412738                  2         0   \n",
       "133066                      0.096828                 11         0   \n",
       "133068                     -0.180734                  2         0   \n",
       "133071                      0.216503                -13         0   \n",
       "133073                     -0.234475                  3         0   \n",
       "133078                      0.615629                  4         0   \n",
       "133079                      0.284359                 12         0   \n",
       "133080                     -0.479448                -26         0   \n",
       "133081                     -0.031966                  3         0   \n",
       "133082                      0.624639                  9         0   \n",
       "133084                      0.332274                  7         0   \n",
       "133085                     -0.431805                -17         0   \n",
       "133088                      0.120628                 11         0   \n",
       "133089                     -0.134321                 -7         0   \n",
       "133092                      0.346808                -14         0   \n",
       "133098                      0.079714                 10         0   \n",
       "133100                      0.269782                  1         0   \n",
       "\n",
       "        russia_diff  stance_diff  \n",
       "132984            0            1  \n",
       "132985            0            0  \n",
       "132986            0           -1  \n",
       "132987            0            0  \n",
       "132988            0            0  \n",
       "132989            0            0  \n",
       "132991           -1           -1  \n",
       "132993            0            0  \n",
       "132996            0            1  \n",
       "132997            0            0  \n",
       "132999            0            0  \n",
       "133003            0            1  \n",
       "133004            0            1  \n",
       "133010            0            0  \n",
       "133011            0            0  \n",
       "133012            0            0  \n",
       "133013            0            0  \n",
       "133014            0            0  \n",
       "133016            0            0  \n",
       "133017            0            0  \n",
       "133019            0            0  \n",
       "133020            0            0  \n",
       "133021            0            0  \n",
       "133022            0            0  \n",
       "133025            0            0  \n",
       "133034            0            0  \n",
       "133035            0            0  \n",
       "133036            0            0  \n",
       "133037            0            0  \n",
       "133039            0            0  \n",
       "133040            0            0  \n",
       "133041            0            0  \n",
       "133042            0            0  \n",
       "133043            0            0  \n",
       "133046            0            0  \n",
       "133054            0            0  \n",
       "133055            0            0  \n",
       "133056            0            0  \n",
       "133057            0            0  \n",
       "133058            0            0  \n",
       "133059            0            0  \n",
       "133060            0            0  \n",
       "133065            0            0  \n",
       "133066            0            0  \n",
       "133068            0            0  \n",
       "133071            0            0  \n",
       "133073            0            0  \n",
       "133078            0            0  \n",
       "133079            0            0  \n",
       "133080            0            0  \n",
       "133081            0            0  \n",
       "133082            0            0  \n",
       "133084            0            0  \n",
       "133085            0            0  \n",
       "133088            0            0  \n",
       "133089            0            0  \n",
       "133092            0            0  \n",
       "133098            0            0  \n",
       "133100            0            0  \n",
       "\n",
       "[59 rows x 29 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feat_ml_df.query(\"Date == '2023-04-15'\")[[\"FighterName\", \"OpponentName\"]]\n",
    "feat_ml_df.query(\"is_upcoming == 1\")[[\"FighterID_espn\", \"OpponentID_espn\", *feat_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12915, 387), (13, 387))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from wrangle.clean_bfo_data import parse_american_odds\n",
    "\n",
    "train_df = feat_ml_df.query(\"is_upcoming == 0\")\\\n",
    "    .dropna(subset=[\n",
    "        *feat_cols, \"win_target\", p_fighter_implied_col\n",
    "    ], how=\"any\")\n",
    "test_df = feat_ml_df.query(\"Date == '2023-04-15'\").copy()\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -34433.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.75682574, 0.41568308, 0.55236191, 0.53309491, 0.20654615,\n",
       "       0.27623798, 0.53562018, 0.60768639, 0.50246826, 0.56842175,\n",
       "       0.39721932, 0.41095475, 0.79942643])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      19      -7634.21     0.0025949       4.42508      0.6432      0.6432       22   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      23      -7634.21    0.00038426      0.192341           1           1       26   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "mod = SimpleSymmetricModel(\n",
    "    feat_cols=feat_cols, target_col=\"win_target\", \n",
    "    p_fighter_implied_col=p_fighter_implied_col,\n",
    "    beta_prior_std=1.0, mcmc=False\n",
    ")\n",
    "\n",
    "y_pred = mod.fit_predict(train_df, test_df, feat_cols)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterName</th>\n",
       "      <th>OpponentName</th>\n",
       "      <th>FighterOpen</th>\n",
       "      <th>OpponentOpen</th>\n",
       "      <th>p_fighter_open_implied</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132984</th>\n",
       "      <td>daniel zellhuber</td>\n",
       "      <td>lando vannata</td>\n",
       "      <td>-175</td>\n",
       "      <td>+150</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.756826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132985</th>\n",
       "      <td>joselyne edwards</td>\n",
       "      <td>lucie pudilova</td>\n",
       "      <td>+150</td>\n",
       "      <td>-175</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.415683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132986</th>\n",
       "      <td>tanner boser</td>\n",
       "      <td>ion curelaba</td>\n",
       "      <td>-160</td>\n",
       "      <td>+140</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.552362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132987</th>\n",
       "      <td>bill algeo</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>-139</td>\n",
       "      <td>+119</td>\n",
       "      <td>0.560185</td>\n",
       "      <td>0.533095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132988</th>\n",
       "      <td>pedro munhoz</td>\n",
       "      <td>chris gutierrez</td>\n",
       "      <td>+200</td>\n",
       "      <td>-235</td>\n",
       "      <td>0.322115</td>\n",
       "      <td>0.206546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132989</th>\n",
       "      <td>clay guida</td>\n",
       "      <td>rafa garcia</td>\n",
       "      <td>+140</td>\n",
       "      <td>-160</td>\n",
       "      <td>0.403727</td>\n",
       "      <td>0.276238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132991</th>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>azamat murzakanov</td>\n",
       "      <td>-200</td>\n",
       "      <td>+170</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.535620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132993</th>\n",
       "      <td>billy quarantillo</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>-155</td>\n",
       "      <td>+135</td>\n",
       "      <td>0.588212</td>\n",
       "      <td>0.607686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132996</th>\n",
       "      <td>arnold allen</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>+125</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.428884</td>\n",
       "      <td>0.502468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132997</th>\n",
       "      <td>bruna brasil</td>\n",
       "      <td>denise gomes</td>\n",
       "      <td>-160</td>\n",
       "      <td>+140</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.568422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132999</th>\n",
       "      <td>gillian robertson</td>\n",
       "      <td>piera rodriguez</td>\n",
       "      <td>+115</td>\n",
       "      <td>-135</td>\n",
       "      <td>0.447406</td>\n",
       "      <td>0.397219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133003</th>\n",
       "      <td>brandon royval</td>\n",
       "      <td>matheus nicolau</td>\n",
       "      <td>+125</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.428884</td>\n",
       "      <td>0.410955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133004</th>\n",
       "      <td>zak cummings</td>\n",
       "      <td>ed herman</td>\n",
       "      <td>-250</td>\n",
       "      <td>+210</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.799426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FighterName       OpponentName FighterOpen OpponentOpen  \\\n",
       "132984   daniel zellhuber      lando vannata        -175         +150   \n",
       "132985   joselyne edwards     lucie pudilova        +150         -175   \n",
       "132986       tanner boser       ion curelaba        -160         +140   \n",
       "132987         bill algeo           tj brown        -139         +119   \n",
       "132988       pedro munhoz    chris gutierrez        +200         -235   \n",
       "132989         clay guida        rafa garcia        +140         -160   \n",
       "132991      dustin jacoby  azamat murzakanov        -200         +170   \n",
       "132993  billy quarantillo      edson barboza        -155         +135   \n",
       "132996       arnold allen       max holloway        +125         -145   \n",
       "132997       bruna brasil       denise gomes        -160         +140   \n",
       "132999  gillian robertson    piera rodriguez        +115         -135   \n",
       "133003     brandon royval    matheus nicolau        +125         -145   \n",
       "133004       zak cummings          ed herman        -250         +210   \n",
       "\n",
       "        p_fighter_open_implied    y_pred  \n",
       "132984                0.614035  0.756826  \n",
       "132985                0.385965  0.415683  \n",
       "132986                0.596273  0.552362  \n",
       "132987                0.560185  0.533095  \n",
       "132988                0.322115  0.206546  \n",
       "132989                0.403727  0.276238  \n",
       "132991                0.642857  0.535620  \n",
       "132993                0.588212  0.607686  \n",
       "132996                0.428884  0.502468  \n",
       "132997                0.596273  0.568422  \n",
       "132999                0.447406  0.397219  \n",
       "133003                0.428884  0.410955  \n",
       "133004                0.688889  0.799426  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = test_df.assign(y_pred = y_pred)\n",
    "preds_df[[\"FighterName\", \"OpponentName\", \n",
    "          \"FighterOpen\", \"OpponentOpen\", \n",
    "          p_fighter_implied_col, \"y_pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterName</th>\n",
       "      <th>OpponentName</th>\n",
       "      <th>DraftKings_fighter</th>\n",
       "      <th>DraftKings_opponent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daniel zellhuber</td>\n",
       "      <td>lando vannata</td>\n",
       "      <td>-130</td>\n",
       "      <td>+110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joselyne edwards</td>\n",
       "      <td>lucie pudilova</td>\n",
       "      <td>+115</td>\n",
       "      <td>-135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tanner boser</td>\n",
       "      <td>ion curelaba</td>\n",
       "      <td>+110</td>\n",
       "      <td>-130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bill algeo</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>-190</td>\n",
       "      <td>+160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pedro munhoz</td>\n",
       "      <td>chris gutierrez</td>\n",
       "      <td>+170</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clay guida</td>\n",
       "      <td>rafa garcia</td>\n",
       "      <td>+215</td>\n",
       "      <td>-255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>azamat murzakanov</td>\n",
       "      <td>-150</td>\n",
       "      <td>+130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>billy quarantillo</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>-170</td>\n",
       "      <td>+145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arnold allen</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>+140</td>\n",
       "      <td>-165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bruna brasil</td>\n",
       "      <td>denise gomes</td>\n",
       "      <td>-150</td>\n",
       "      <td>+130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gillian robertson</td>\n",
       "      <td>piera rodriguez</td>\n",
       "      <td>-125</td>\n",
       "      <td>+105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>brandon royval</td>\n",
       "      <td>matheus nicolau</td>\n",
       "      <td>+170</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zak cummings</td>\n",
       "      <td>ed herman</td>\n",
       "      <td>-225</td>\n",
       "      <td>+190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FighterName       OpponentName DraftKings_fighter  \\\n",
       "0    daniel zellhuber      lando vannata               -130   \n",
       "1    joselyne edwards     lucie pudilova               +115   \n",
       "2        tanner boser       ion curelaba               +110   \n",
       "3          bill algeo           tj brown               -190   \n",
       "4        pedro munhoz    chris gutierrez               +170   \n",
       "5          clay guida        rafa garcia               +215   \n",
       "6       dustin jacoby  azamat murzakanov               -150   \n",
       "7   billy quarantillo      edson barboza               -170   \n",
       "8        arnold allen       max holloway               +140   \n",
       "9        bruna brasil       denise gomes               -150   \n",
       "10  gillian robertson    piera rodriguez               -125   \n",
       "11     brandon royval    matheus nicolau               +170   \n",
       "12       zak cummings          ed herman               -225   \n",
       "\n",
       "   DraftKings_opponent  \n",
       "0                 +110  \n",
       "1                 -135  \n",
       "2                 -130  \n",
       "3                 +160  \n",
       "4                 -200  \n",
       "5                 -255  \n",
       "6                 +130  \n",
       "7                 +145  \n",
       "8                 -165  \n",
       "9                 +130  \n",
       "10                +105  \n",
       "11                -200  \n",
       "12                +190  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df = pd.DataFrame([['daniel zellhuber', 'lando vannata', \"-130\", \"+110\"],\n",
    "['joselyne edwards', 'lucie pudilova', \"+115\", \"-135\"],\n",
    "['tanner boser', 'ion curelaba', \"+110\", \"-130\"],\n",
    "['bill algeo', 'tj brown', \"-190\", \"+160\"],\n",
    "['pedro munhoz', 'chris gutierrez', \"+170\", \"-200\"],\n",
    "['clay guida', 'rafa garcia', \"+215\", \"-255\"],\n",
    "['dustin jacoby', 'azamat murzakanov', \"-150\", \"+130\"],\n",
    "['billy quarantillo', 'edson barboza', \"-170\", \"+145\"],\n",
    "['arnold allen', 'max holloway', \"+140\", \"-165\"],\n",
    "['bruna brasil', 'denise gomes', \"-150\", \"+130\"],\n",
    "['gillian robertson', 'piera rodriguez', \"-125\", \"+105\"],\n",
    "['brandon royval', 'matheus nicolau', \"+170\", \"-200\"],\n",
    "['zak cummings', 'ed herman', \"-225\", \"+190\"]], \n",
    "columns=[\"FighterName\", \"OpponentName\", \"DraftKings_fighter\", \"DraftKings_opponent\"])\n",
    "ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight_id_legacy</th>\n",
       "      <th>Date</th>\n",
       "      <th>FighterResult</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Rnd</th>\n",
       "      <th>Time</th>\n",
       "      <th>Event</th>\n",
       "      <th>OpponentID_espn</th>\n",
       "      <th>FighterID_espn</th>\n",
       "      <th>TSL</th>\n",
       "      <th>...</th>\n",
       "      <th>height_diff</th>\n",
       "      <th>t_since_first_fight_diff</th>\n",
       "      <th>log_t_since_first_fight_diff</th>\n",
       "      <th>log_t_since_prev_fight_diff</th>\n",
       "      <th>usa_diff</th>\n",
       "      <th>russia_diff</th>\n",
       "      <th>stance_diff</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>DraftKings_fighter</th>\n",
       "      <th>DraftKings_opponent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-15_3949555_4863327</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3949555</td>\n",
       "      <td>4863327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1596</td>\n",
       "      <td>-0.510659</td>\n",
       "      <td>-0.528675</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.756826</td>\n",
       "      <td>-130</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-15_4040197_4397782</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4040197</td>\n",
       "      <td>4397782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-455</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>0.084218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415683</td>\n",
       "      <td>115</td>\n",
       "      <td>-135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-15_3994033_4232775</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3994033</td>\n",
       "      <td>4232775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-183</td>\n",
       "      <td>-0.046496</td>\n",
       "      <td>0.354646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.552362</td>\n",
       "      <td>110</td>\n",
       "      <td>-130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-15_4063667_4076472</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4063667</td>\n",
       "      <td>4076472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>526</td>\n",
       "      <td>0.142094</td>\n",
       "      <td>0.507671</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533095</td>\n",
       "      <td>-190</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-15_3045734_3961293</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3961293</td>\n",
       "      <td>3045734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1547</td>\n",
       "      <td>0.358149</td>\n",
       "      <td>0.619535</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.206546</td>\n",
       "      <td>170</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-04-15_2335674_4690549</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4690549</td>\n",
       "      <td>2335674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3870</td>\n",
       "      <td>0.809855</td>\n",
       "      <td>0.110348</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.276238</td>\n",
       "      <td>215</td>\n",
       "      <td>-255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-04-15_2594871_4227265</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4227265</td>\n",
       "      <td>2594871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-287</td>\n",
       "      <td>-0.061522</td>\n",
       "      <td>-0.375433</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.535620</td>\n",
       "      <td>-150</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-04-15_2526299_3900088</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>2526299</td>\n",
       "      <td>3900088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1400</td>\n",
       "      <td>-0.320020</td>\n",
       "      <td>-1.164626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607686</td>\n",
       "      <td>-170</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-04-15_2614933_3902098</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>2614933</td>\n",
       "      <td>3902098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-574</td>\n",
       "      <td>-0.133283</td>\n",
       "      <td>-0.533062</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502468</td>\n",
       "      <td>140</td>\n",
       "      <td>-165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-04-15_4394200_4963343</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4963343</td>\n",
       "      <td>4394200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1036</td>\n",
       "      <td>0.409856</td>\n",
       "      <td>0.018780</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.568422</td>\n",
       "      <td>-150</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-04-15_4089026_4816066</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>4816066</td>\n",
       "      <td>4089026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>435</td>\n",
       "      <td>0.183711</td>\n",
       "      <td>0.142372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.397219</td>\n",
       "      <td>-125</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-04-15_3020090_4239928</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>3020090</td>\n",
       "      <td>4239928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-741</td>\n",
       "      <td>-0.174199</td>\n",
       "      <td>0.942802</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.410955</td>\n",
       "      <td>170</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-04-15_2335754_2512055</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>UFC Fight Night: Holloway vs. Allen</td>\n",
       "      <td>2335754</td>\n",
       "      <td>2512055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1663</td>\n",
       "      <td>-0.259292</td>\n",
       "      <td>0.442064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799426</td>\n",
       "      <td>-225</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows Ã— 390 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               fight_id_legacy       Date FighterResult Decision Rnd Time  \\\n",
       "0   2023-04-15_3949555_4863327 2023-04-15          None     None   -    -   \n",
       "1   2023-04-15_4040197_4397782 2023-04-15          None     None   -    -   \n",
       "2   2023-04-15_3994033_4232775 2023-04-15          None     None   -    -   \n",
       "3   2023-04-15_4063667_4076472 2023-04-15          None     None   -    -   \n",
       "4   2023-04-15_3045734_3961293 2023-04-15          None     None   -    -   \n",
       "5   2023-04-15_2335674_4690549 2023-04-15          None     None   -    -   \n",
       "6   2023-04-15_2594871_4227265 2023-04-15          None     None   -    -   \n",
       "7   2023-04-15_2526299_3900088 2023-04-15          None     None   -    -   \n",
       "8   2023-04-15_2614933_3902098 2023-04-15          None     None   -    -   \n",
       "9   2023-04-15_4394200_4963343 2023-04-15          None     None   -    -   \n",
       "10  2023-04-15_4089026_4816066 2023-04-15          None     None   -    -   \n",
       "11  2023-04-15_3020090_4239928 2023-04-15          None     None   -    -   \n",
       "12  2023-04-15_2335754_2512055 2023-04-15          None     None   -    -   \n",
       "\n",
       "                                  Event OpponentID_espn FighterID_espn  TSL  \\\n",
       "0   UFC Fight Night: Holloway vs. Allen         3949555        4863327  NaN   \n",
       "1   UFC Fight Night: Holloway vs. Allen         4040197        4397782  NaN   \n",
       "2   UFC Fight Night: Holloway vs. Allen         3994033        4232775  NaN   \n",
       "3   UFC Fight Night: Holloway vs. Allen         4063667        4076472  NaN   \n",
       "4   UFC Fight Night: Holloway vs. Allen         3961293        3045734  NaN   \n",
       "5   UFC Fight Night: Holloway vs. Allen         4690549        2335674  NaN   \n",
       "6   UFC Fight Night: Holloway vs. Allen         4227265        2594871  NaN   \n",
       "7   UFC Fight Night: Holloway vs. Allen         2526299        3900088  NaN   \n",
       "8   UFC Fight Night: Holloway vs. Allen         2614933        3902098  NaN   \n",
       "9   UFC Fight Night: Holloway vs. Allen         4963343        4394200  NaN   \n",
       "10  UFC Fight Night: Holloway vs. Allen         4816066        4089026  NaN   \n",
       "11  UFC Fight Night: Holloway vs. Allen         3020090        4239928  NaN   \n",
       "12  UFC Fight Night: Holloway vs. Allen         2335754        2512055  NaN   \n",
       "\n",
       "    ...  height_diff  t_since_first_fight_diff  log_t_since_first_fight_diff  \\\n",
       "0   ...          4.0                     -1596                     -0.510659   \n",
       "1   ...          0.0                      -455                     -0.146069   \n",
       "2   ...          1.0                      -183                     -0.046496   \n",
       "3   ...          3.0                       526                      0.142094   \n",
       "4   ...         -3.0                      1547                      0.358149   \n",
       "5   ...          0.0                      3870                      0.809855   \n",
       "6   ...          5.0                      -287                     -0.061522   \n",
       "7   ...         -1.0                     -1400                     -0.320020   \n",
       "8   ...         -3.0                      -574                     -0.133283   \n",
       "9   ...          4.0                      1036                      0.409856   \n",
       "10  ...          2.0                       435                      0.183711   \n",
       "11  ...          3.0                      -741                     -0.174199   \n",
       "12  ...         -1.0                     -1663                     -0.259292   \n",
       "\n",
       "    log_t_since_prev_fight_diff  usa_diff  russia_diff  stance_diff    y_pred  \\\n",
       "0                     -0.528675        -1            0            1  0.756826   \n",
       "1                      0.084218         0            0            0  0.415683   \n",
       "2                      0.354646         0            0           -1  0.552362   \n",
       "3                      0.507671         0            0            0  0.533095   \n",
       "4                      0.619535        -1            0            0  0.206546   \n",
       "5                      0.110348         1            0            0  0.276238   \n",
       "6                     -0.375433         1           -1           -1  0.535620   \n",
       "7                     -1.164626         1            0            0  0.607686   \n",
       "8                     -0.533062        -1            0            1  0.502468   \n",
       "9                      0.018780         0            0            0  0.568422   \n",
       "10                     0.142372         0            0            0  0.397219   \n",
       "11                     0.942802         1            0            1  0.410955   \n",
       "12                     0.442064         0            0            1  0.799426   \n",
       "\n",
       "    DraftKings_fighter  DraftKings_opponent  \n",
       "0                 -130                  110  \n",
       "1                  115                 -135  \n",
       "2                  110                 -130  \n",
       "3                 -190                  160  \n",
       "4                  170                 -200  \n",
       "5                  215                 -255  \n",
       "6                 -150                  130  \n",
       "7                 -170                  145  \n",
       "8                  140                 -165  \n",
       "9                 -150                  130  \n",
       "10                -125                  105  \n",
       "11                 170                 -200  \n",
       "12                -225                  190  \n",
       "\n",
       "[13 rows x 390 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_preds_df = preds_df.merge(\n",
    "    ml_df,\n",
    "    on=[\"FighterName\", \"OpponentName\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "aug_preds_df[\"DraftKings_fighter\"] = aug_preds_df[\"DraftKings_fighter\"].astype(int)\n",
    "aug_preds_df[\"DraftKings_opponent\"] = aug_preds_df[\"DraftKings_opponent\"].astype(int)\n",
    "aug_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FighterName</th>\n",
       "      <th>fighter_bet</th>\n",
       "      <th>OpponentName</th>\n",
       "      <th>opponent_bet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daniel zellhuber</td>\n",
       "      <td>0.040064</td>\n",
       "      <td>lando vannata</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joselyne edwards</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>lucie pudilova</td>\n",
       "      <td>0.002104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tanner boser</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>ion curelaba</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bill algeo</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tj brown</td>\n",
       "      <td>0.012156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pedro munhoz</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>chris gutierrez</td>\n",
       "      <td>0.034578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clay guida</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>rafa garcia</td>\n",
       "      <td>0.001760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dustin jacoby</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>azamat murzakanov</td>\n",
       "      <td>0.004760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>billy quarantillo</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>edson barboza</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arnold allen</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>max holloway</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bruna brasil</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>denise gomes</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gillian robertson</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>piera rodriguez</td>\n",
       "      <td>0.020407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>brandon royval</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>matheus nicolau</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zak cummings</td>\n",
       "      <td>0.031649</td>\n",
       "      <td>ed herman</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FighterName  fighter_bet       OpponentName  opponent_bet\n",
       "0    daniel zellhuber     0.040064      lando vannata      0.000000\n",
       "1    joselyne edwards     0.000000     lucie pudilova      0.002104\n",
       "2        tanner boser     0.013220       ion curelaba      0.000000\n",
       "3          bill algeo     0.000000           tj brown      0.012156\n",
       "4        pedro munhoz     0.000000    chris gutierrez      0.034578\n",
       "5          clay guida     0.000000        rafa garcia      0.001760\n",
       "6       dustin jacoby     0.000000  azamat murzakanov      0.004760\n",
       "7   billy quarantillo     0.000000      edson barboza      0.000000\n",
       "8        arnold allen     0.013372       max holloway      0.000000\n",
       "9        bruna brasil     0.000000       denise gomes      0.000000\n",
       "10  gillian robertson     0.000000    piera rodriguez      0.020407\n",
       "11     brandon royval     0.005860    matheus nicolau      0.000000\n",
       "12       zak cummings     0.031649          ed herman      0.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_selection.backtesting import MultiKellyPM\n",
    "\n",
    "pm = MultiKellyPM(aug_preds_df, max_bankroll_fraction=0.05,\n",
    "                  fighter_ml_col=\"DraftKings_fighter\",\n",
    "                    opponent_ml_col=\"DraftKings_opponent\",\n",
    "                  parse_ml=True)\n",
    "pw = pm.get_portfolio_weights().merge(preds_df[[\"FighterID_espn\", \"OpponentID_espn\", \"FighterName\", \"OpponentName\"]])\n",
    "pw[[\"FighterName\", \"fighter_bet\", \"OpponentName\", \"opponent_bet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sports_pystan2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a237f2fbfa4eeeaf420965c4b3f40ac3440be1ed8d868d43cc135fc4be38fee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
