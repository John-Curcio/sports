{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b45d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Make plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f16c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from math import floor\n",
    "\n",
    "# this is for running the notebook in our testing framework\n",
    "smoke_test = ('CI' in os.environ)\n",
    "\n",
    "N = 100\n",
    "X = torch.linspace(-1., 1., N)\n",
    "probs = (torch.sin(X * math.pi).add(1.).div(2.))\n",
    "y = torch.distributions.Bernoulli(probs=probs).sample()\n",
    "X = X.unsqueeze(-1)\n",
    "\n",
    "train_n = int(floor(0.8 * N))\n",
    "indices = torch.randperm(N)\n",
    "train_x = X[indices[:train_n]].contiguous()\n",
    "train_y = y[indices[:train_n]].contiguous()\n",
    "\n",
    "test_x = X[indices[train_n:]].contiguous()\n",
    "test_y = y[indices[train_n:]].contiguous()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    train_x, train_y, test_x, test_y = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7eb9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7cb9474ac0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAATs0lEQVR4nO3de6wcZ3nH8e/TE0dyCo0JPkDi2DiVgiEtpMA24dJCgIIdtzRcWikGAUmRrEgYwR+NcFSVIkUVUERFqoQaN7WAqor/SRrSyDSlhRSJCJTj3ENwMOES22niAAmFWM2Fp3/sOEz27GX27KzPOW+/H+no7M68877PvDP+ebw7643MRJK0/P3aYhcgSWqHgS5JhTDQJakQBrokFcJAl6RCHLdYA69evTrXr1+/WMNL0rK0d+/ehzNztt+6RQv09evXMzc3t1jDS9KyFBE/HLTOl1wkqRAGuiQVwkCXpEIY6JJUCANdkgox8i6XiNgF/BHwUGb+dp/1AVwGbAYeAy7IzFvaLrSfa289yKdu2MehR45wyqqVXLxxA297+ZqJ+ll1wgoy4dEjT0zUp+arz/OJK1cQAY88Nn+e2zquk9YxaJtB58igfuuPe7d9w4tn+dp3Ds/rt/540PaDljc9hwft0yTjNT2uk4zXZM4XMreD+h33GC9mbsSo/20xIl4H/Bz44oBA3wx8kG6gnw1clplnjxq40+nkJLctXnvrQS655k6OPPHU08tWrpjh4+946VgT2a+fuoX0qfmazjPQynGdtI76WE22eecr13D13oMD2yymhexT22PD/OM6ab/TmPNB/Y473jRzIyL2Zman77om/31uRKwHrh8Q6J8DbszMq6rn+4BzMvOBYX1OGuiv/cRXOfjIkXnL16xayTe2v3HifibpU/M1nWegleM6aR31sZpsMxPBU0v4v6JeyD61OTb0P66TmNacD+p33PGmlRvDAr2NDxatAe6vPT9QLZsX6BGxFdgKsG7duokGPTTg5Bi0fNx+JulT8006z20dg4XU0WSbpRzmsLB9mtbYbZnWnA/qd9zxFiM32nhTNPos67vnmbkzMzuZ2Zmd7fvJ1cZOqf7Wb7p83H4m6VPzNZ3nto7rpHWMu81M9PtjsHQsZJ/aHHsa401rzgf1O+54i5EbbQT6AWBt7fmpwKEW+h3q4o0bWLli5hnLVq6Y4eKNGybuZ9I+NV/TeW7ruE5ax7jbbDl77dA2i2kh+9T22G2PN605H9TvuOMtVm608ZLLdcC2iNhN903RR0e9ft6Go282THo3RG8/3uUyHb3zPOqugGnd5TJuHf22GXSOdF540rK5y2XYPk3rLpe2xmsy55Pe5VLvd9xjvNTvcrkKOAdYDTwI/BWwAiAzd1S3LV4ObKJ72+KFmTny3c5J3xSVpP+PJnpTNDO3jFifwAcWWJskqSV+UlSSCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEI0CvSI2BQR+yJif0Rs77P+xIj414i4PSLujogL2y9VkjTMyECPiBngCuBc4AxgS0Sc0dPsA8C3M/NM4Bzg0xFxfMu1SpKGaHKFfhawPzPvy8zHgd3AeT1tEnh2RATwLOAnwJOtVipJGqpJoK8B7q89P1Atq7sceAlwCLgT+FBm/rK3o4jYGhFzETF3+PDhBZYsSeqnSaBHn2XZ83wjcBtwCvA7wOUR8RvzNsrcmZmdzOzMzs6OWaokaZgmgX4AWFt7firdK/G6C4Frsms/8H3gxe2UKElqokmg3wycHhGnVW90ng9c19PmR8CbACLi+cAG4L42C5UkDXfcqAaZ+WREbANuAGaAXZl5d0RcVK3fAVwKfD4i7qT7Es1HMvPhKdYtSeoxMtABMnMPsKdn2Y7a40PAW9otTZI0Dj8pKkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgrRKNAjYlNE7IuI/RGxfUCbcyLitoi4OyL+q90yJUmjHDeqQUTMAFcAbwYOADdHxHWZ+e1am1XAZ4FNmfmjiHjelOqVJA3Q5Ar9LGB/Zt6XmY8Du4Hzetq8C7gmM38EkJkPtVumJGmUJoG+Bri/9vxAtazuRcBzIuLGiNgbEe/t11FEbI2IuYiYO3z48MIqliT11STQo8+y7Hl+HPBK4A+BjcBfRsSL5m2UuTMzO5nZmZ2dHbtYSdJgI19Dp3tFvrb2/FTgUJ82D2fmL4BfRMTXgTOBe1upUpI0UpMr9JuB0yPitIg4HjgfuK6nzZeA34+I4yLiBOBs4J52S5UkDTPyCj0zn4yIbcANwAywKzPvjoiLqvU7MvOeiPg34A7gl8CVmXnXNAuXJD1TZPa+HH5sdDqdnJubW5SxJWm5ioi9mdnpt85PikpSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVIhGgR4RmyJiX0Tsj4jtQ9r9bkQ8FRF/0l6JkqQmRgZ6RMwAVwDnAmcAWyLijAHtPgnc0HaRkqTRmlyhnwXsz8z7MvNxYDdwXp92HwSuBh5qsT5JUkNNAn0NcH/t+YFq2dMiYg3wdmDHsI4iYmtEzEXE3OHDh8etVZI0RJNAjz7Lsuf5Z4CPZOZTwzrKzJ2Z2cnMzuzsbMMSJUlNHNegzQFgbe35qcChnjYdYHdEAKwGNkfEk5l5bRtFSpJGaxLoNwOnR8RpwEHgfOBd9QaZedrRxxHxeeB6w1ySjq2RgZ6ZT0bENrp3r8wAuzLz7oi4qFo/9HVzSdKx0eQKnczcA+zpWdY3yDPzgsnLkiSNy0+KSlIhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEI0CvSI2BQR+yJif0Rs77P+3RFxR/VzU0Sc2X6pkqRhRgZ6RMwAVwDnAmcAWyLijJ5m3wden5kvAy4FdrZdqCRpuCZX6GcB+zPzvsx8HNgNnFdvkJk3ZeZPq6ffBE5tt0xJ0ihNAn0NcH/t+YFq2SDvB77cb0VEbI2IuYiYO3z4cPMqJUkjNQn06LMs+zaMeAPdQP9Iv/WZuTMzO5nZmZ2dbV6lJGmk4xq0OQCsrT0/FTjU2ygiXgZcCZybmT9upzxJUlNNrtBvBk6PiNMi4njgfOC6eoOIWAdcA7wnM+9tv0xJ0igjr9Az88mI2AbcAMwAuzLz7oi4qFq/A/go8FzgsxEB8GRmdqZXtiSpV2T2fTl86jqdTs7NzS3K2JK0XEXE3kEXzH5SVJIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhzXpFFEbAIuA2aAKzPzEz3ro1q/GXgMuCAzb2m5Vq699SCfumEfhx45wimrVnLxxg287eVr5q1bdcIKMuHRI088o92w7ccd+w0vnuVr3zk8r696uxNXriACHnlscB1Na62PV9+mPkaTvga1H7Rt777Xt28ydpvHtckcDqpv0LEYp5blqLT9WS6anLfTOB6RmcMbRMwA9wJvBg4ANwNbMvPbtTabgQ/SDfSzgcsy8+xh/XY6nZybm2tc6LW3HuSSa+7kyBNPPb1s5YoZPv6OlwLMW1e3csUM73zlGq7ee7Dv9qMmtN/YTceYRpumJumr6dyO2n4hczts7Lbmp199w2pZjiFY2v4sF4PmfZIMqouIvZnZ6buuQaC/GvhYZm6snl8CkJkfr7X5HHBjZl5VPd8HnJOZDwzqd9xAf+0nvsrBR47MW75m1UqAvuvqZiJ4qs++rlm1km9sf+OCxm46xjTaNDVJX03ndtj2C53bYWO3NT+99Q2rZdR+LEWl7c9yMWjeJ8mgumGB3uQllzXA/bXnB+hehY9qswZ4RqBHxFZgK8C6desaDP0rhwaEyqDlvQYFQJPtJx1jGm2amqSvpvs9yfYLOa5tzU/vGJOeY0tNafuzXAya30kyqKkmb4pGn2W9lTVpQ2buzMxOZnZmZ2eb1Pe0U6ortn7LB62rm4l+JQ7ud9w2w8aYRpumJumr6dwO236hbYaN3db89PY/rJblqLT9WS7GPW/bPB5NAv0AsLb2/FTg0ALaTOTijRtYuWLmGctWrpjh4o0b+q7rbbfl7LUDt1/I2E3HmEabpibpq+ncjtp+lHGPa1vz06++YbUsR6Xtz3Ixznnb9vFo8pLLzcDpEXEacBA4H3hXT5vrgG0RsZvuyzGPDnv9fCGOvmkw7B3iUXeOdF540oLeYe439qC7XOpjDLqzot6maa2T3OUyqKamd7nU973tu1zGOa5N5nCSu1ya1LKclLY/y8WweV9oBjU18k1RePouls/QvW1xV2b+dURcBJCZO6rbFi8HNtG9bfHCzBz6jue4b4pKkiZ/U5TM3APs6Vm2o/Y4gQ9MUqQkaTJ+UlSSCmGgS1IhDHRJKoSBLkmFaHSXy1QGjjgM/HCMTVYDD0+pnEkt1dqWal2wdGuzrvEt1dqWal0wWW0vzMy+n8xctEAfV0TMDbpVZ7Et1dqWal2wdGuzrvEt1dqWal0wvdp8yUWSCmGgS1IhllOg71zsAoZYqrUt1bpg6dZmXeNbqrUt1bpgSrUtm9fQJUnDLacrdEnSEAa6JBViSQV6RPxpRNwdEb+MiIG39ETEpojYFxH7I2J7bflJEfGViPhu9fs5LdU1st+I2BARt9V+fhYRH67WfSwiDtbWbW6jrqa1Ve1+EBF3VuPPjbv9NOqKiLUR8bWIuKc67h+qrWt1zgadM7X1ERF/V62/IyJe0XTbSTWo7d1VTXdExE0RcWZtXd/jeozqOiciHq0do4823fYY1HZxra67IuKpiDipWjfNOdsVEQ9FxF0D1k/3PMvMJfMDvATYANwIdAa0mQG+B/wmcDxwO3BGte5vgO3V4+3AJ1uqa6x+qxr/m+4HAAA+Bvz5lOasUW3AD4DVk+5bm3UBJwOvqB4/m+6XkR89lq3N2bBzptZmM/Blut++9SrgW023PQa1vQZ4TvX43KO1DTuux6iuc4DrF7LttGvraf9W4KvTnrOq79cBrwDuGrB+qufZkrpCz8x7MnPfiGZnAfsz877MfBzYDZxXrTsP+EL1+AvA21oqbdx+3wR8LzPH+STsQk26z4s2Z5n5QGbeUj3+H+Aeut9F27Zh50y93i9m1zeBVRFxcsNtp1pbZt6UmT+tnn6T7jeCTdsk+73oc9ZjC3BVi+MPlJlfB34ypMlUz7MlFegNDfpCaoDnZ/VNSdXv57U05rj9ns/8E2hb9U+sXW29rDFmbQn8e0Tsje6XdY+7/bTqAiAi1gMvB75VW9zWnA07Z0a1abLtJMbt//10r/COGnRcj1Vdr46I2yPiyxHxW2NuO+3aiIgT6H7xztW1xdOasyamep41+oKLNkXEfwAv6LPqLzLzS0266LNs4nsvh9U1Zj/HA38MXFJb/PfApXTrvBT4NPBnx7i212bmoYh4HvCViPhOdTWxYC3O2bPo/oH7cGb+rFo80Zz1DtFnWdMvOp/K+dZg3PkNI95AN9B/r7a49eM6Rl230H1Z8efVexzXAqc33HbatR31VuAbmVm/ap7WnDUx1fPsmAd6Zv7BhF0M+0LqByPi5Mx8oPpnzENt1BUR4/R7LnBLZj5Y6/vpxxHxD8D1Tetqq7bMPFT9figi/oXuP/G+ziLPWUSsoBvm/5yZ19T6nmjOekzyRefHN9h2Eo2+YD0iXgZcCZybmT8+unzIcZ16XbW/fMnMPRHx2YhY3WTbaddWM+9fy1Ocsyamep4tx5dcnv7S6upq+Hy6X1JN9ft91eP3AU2u+JsYp995r9dVgXbU24G+74BPq7aI+PWIePbRx8BbajUs2pxFRAD/CNyTmX/bs67NORt2ztTrfW91F8Kr+NUXnTfZdhIj+4+IdcA1wHsy897a8mHH9VjU9YLqGBIRZ9HNkx832XbatVU1nQi8ntq5N+U5a2K659k03uld6A/dP7gHgP8FHgRuqJafAuyptdtM946I79F9qebo8ucC/wl8t/p9Ukt19e23T10n0D2hT+zZ/p+AO4E7qoN0cotzNrI2uu+c31793L1U5ozuSwdZzctt1c/macxZv3MGuAi4qHocwBXV+jup3WU16Hxr8RiOqu1K4Ke1OZobdVyPUV3bqnFvp/tm7WuWypxVzy8AdvdsN+05uwp4AHiCbpa9/1ieZ370X5IKsRxfcpEk9WGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEL8H4EZkfzuqBrcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_x.squeeze(-1), train_y, 'o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5173b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100000, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "200e80d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGLikelihood(gpytorch.likelihoods._OneDimensionalLikelihood):\n",
    "    # this method effectively computes the expected log likelihood\n",
    "    # contribution to Eqn (10) in Reference [1].\n",
    "    def expected_log_prob(self, target, input, *args, **kwargs):\n",
    "        mean, variance = input.mean, input.variance\n",
    "        # Compute the expectation E[f_i^2]\n",
    "        raw_second_moment = variance + mean.pow(2)\n",
    "\n",
    "        # Translate targets to be -1, 1\n",
    "        target = target.to(mean.dtype).mul(2.).sub(1.)\n",
    "\n",
    "        # We detach the following variable since we do not want\n",
    "        # to differentiate through the closed-form PG update.\n",
    "        c = raw_second_moment.detach().sqrt()\n",
    "        # Compute mean of PG auxiliary variable omega: 0.5 * Expectation[omega]\n",
    "        # See Eqn (11) and Appendix A2 and A3 in Reference [1] for details.\n",
    "        half_omega = 0.25 * torch.tanh(0.5 * c) / c\n",
    "\n",
    "        # Expected log likelihood\n",
    "        res = 0.5 * target * mean - half_omega * raw_second_moment\n",
    "        # Sum over data points in mini-batch\n",
    "        res = res.sum(dim=-1)\n",
    "\n",
    "        return res\n",
    "\n",
    "    # define the likelihood\n",
    "    def forward(self, function_samples):\n",
    "        return torch.distributions.Bernoulli(logits=function_samples)\n",
    "\n",
    "    # define the marginal likelihood using Gauss Hermite quadrature\n",
    "    def marginal(self, function_dist):\n",
    "        prob_lambda = lambda function_samples: self.forward(function_samples).probs\n",
    "        probs = self.quadrature(prob_lambda, function_dist)\n",
    "        return torch.distributions.Bernoulli(probs=probs)\n",
    "\n",
    "\n",
    "# define the actual GP model (kernels, inducing points, etc.)\n",
    "class GPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = gpytorch.variational.NaturalVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super(GPModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# we initialize our model with M = 30 inducing points\n",
    "M = 30\n",
    "inducing_points = torch.linspace(-2., 2., M, dtype=train_x.dtype, device=train_x.device).unsqueeze(-1)\n",
    "model = GPModel(inducing_points=inducing_points)\n",
    "model.covar_module.base_kernel.initialize(lengthscale=0.2)\n",
    "likelihood = PGLikelihood()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    likelihood = likelihood.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d009790",
   "metadata": {},
   "outputs": [],
   "source": [
    "variational_ngd_optimizer = gpytorch.optim.NGD(model.variational_parameters(), num_data=train_y.size(0), lr=0.1)\n",
    "\n",
    "hyperparameter_optimizer = torch.optim.Adam([\n",
    "    {'params': model.hyperparameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "956d593c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68ab5d91d504c29bafe4fea6f798a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train()\n",
    "likelihood.train()\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\n",
    "\n",
    "num_epochs = 1 if smoke_test else 100\n",
    "epochs_iter = tqdm.notebook.tqdm(range(num_epochs), desc=\"Epoch\")\n",
    "for i in epochs_iter:\n",
    "    minibatch_iter = tqdm.notebook.tqdm(train_loader, desc=\"Minibatch\", leave=False)\n",
    "\n",
    "    for x_batch, y_batch in minibatch_iter:\n",
    "        ### Perform NGD step to optimize variational parameters\n",
    "        variational_ngd_optimizer.zero_grad()\n",
    "        hyperparameter_optimizer.zero_grad()\n",
    "\n",
    "        output = model(x_batch)\n",
    "        loss = -mll(output, y_batch)\n",
    "        minibatch_iter.set_postfix(loss=loss.item())\n",
    "        loss.backward()\n",
    "        variational_ngd_optimizer.step()\n",
    "        hyperparameter_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a981a271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7c6002a580>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# push training data points through model\n",
    "train_mean_f = model(train_x).loc.data.cpu()\n",
    "# plot training data with y being -1/1 valued\n",
    "plt.plot(train_x.squeeze(-1), train_y.mul(2.).sub(1.), 'o')\n",
    "# plot mean gaussian process posterior mean evaluated at training data\n",
    "plt.plot(train_x.squeeze(-1).cpu(), train_mean_f.cpu(), 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dbd5a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NLL: 0.4911\n",
      "Test Acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "with torch.no_grad():\n",
    "    nlls = -likelihood.log_marginal(test_y, model(test_x))\n",
    "    acc = (likelihood(model(test_x)).probs.gt(0.5) == test_y.bool()).float().mean()\n",
    "print('Test NLL: {:.4f}'.format(nlls.mean()))\n",
    "print('Test Acc: {:.4f}'.format(acc.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d39183b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.7355]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())['covar_module.base_kernel.raw_lengthscale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7e37697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(1.3688, requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.covar_module.raw_outputscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a1cecb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: variational_strategy.inducing_points       value = Parameter containing:\n",
      "tensor([[-2.9195],\n",
      "        [-2.7519],\n",
      "        [-1.9329],\n",
      "        [-1.9289],\n",
      "        [-1.9049],\n",
      "        [-1.6244],\n",
      "        [-1.4084],\n",
      "        [-1.2762],\n",
      "        [-1.1212],\n",
      "        [-0.9774],\n",
      "        [-0.8427],\n",
      "        [-0.7509],\n",
      "        [-0.6561],\n",
      "        [-0.5174],\n",
      "        [-0.3318],\n",
      "        [-0.1711],\n",
      "        [-0.0923],\n",
      "        [-0.0094],\n",
      "        [ 0.1403],\n",
      "        [ 0.3073],\n",
      "        [ 0.5121],\n",
      "        [ 0.7310],\n",
      "        [ 0.9969],\n",
      "        [ 1.1324],\n",
      "        [ 1.3524],\n",
      "        [ 1.5366],\n",
      "        [ 1.7708],\n",
      "        [ 2.0190],\n",
      "        [ 2.2523],\n",
      "        [ 2.4393]], requires_grad=True)\n",
      "Parameter name: variational_strategy._variational_distribution.natural_vec value = Parameter containing:\n",
      "tensor([-4.0015e-06, -7.0124e-05, -8.2688e-02, -5.5328e-02, -2.2866e-01,\n",
      "        -9.4319e-01, -2.6563e+00, -4.3793e+00, -5.2466e+00, -5.6062e+00,\n",
      "        -4.4985e+00, -2.4491e+00, -1.0242e+00,  1.1473e+00,  4.8483e+00,\n",
      "         7.7755e+00,  6.3273e+00,  6.5731e+00,  7.7889e+00,  6.9030e+00,\n",
      "         4.7256e+00,  1.8590e+00,  1.1169e-01, -7.8280e-02,  2.0045e-02,\n",
      "         6.6548e-03, -1.3483e-02,  9.5192e-03, -4.0343e-03, -1.0348e-04],\n",
      "       requires_grad=True)\n",
      "Parameter name: variational_strategy._variational_distribution.natural_mat value = Parameter containing:\n",
      "tensor([[-5.0000e-01, -1.2987e-10, -1.0925e-07, -6.5573e-08, -2.6805e-07,\n",
      "         -8.5465e-07, -1.6298e-06, -1.5760e-06, -1.0220e-06, -5.0847e-07,\n",
      "         -1.2486e-07,  4.8646e-11,  1.2602e-08, -2.9293e-09, -9.5134e-09,\n",
      "          5.1642e-09,  2.6243e-09, -2.0694e-10, -2.9666e-09, -2.3777e-10,\n",
      "          1.7927e-09, -1.0317e-09,  1.0453e-10,  3.7598e-10, -3.5003e-10,\n",
      "          7.2886e-11,  1.0875e-10, -1.2835e-10,  8.3682e-11, -2.9271e-11],\n",
      "        [-1.2987e-10, -5.0000e-01, -1.8652e-06, -1.1225e-06, -4.5884e-06,\n",
      "         -1.4700e-05, -2.8227e-05, -2.7575e-05, -1.8122e-05, -9.2315e-06,\n",
      "         -2.4245e-06, -1.0181e-07,  1.8139e-07, -5.2905e-08, -1.6408e-07,\n",
      "          8.4839e-08,  4.5776e-08, -1.7423e-09, -4.9864e-08, -5.3840e-09,\n",
      "          3.0665e-08, -1.7019e-08,  1.2790e-09,  6.6932e-09, -5.9443e-09,\n",
      "          1.1028e-09,  1.9537e-09, -2.2192e-09,  1.4155e-09, -4.7187e-10],\n",
      "        [-1.0925e-07, -1.8652e-06, -5.0168e-01, -1.0248e-03, -4.1908e-03,\n",
      "         -1.3847e-02, -2.7832e-02, -2.9127e-02, -2.0979e-02, -1.2484e-02,\n",
      "         -4.7632e-03, -1.2410e-03, -4.0012e-04, -2.6584e-04, -2.0198e-04,\n",
      "          5.1917e-05,  4.0657e-05,  4.2807e-06, -3.9428e-05, -9.2110e-06,\n",
      "          2.6005e-05, -1.2200e-05, -7.2411e-07,  6.6056e-06, -4.8866e-06,\n",
      "          4.2272e-07,  1.9897e-06, -1.9668e-06,  1.1436e-06, -2.9778e-07],\n",
      "        [-6.5573e-08, -1.1225e-06, -1.0248e-03, -5.0074e-01, -2.5446e-03,\n",
      "         -8.5804e-03, -1.7473e-02, -1.8636e-02, -1.3737e-02, -8.4867e-03,\n",
      "         -3.4891e-03, -1.0446e-03, -4.0853e-04, -2.4358e-04, -1.4812e-04,\n",
      "          2.5638e-05,  2.3651e-05,  2.7215e-06, -2.3462e-05, -5.8635e-06,\n",
      "          1.5543e-05, -7.1381e-06, -5.4883e-07,  4.0026e-06, -2.9050e-06,\n",
      "          2.1614e-07,  1.2111e-06, -1.1799e-06,  6.7794e-07, -1.6934e-07],\n",
      "        [-2.6805e-07, -4.5884e-06, -4.1908e-03, -2.5446e-03, -5.1054e-01,\n",
      "         -3.5109e-02, -7.1549e-02, -7.6442e-02, -5.6579e-02, -3.5136e-02,\n",
      "         -1.4577e-02, -4.4530e-03, -1.7727e-03, -1.0528e-03, -6.2278e-04,\n",
      "          9.9642e-05,  9.5880e-05,  1.0856e-05, -9.5436e-05, -2.3941e-05,\n",
      "          6.3152e-05, -2.8881e-05, -2.3634e-06,  1.6348e-05, -1.1809e-05,\n",
      "          8.5541e-07,  4.9389e-06, -4.8020e-06,  2.7556e-06, -6.8535e-07],\n",
      "        [-8.5465e-07, -1.4700e-05, -1.3847e-02, -8.5804e-03, -3.5109e-02,\n",
      "         -6.1922e-01, -2.4976e-01, -2.7812e-01, -2.1737e-01, -1.4664e-01,\n",
      "         -7.0697e-02, -2.7288e-02, -1.3877e-02, -8.2376e-03, -3.8723e-03,\n",
      "         -1.1485e-04,  2.1126e-04, -6.4028e-06, -3.1604e-04, -7.4502e-05,\n",
      "          1.9751e-04, -9.1481e-05, -6.4369e-06,  5.0562e-05, -3.6933e-05,\n",
      "          2.9174e-06,  1.5258e-05, -1.4950e-05,  8.6274e-06, -2.1862e-06],\n",
      "        [-1.6298e-06, -2.8227e-05, -2.7832e-02, -1.7473e-02, -7.1549e-02,\n",
      "         -2.4976e-01, -1.0455e+00, -6.4592e-01, -5.4600e-01, -4.1102e-01,\n",
      "         -2.3555e-01, -1.1238e-01, -6.8435e-02, -4.4377e-02, -2.0885e-02,\n",
      "         -3.9605e-03, -5.2501e-04, -4.9557e-04, -8.3324e-04, -1.3030e-04,\n",
      "          3.8049e-04, -2.0121e-04,  6.9522e-06,  8.7475e-05, -7.2709e-05,\n",
      "          1.1038e-05,  2.5844e-05, -2.7882e-05,  1.7192e-05, -5.2603e-06],\n",
      "        [-1.5760e-06, -2.7575e-05, -2.9127e-02, -1.8636e-02, -7.6442e-02,\n",
      "         -2.7812e-01, -6.4592e-01, -1.3333e+00, -7.8054e-01, -6.6790e-01,\n",
      "         -4.5508e-01, -2.5846e-01, -1.8000e-01, -1.3031e-01, -6.8678e-02,\n",
      "         -1.9975e-02, -4.8809e-03, -2.8672e-03, -2.0911e-03, -2.5442e-04,\n",
      "          4.2117e-04, -3.0256e-04,  6.0682e-05,  7.4048e-05, -8.8360e-05,\n",
      "          2.7589e-05,  2.0158e-05, -2.9708e-05,  2.1445e-05, -8.9750e-06],\n",
      "        [-1.0220e-06, -1.8122e-05, -2.0979e-02, -1.3737e-02, -5.6579e-02,\n",
      "         -2.1737e-01, -5.4600e-01, -7.8054e-01, -1.3201e+00, -7.9814e-01,\n",
      "         -6.3547e-01, -4.1574e-01, -3.2285e-01, -2.6200e-01, -1.5988e-01,\n",
      "         -5.9228e-02, -1.7108e-02, -9.8719e-03, -5.9788e-03, -1.1687e-03,\n",
      "          3.3939e-04, -4.1161e-04,  1.0505e-04,  6.5886e-05, -1.0397e-04,\n",
      "          4.1898e-05,  1.6201e-05, -3.2141e-05,  2.5576e-05, -1.2272e-05],\n",
      "        [-5.0847e-07, -9.2315e-06, -1.2484e-02, -8.4867e-03, -3.5136e-02,\n",
      "         -1.4664e-01, -4.1102e-01, -6.6790e-01, -7.9814e-01, -1.3829e+00,\n",
      "         -8.0876e-01, -5.9521e-01, -5.0570e-01, -4.5424e-01, -3.1657e-01,\n",
      "         -1.3946e-01, -4.5225e-02, -2.7294e-02, -1.6676e-02, -4.5087e-03,\n",
      "         -1.3185e-04, -5.9932e-04,  1.0300e-04,  1.0621e-04, -1.3722e-04,\n",
      "          4.7199e-05,  2.7766e-05, -4.4765e-05,  3.3374e-05, -1.4665e-05],\n",
      "        [-1.2486e-07, -2.4245e-06, -4.7632e-03, -3.4891e-03, -1.4577e-02,\n",
      "         -7.0697e-02, -2.3555e-01, -4.5508e-01, -6.3547e-01, -8.0876e-01,\n",
      "         -1.3561e+00, -7.0777e-01, -6.5740e-01, -6.5501e-01, -5.2188e-01,\n",
      "         -2.6998e-01, -9.8343e-02, -6.3406e-02, -4.1158e-02, -1.3782e-02,\n",
      "         -2.2070e-03, -9.9720e-04,  5.6516e-06,  1.9232e-04, -1.6954e-04,\n",
      "          3.2490e-05,  5.4748e-05, -6.2901e-05,  4.0153e-05, -1.3328e-05],\n",
      "        [ 4.8646e-11, -1.0181e-07, -1.2410e-03, -1.0446e-03, -4.4530e-03,\n",
      "         -2.7288e-02, -1.1238e-01, -2.5846e-01, -4.1574e-01, -5.9521e-01,\n",
      "         -7.0777e-01, -1.1408e+00, -6.3780e-01, -6.8923e-01, -6.0919e-01,\n",
      "         -3.5644e-01, -1.4293e-01, -9.7795e-02, -6.7628e-02, -2.5925e-02,\n",
      "         -6.0093e-03, -1.6586e-03, -1.3570e-04,  2.3691e-04, -1.6343e-04,\n",
      "          1.0583e-05,  6.9208e-05, -6.6804e-05,  3.7932e-05, -9.0790e-06],\n",
      "        [ 1.2602e-08,  1.8139e-07, -4.0012e-04, -4.0853e-04, -1.7727e-03,\n",
      "         -1.3877e-02, -6.8435e-02, -1.8000e-01, -3.2285e-01, -5.0570e-01,\n",
      "         -6.5740e-01, -6.3780e-01, -1.1695e+00, -7.7055e-01, -7.3885e-01,\n",
      "         -4.7677e-01, -2.0708e-01, -1.4903e-01, -1.0912e-01, -4.6379e-02,\n",
      "         -1.3153e-02, -3.2393e-03, -3.4731e-04,  2.9743e-04, -1.7354e-04,\n",
      "         -5.1947e-06,  8.6573e-05, -7.6003e-05,  3.9875e-05, -6.8150e-06],\n",
      "        [-2.9293e-09, -5.2905e-08, -2.6584e-04, -2.4358e-04, -1.0528e-03,\n",
      "         -8.2376e-03, -4.4377e-02, -1.3031e-01, -2.6200e-01, -4.5424e-01,\n",
      "         -6.5501e-01, -6.8923e-01, -7.7055e-01, -1.4568e+00, -1.0135e+00,\n",
      "         -7.3843e-01, -3.5504e-01, -2.7231e-01, -2.1524e-01, -1.0392e-01,\n",
      "         -3.5988e-02, -9.0723e-03, -1.0770e-03,  4.5363e-04, -2.0759e-04,\n",
      "         -3.5725e-05,  1.2733e-04, -1.0068e-04,  4.7722e-05, -3.6407e-06],\n",
      "        [-9.5134e-09, -1.6408e-07, -2.0198e-04, -1.4812e-04, -6.2278e-04,\n",
      "         -3.8723e-03, -2.0885e-02, -6.8678e-02, -1.5988e-01, -3.1657e-01,\n",
      "         -5.2188e-01, -6.0919e-01, -7.3885e-01, -1.0135e+00, -1.7262e+00,\n",
      "         -1.0515e+00, -5.7974e-01, -4.8385e-01, -4.2580e-01, -2.4383e-01,\n",
      "         -1.0535e-01, -3.0378e-02, -4.0624e-03,  8.2631e-04, -2.1354e-04,\n",
      "         -1.3445e-04,  2.1102e-04, -1.3824e-04,  5.1497e-05,  9.5929e-06],\n",
      "        [ 5.1642e-09,  8.4839e-08,  5.1917e-05,  2.5638e-05,  9.9642e-05,\n",
      "         -1.1485e-04, -3.9605e-03, -1.9975e-02, -5.9228e-02, -1.3946e-01,\n",
      "         -2.6998e-01, -3.5644e-01, -4.7677e-01, -7.3843e-01, -1.0515e+00,\n",
      "         -1.5945e+00, -7.0673e-01, -6.4808e-01, -6.4620e-01, -4.4621e-01,\n",
      "         -2.3788e-01, -8.1723e-02, -1.2663e-02,  1.6802e-03, -1.3558e-04,\n",
      "         -3.9316e-04,  3.8913e-04, -2.0142e-04,  4.3950e-05,  4.6030e-05],\n",
      "        [ 2.6243e-09,  4.5776e-08,  4.0657e-05,  2.3651e-05,  9.5880e-05,\n",
      "          2.1126e-04, -5.2501e-04, -4.8809e-03, -1.7108e-02, -4.5225e-02,\n",
      "         -9.8343e-02, -1.4293e-01, -2.0708e-01, -3.5504e-01, -5.7974e-01,\n",
      "         -7.0673e-01, -1.0177e+00, -5.1089e-01, -5.6368e-01, -4.4952e-01,\n",
      "         -2.7840e-01, -1.0983e-01, -1.9148e-02,  2.2135e-03, -4.1458e-05,\n",
      "         -5.7395e-04,  4.9857e-04, -2.3361e-04,  3.3395e-05,  7.1400e-05],\n",
      "        [-2.0694e-10, -1.7423e-09,  4.2807e-06,  2.7215e-06,  1.0856e-05,\n",
      "         -6.4028e-06, -4.9557e-04, -2.8672e-03, -9.8719e-03, -2.7294e-02,\n",
      "         -6.3406e-02, -9.7795e-02, -1.4903e-01, -2.7231e-01, -4.8385e-01,\n",
      "         -6.4808e-01, -5.1089e-01, -1.0261e+00, -6.1565e-01, -5.3247e-01,\n",
      "         -3.5803e-01, -1.5290e-01, -2.8617e-02,  3.1873e-03, -1.1997e-05,\n",
      "         -8.5286e-04,  7.2154e-04, -3.3103e-04,  4.1772e-05,  1.0689e-04],\n",
      "        [-2.9666e-09, -4.9864e-08, -3.9428e-05, -2.3462e-05, -9.5436e-05,\n",
      "         -3.1604e-04, -8.3324e-04, -2.0911e-03, -5.9788e-03, -1.6676e-02,\n",
      "         -4.1158e-02, -6.7628e-02, -1.0912e-01, -2.1524e-01, -4.2580e-01,\n",
      "         -6.4620e-01, -5.6368e-01, -6.1565e-01, -1.2841e+00, -7.6017e-01,\n",
      "         -5.7385e-01, -2.7512e-01, -5.7406e-02,  6.2213e-03,  4.6978e-05,\n",
      "         -1.7378e-03,  1.4485e-03, -6.5667e-04,  7.5943e-05,  2.1960e-04],\n",
      "        [-2.3777e-10, -5.3840e-09, -9.2110e-06, -5.8635e-06, -2.3941e-05,\n",
      "         -7.4502e-05, -1.3030e-04, -2.5442e-04, -1.1687e-03, -4.5087e-03,\n",
      "         -1.3782e-02, -2.5925e-02, -4.6379e-02, -1.0392e-01, -2.4383e-01,\n",
      "         -4.4621e-01, -4.4952e-01, -5.3247e-01, -7.6017e-01, -1.3519e+00,\n",
      "         -7.4142e-01, -4.0964e-01, -9.8251e-02,  1.0374e-02,  2.6249e-04,\n",
      "         -3.1260e-03,  2.5449e-03, -1.1250e-03,  1.0272e-04,  4.0636e-04],\n",
      "        [ 1.7927e-09,  3.0665e-08,  2.6005e-05,  1.5543e-05,  6.3152e-05,\n",
      "          1.9751e-04,  3.8049e-04,  4.2117e-04,  3.3939e-04, -1.3185e-04,\n",
      "         -2.2070e-03, -6.0093e-03, -1.3153e-02, -3.5988e-02, -1.0535e-01,\n",
      "         -2.3788e-01, -2.7840e-01, -3.5803e-01, -5.7385e-01, -7.4142e-01,\n",
      "         -1.2438e+00, -4.7548e-01, -1.3318e-01,  1.3295e-02,  8.8270e-04,\n",
      "         -4.5412e-03,  3.4937e-03, -1.4435e-03,  3.7558e-05,  6.2281e-04],\n",
      "        [-1.0317e-09, -1.7019e-08, -1.2200e-05, -7.1381e-06, -2.8881e-05,\n",
      "         -9.1481e-05, -2.0121e-04, -3.0256e-04, -4.1161e-04, -5.9932e-04,\n",
      "         -9.9720e-04, -1.6586e-03, -3.2393e-03, -9.0723e-03, -3.0378e-02,\n",
      "         -8.1723e-02, -1.0983e-01, -1.5290e-01, -2.7512e-01, -4.0964e-01,\n",
      "         -4.7548e-01, -8.5380e-01, -1.1760e-01,  1.0248e-02,  1.5806e-03,\n",
      "         -4.2412e-03,  2.9446e-03, -1.0558e-03, -1.2889e-04,  6.2206e-04],\n",
      "        [ 1.0453e-10,  1.2790e-09, -7.2411e-07, -5.4883e-07, -2.3634e-06,\n",
      "         -6.4369e-06,  6.9522e-06,  6.0682e-05,  1.0505e-04,  1.0300e-04,\n",
      "          5.6516e-06, -1.3570e-04, -3.4731e-04, -1.0770e-03, -4.0624e-03,\n",
      "         -1.2663e-02, -1.9148e-02, -2.8617e-02, -5.7406e-02, -9.8251e-02,\n",
      "         -1.3318e-01, -1.1760e-01, -5.4826e-01,  2.8383e-03,  1.1849e-03,\n",
      "         -1.7370e-03,  9.8508e-04, -2.3507e-04, -1.5950e-04,  2.7720e-04],\n",
      "        [ 3.7598e-10,  6.6932e-09,  6.6056e-06,  4.0026e-06,  1.6348e-05,\n",
      "          5.0562e-05,  8.7475e-05,  7.4048e-05,  6.5886e-05,  1.0621e-04,\n",
      "          1.9232e-04,  2.3691e-04,  2.9743e-04,  4.5363e-04,  8.2631e-04,\n",
      "          1.6802e-03,  2.2135e-03,  3.1873e-03,  6.2213e-03,  1.0374e-02,\n",
      "          1.3295e-02,  1.0248e-02,  2.8383e-03, -5.0058e-01,  2.1935e-05,\n",
      "          1.5725e-04, -1.3821e-04,  6.3371e-05, -7.0106e-06, -2.1718e-05],\n",
      "        [-3.5003e-10, -5.9443e-09, -4.8866e-06, -2.9050e-06, -1.1809e-05,\n",
      "         -3.6933e-05, -7.2709e-05, -8.8360e-05, -1.0397e-04, -1.3722e-04,\n",
      "         -1.6954e-04, -1.6343e-04, -1.7354e-04, -2.0759e-04, -2.1354e-04,\n",
      "         -1.3558e-04, -4.1458e-05, -1.1997e-05,  4.6978e-05,  2.6249e-04,\n",
      "          8.8270e-04,  1.5806e-03,  1.1849e-03,  2.1935e-05, -5.0007e-01,\n",
      "          4.0395e-05, -6.1392e-06, -9.3545e-06,  1.1621e-05, -7.9802e-06],\n",
      "        [ 7.2886e-11,  1.1028e-09,  4.2272e-07,  2.1614e-07,  8.5541e-07,\n",
      "          2.9174e-06,  1.1038e-05,  2.7589e-05,  4.1898e-05,  4.7199e-05,\n",
      "          3.2490e-05,  1.0583e-05, -5.1947e-06, -3.5725e-05, -1.3445e-04,\n",
      "         -3.9316e-04, -5.7395e-04, -8.5286e-04, -1.7378e-03, -3.1260e-03,\n",
      "         -4.5412e-03, -4.2412e-03, -1.7370e-03,  1.5725e-04,  4.0395e-05,\n",
      "         -5.0008e-01,  4.6783e-05, -1.3058e-05, -5.8181e-06,  1.2157e-05],\n",
      "        [ 1.0875e-10,  1.9537e-09,  1.9897e-06,  1.2111e-06,  4.9389e-06,\n",
      "          1.5258e-05,  2.5844e-05,  2.0158e-05,  1.6201e-05,  2.7766e-05,\n",
      "          5.4748e-05,  6.9208e-05,  8.6573e-05,  1.2733e-04,  2.1102e-04,\n",
      "          3.8913e-04,  4.9857e-04,  7.2154e-04,  1.4485e-03,  2.5449e-03,\n",
      "          3.4937e-03,  2.9446e-03,  9.8508e-04, -1.3821e-04, -6.1392e-06,\n",
      "          4.6783e-05, -5.0004e-01,  1.4818e-05,  4.2012e-08, -6.8413e-06],\n",
      "        [-1.2835e-10, -2.2192e-09, -1.9668e-06, -1.1799e-06, -4.8020e-06,\n",
      "         -1.4950e-05, -2.7882e-05, -2.9708e-05, -3.2141e-05, -4.4765e-05,\n",
      "         -6.2901e-05, -6.6804e-05, -7.6003e-05, -1.0068e-04, -1.3824e-04,\n",
      "         -2.0142e-04, -2.3361e-04, -3.3103e-04, -6.5667e-04, -1.1250e-03,\n",
      "         -1.4435e-03, -1.0558e-03, -2.3507e-04,  6.3371e-05, -9.3545e-06,\n",
      "         -1.3058e-05,  1.4818e-05, -5.0001e-01,  2.1080e-06,  1.5474e-06],\n",
      "        [ 8.3682e-11,  1.4155e-09,  1.1436e-06,  6.7794e-07,  2.7556e-06,\n",
      "          8.6274e-06,  1.7192e-05,  2.1445e-05,  2.5576e-05,  3.3374e-05,\n",
      "          4.0153e-05,  3.7932e-05,  3.9875e-05,  4.7722e-05,  5.1497e-05,\n",
      "          4.3950e-05,  3.3395e-05,  4.1772e-05,  7.5943e-05,  1.0272e-04,\n",
      "          3.7558e-05, -1.2889e-04, -1.5950e-04, -7.0106e-06,  1.1621e-05,\n",
      "         -5.8181e-06,  4.2012e-08,  2.1080e-06, -5.0000e-01,  1.2487e-06],\n",
      "        [-2.9271e-11, -4.7187e-10, -2.9778e-07, -1.6934e-07, -6.8535e-07,\n",
      "         -2.1862e-06, -5.2603e-06, -8.9750e-06, -1.2272e-05, -1.4665e-05,\n",
      "         -1.3328e-05, -9.0790e-06, -6.8150e-06, -3.6407e-06,  9.5929e-06,\n",
      "          4.6030e-05,  7.1400e-05,  1.0689e-04,  2.1960e-04,  4.0636e-04,\n",
      "          6.2281e-04,  6.2206e-04,  2.7720e-04, -2.1718e-05, -7.9802e-06,\n",
      "          1.2157e-05, -6.8413e-06,  1.5474e-06,  1.2487e-06, -5.0000e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter name: covar_module.raw_outputscale               value = 1.3688079118728638\n",
      "Parameter name: covar_module.base_kernel.raw_lengthscale   value = Parameter containing:\n",
      "tensor([[-0.7355]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in model.named_parameters():\n",
    "    print(f'Parameter name: {param_name:42} value = {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aa839c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9d/jpvr10fs6jb7vfqnwlqck0kc0000gp/T/ipykernel_19511/2103537015.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_rows = 40\n",
    "pd.options.display.max_columns = 40\n",
    "!ls data/kaggle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e701953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907acc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpytorch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57bde1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 100 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, 100)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313059a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed94c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 50\n",
    "print(smoke_test)\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model.covar_module.base_kernel.lengthscale.item(),\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53865563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(0, 1, 51)\n",
    "    observed_pred = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f09e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f6abd",
   "metadata": {},
   "source": [
    "# Custom kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 50\n",
    "\n",
    "# Training data is 100 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, 100)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)\n",
    "\n",
    "# Wrap training, prediction and plotting from the ExactGP-Tutorial into a function,\n",
    "# so that we do not have to repeat the code later on\n",
    "def train(model, likelihood, training_iter=training_iter):\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def predict(model, likelihood, test_x = torch.linspace(0, 1, 51)):\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    # Make predictions by feeding model through likelihood\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        # Test points are regularly spaced along [0,1]\n",
    "        return likelihood(model(test_x))\n",
    "\n",
    "def plot(observed_pred, test_x=torch.linspace(0, 1, 51)):\n",
    "    with torch.no_grad():\n",
    "        # Initialize plot\n",
    "        f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "        # Get upper and lower confidence bounds\n",
    "        lower, upper = observed_pred.confidence_region()\n",
    "        # Plot training data as black stars\n",
    "        ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "        # Plot predictive means as blue line\n",
    "        ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
    "        # Shade between the lower and upper confidence bounds\n",
    "        ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "        ax.set_ylim([-3, 3])\n",
    "        ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0113844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstSincKernel(gpytorch.kernels.Kernel):\n",
    "    # the sinc kernel is stationary\n",
    "    is_stationary = True\n",
    "\n",
    "    # this is the kernel function\n",
    "    def forward(self, x1, x2, **params):\n",
    "        # calculate the distance between inputs\n",
    "        diff = self.covar_dist(x1, x2, **params)\n",
    "        # prevent divide by 0 errors\n",
    "        diff.where(diff == 0, torch.as_tensor(1e-20))\n",
    "        # return sinc(diff) = sin(diff) / diff\n",
    "        return torch.sin(diff).div(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the simplest form of GP model, exact inference\n",
    "class FirstGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = FirstSincKernel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = FirstGPModel(train_x, train_y, likelihood)\n",
    "\n",
    "# set to training mode and train\n",
    "model.train()\n",
    "likelihood.train()\n",
    "train(model, likelihood)\n",
    "\n",
    "# Get into evaluation (predictive posterior) mode and predict\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "observed_pred = predict(model, likelihood)\n",
    "# plot results\n",
    "plot(observed_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306c9e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import positivity constraint\n",
    "from gpytorch.constraints import Positive\n",
    "\n",
    "class SincKernel(gpytorch.kernels.Kernel):\n",
    "    # the sinc kernel is stationary\n",
    "    is_stationary = True\n",
    "\n",
    "    # We will register the parameter when initializing the kernel\n",
    "    def __init__(self, length_prior=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # register the raw parameter\n",
    "        self.register_parameter(\n",
    "            name='raw_length', parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # set the parameter constraint to be positive, when nothing is specified\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "\n",
    "        # register the constraint\n",
    "        self.register_constraint(\"raw_length\", length_constraint)\n",
    "\n",
    "        # set the parameter prior, see\n",
    "        # https://docs.gpytorch.ai/en/latest/module.html#gpytorch.Module.register_prior\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"length_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.length,\n",
    "                lambda m, v : m._set_length(v),\n",
    "            )\n",
    "\n",
    "    # now set up the 'actual' paramter\n",
    "    @property\n",
    "    def length(self):\n",
    "        # when accessing the parameter, apply the constraint transform\n",
    "        return self.raw_length_constraint.transform(self.raw_length)\n",
    "\n",
    "    @length.setter\n",
    "    def length(self, value):\n",
    "        return self._set_length(value)\n",
    "\n",
    "    def _set_length(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_length)\n",
    "        # when setting the paramater, transform the actual value to a raw one by applying the inverse transform\n",
    "        self.initialize(raw_length=self.raw_length_constraint.inverse_transform(value))\n",
    "\n",
    "    # this is the kernel function\n",
    "    def forward(self, x1, x2, **params):\n",
    "        # apply lengthscale\n",
    "        x1_ = x1.div(self.length)\n",
    "        x2_ = x2.div(self.length)\n",
    "        # calculate the distance between inputs\n",
    "        diff = self.covar_dist(x1_, x2_, **params)\n",
    "        # prevent divide by 0 errors\n",
    "        diff.where(diff == 0, torch.as_tensor(1e-20))\n",
    "        # return sinc(diff) = sin(diff) / diff\n",
    "        return torch.sin(diff).div(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b018b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the simplest form of GP model, exact inference\n",
    "class SincGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = SincKernel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize the new model\n",
    "model = SincGPModel(train_x, train_y, likelihood)\n",
    "\n",
    "# set to training mode and train\n",
    "model.train()\n",
    "likelihood.train()\n",
    "train(model, likelihood)\n",
    "\n",
    "# Get into evaluation (predictive posterior) mode and predict\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "observed_pred = predict(model, likelihood)\n",
    "# plot results\n",
    "plot(observed_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9761a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSincKernel(gpytorch.kernels.Kernel):\n",
    "    has_lengthscale = True\n",
    "\n",
    "    # this is the kernel function\n",
    "    def forward(self, x1, x2, **params):\n",
    "        # apply lengthscale\n",
    "        x1_ = x1.div(self.lengthscale)\n",
    "        x2_ = x2.div(self.lengthscale)\n",
    "        # calculate the distance between inputs\n",
    "        diff = self.covar_dist(x1_, x2_, **params)\n",
    "        # prevent divide by 0 errors\n",
    "        diff.where(diff == 0, torch.as_tensor(1e-20))\n",
    "        # return sinc(diff) = sin(diff) / diff\n",
    "        return torch.sin(diff).div(diff)\n",
    "\n",
    "# Use the simplest form of GP model, exact inference\n",
    "class SimpleSincGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = SimpleSincKernel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize the new model\n",
    "model = SimpleSincGPModel(train_x, train_y, likelihood)\n",
    "\n",
    "# set to training mode and train\n",
    "model.train()\n",
    "likelihood.train()\n",
    "train(model, likelihood)\n",
    "\n",
    "# Get into evaluation (predictive posterior) mode and predict\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "observed_pred = predict(model, likelihood)\n",
    "# plot results\n",
    "plot(observed_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf06d2",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffe2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(num_data, seed = 2019):\n",
    "    torch.random.manual_seed(seed)\n",
    "\n",
    "    x = torch.randn(num_data,1)\n",
    "    y = torch.randn(num_data,1)\n",
    "\n",
    "    u = torch.rand(1)\n",
    "    data_fn = lambda x, y: 1 * torch.sin(0.15 * u * 3.1415 * (x + y)) + 1\n",
    "    latent_fn = data_fn(x, y)\n",
    "    z = torch.round(latent_fn).long().squeeze()\n",
    "    return torch.cat((x,y),dim=1), z, data_fn\n",
    "\n",
    "train_x, train_y, genfn = gen_data(500)\n",
    "plt.scatter(train_x[:,0].numpy(), train_x[:,1].numpy(), c = train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a1de9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d1 = np.linspace(-3, 3, 20)\n",
    "test_d2 = np.linspace(-3, 3, 20)\n",
    "\n",
    "test_x_mat, test_y_mat = np.meshgrid(test_d1, test_d2)\n",
    "test_x_mat, test_y_mat = torch.Tensor(test_x_mat), torch.Tensor(test_y_mat)\n",
    "\n",
    "test_x = torch.cat((test_x_mat.view(-1,1), test_y_mat.view(-1,1)),dim=1)\n",
    "test_labels = torch.round(genfn(test_x_mat, test_y_mat))\n",
    "test_y = test_labels.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import DirichletClassificationLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "class DirichletGPModel(ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, num_classes):\n",
    "        super(DirichletGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean(batch_shape=torch.Size((num_classes,)))\n",
    "        self.covar_module = ScaleKernel(\n",
    "            RBFKernel(batch_shape=torch.Size((num_classes,))),\n",
    "            batch_shape=torch.Size((num_classes,)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "# we let the DirichletClassificationLikelihood compute the targets for us\n",
    "likelihood = DirichletClassificationLikelihood(train_y, learn_additional_noise=True)\n",
    "model = DirichletGPModel(train_x, likelihood.transformed_targets, likelihood, num_classes=likelihood.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f7230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 50\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, likelihood.transformed_targets).sum()\n",
    "    loss.backward()\n",
    "    if i % 5 == 0:\n",
    "        print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "            i + 1, training_iter, loss.item(),\n",
    "            model.covar_module.base_kernel.lengthscale.mean().item(),\n",
    "            model.likelihood.second_noise_covar.noise.mean().item()\n",
    "        ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_X.shape, n_fighters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551f53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with gpytorch.settings.fast_pred_var(), torch.no_grad():\n",
    "    test_dist = model(test_x)\n",
    "\n",
    "    pred_means = test_dist.loc\n",
    "    \n",
    "fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "for i in range(3):\n",
    "    im = ax[i].contourf(\n",
    "        test_x_mat.numpy(), test_y_mat.numpy(), pred_means[i].numpy().reshape((20,20))\n",
    "    )\n",
    "    fig.colorbar(im, ax=ax[i])\n",
    "    ax[i].set_title(\"Logits: Class \" + str(i), fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1553944",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_samples = test_dist.sample(torch.Size((256,))).exp()\n",
    "probabilities = (pred_samples / pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "levels = np.linspace(0, 1.05, 20)\n",
    "for i in range(3):\n",
    "    im = ax[i].contourf(\n",
    "        test_x_mat.numpy(), test_y_mat.numpy(), probabilities[i].numpy().reshape((20,20)), levels=levels\n",
    "    )\n",
    "    fig.colorbar(im, ax=ax[i])\n",
    "    ax[i].set_title(\"Probabilities: Class \" + str(i), fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6405b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3679acdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6da16db",
   "metadata": {},
   "source": [
    "# UFC fights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb687063",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/kaggle_data/ufc-master.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3764a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_implied_opener_prob(x):\n",
    "    if x < 0: # favorite\n",
    "        x *= 1\n",
    "        return x / (x + 100)\n",
    "    return 100 / (x + 100)\n",
    "\n",
    "p_R = df[\"R_odds\"].apply(get_implied_opener_prob)\n",
    "p_B = df[\"B_odds\"].apply(get_implied_opener_prob)\n",
    "p_R_norm = p_R / (p_R + p_B)\n",
    "df[\"p_R_norm\"] = p_R_norm\n",
    "\n",
    "y_true = df[\"Winner\"] == \"Red\"\n",
    "y_pred = df[\"p_R_norm\"]\n",
    "ignore_inds = y_true.isnull() | y_pred.isnull() | (df[\"finish\"].isin([\"DQ\", \"Overturned\", \"M-DEC\"]))\n",
    "y_true = y_true.loc[~ignore_inds]\n",
    "y_pred = y_pred.loc[~ignore_inds]\n",
    "ignore_inds = df[\"Winner\"].isnull() | df[\"p_R_norm\"].isnull() | (df[\"finish\"].isin([\"DQ\", \"Overturned\", \"M-DEC\"]))\n",
    "\n",
    "temp_df = df.loc[~ignore_inds].copy()\n",
    "temp_df[\"date\"] = pd.to_datetime(temp_df[\"date\"])\n",
    "temp_df[\"y_true\"] = (temp_df[\"Winner\"] == \"Red\").astype(int)\n",
    "date_split = temp_df[\"date\"].quantile(0.8) # 80-20 split\n",
    "train_df = temp_df.query(\"date <= '{}'\".format(date_split))\n",
    "test_df = temp_df.query(\"date > '{}'\".format(date_split))\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "fighter_encoder = OneHotEncoder()\n",
    "fighters = set()\n",
    "for temp_df in [train_df, test_df]:\n",
    "    for col in [\"R_fighter\", \"B_fighter\"]:\n",
    "        fighters = fighters | set(temp_df[col])\n",
    "fighters = sorted(fighters)\n",
    "fighter_encoder.fit(np.array(fighters).reshape(-1, 1))\n",
    "\n",
    "y = torch.Tensor((train_df[\"Winner\"] == \"Red\").values).to(int)\n",
    "fighter_A = fighter_encoder.transform(train_df[\"R_fighter\"].values.reshape(-1, 1)).todense()\n",
    "fighter_B = fighter_encoder.transform(train_df[\"B_fighter\"].values.reshape(-1, 1)).todense()\n",
    "n_fighters = len(fighters)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e78696",
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24386781",
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_X = torch.Tensor(fighter_A - fighter_B) \n",
    "fighter_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4977069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay awesome, that's about what i expected\n",
    "test_y = (test_df[\"Winner\"] == \"Red\")#.astype(int)\n",
    "fighter_A = fighter_encoder.transform(test_df[\"R_fighter\"].values.reshape(-1, 1)).todense()\n",
    "fighter_B = fighter_encoder.transform(test_df[\"B_fighter\"].values.reshape(-1, 1)).todense()\n",
    "test_X = torch.Tensor(fighter_A - fighter_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5a93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "kernel = DotProduct()\n",
    "gpc = GaussianProcessClassifier(kernel=kernel,\n",
    "        random_state=0).fit(fighter_X, y)\n",
    "gpc.score(fighter_X, y)\n",
    "\n",
    "gpc.predict_proba(fighter_X[:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05265d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc.score(fighter_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90610ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the simplest form of GP model, exact inference\n",
    "class SimpleEloModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, num_classes):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean(batch_shape=torch.Size((num_classes,)))\n",
    "        self.covar_module = ScaleKernel(\n",
    "            gpytorch.kernels.LinearKernel(batch_shape=torch.Size((num_classes,))),\n",
    "            batch_shape=torch.Size((num_classes,)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "# we let the DirichletClassificationLikelihood compute the targets for us\n",
    "from gpytorch.likelihoods import DirichletClassificationLikelihood\n",
    "\n",
    "likelihood = DirichletClassificationLikelihood(y, learn_additional_noise=True)\n",
    "model = SimpleEloModel(fighter_X, likelihood.transformed_targets, likelihood, num_classes=likelihood.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567e016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 50\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(fighter_X)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, likelihood.transformed_targets).sum()\n",
    "    loss.backward()\n",
    "    if i % 5 == 0:\n",
    "        print('Iter %d/%d - Loss: %.3f   noise: %.3f' % (\n",
    "            i + 1, training_iter, loss.item(),\n",
    "            #model.covar_module.base_kernel.mean().item(),\n",
    "            model.likelihood.second_noise_covar.noise.mean().item()\n",
    "        ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8212d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with gpytorch.settings.fast_pred_var(), torch.no_grad():\n",
    "    test_dist = model(fighter_X)\n",
    "\n",
    "    pred_means = test_dist.loc\n",
    "pred_means\n",
    "# predict(model, likelihood, fighter_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6905d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_samples = test_dist.sample(torch.Size((256,))).exp()\n",
    "probabilities = (pred_samples / pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4733f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(((probabilities[1] > 0.5).to(int) == y).to(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059a4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import DirichletClassificationLikelihood\n",
    "from gpytorch.means import ConstantMean, ZeroMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, LinearKernel\n",
    "\n",
    "class SimpleEloModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, num_classes):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        batch_shape = torch.Size((num_classes,))\n",
    "        self.mean_module = ZeroMean(batch_shape=batch_shape)\n",
    "        self.covar_module = ScaleKernel(\n",
    "            LinearKernel(batch_shape=batch_shape),\n",
    "            batch_shape=batch_shape,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "class GPClassifier(object):\n",
    "    \n",
    "    def __init__(self, training_iter=50, lr=0.1):\n",
    "        self.training_iter = training_iter\n",
    "        self.lr = lr\n",
    "        self.likelihood = None\n",
    "        self.model = None\n",
    "        self.fighter_encoder = None\n",
    "        \n",
    "    def init_model(self, X, y):\n",
    "        self.likelihood = DirichletClassificationLikelihood(y, learn_additional_noise=True)\n",
    "        self.model = SimpleEloModel(X, self.likelihood.transformed_targets, \n",
    "                                    self.likelihood, num_classes=self.likelihood.num_classes)\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        assert self.fighter_encoder is not None, \"did you forget to call init_fighter_encoder?\"\n",
    "        X = self._get_covar(train_df)\n",
    "        y = self._get_targets(train_df)\n",
    "        self.init_model(X, y)\n",
    "        self.model.train()\n",
    "        self.model.likelihood.train()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "        for i in range(training_iter):\n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            # Output from model\n",
    "            output = self.model(X)\n",
    "            # Calc loss and backprop gradients\n",
    "            loss = -mll(output, self.model.likelihood.transformed_targets).sum()\n",
    "            loss.backward()\n",
    "            if i % 5 == 0:\n",
    "                print('Iter %d/%d - Loss: %.3f   noise: %.3f' % (\n",
    "                    i + 1, training_iter, loss.item(),\n",
    "                    #self.model.covar_module.base_kernel.mean().item(),\n",
    "                    self.model.likelihood.second_noise_covar.noise.mean().item()\n",
    "                ))\n",
    "            optimizer.step()\n",
    "        \n",
    "    def init_fighter_encoder(self, train_df, test_df):\n",
    "        # note that this takes both train_df and test_df in\n",
    "        # i want to call this before calling .fit()\n",
    "        self.fighter_encoder = OneHotEncoder()\n",
    "        fighters = set()\n",
    "        for temp_df in [train_df, test_df]:\n",
    "            for col in [\"R_fighter\", \"B_fighter\"]:\n",
    "                fighters = fighters | set(temp_df[col])\n",
    "        fighters = sorted(fighters)\n",
    "        self.fighter_encoder.fit(np.array(fighters).reshape(-1, 1))\n",
    "        \n",
    "    def _get_covar(self, df):\n",
    "        fighter_R = fighter_encoder.transform(\n",
    "            df[\"R_fighter\"].values.reshape(-1, 1)\n",
    "        ).todense()\n",
    "        fighter_B = fighter_encoder.transform(\n",
    "            df[\"B_fighter\"].values.reshape(-1, 1)\n",
    "        ).todense()\n",
    "        n_fighters = len(fighters)\n",
    "        return torch.Tensor(fighter_R - fighter_B) \n",
    "    \n",
    "    def _get_targets(self, df):\n",
    "        y = df[\"Winner\"] == \"Red\"\n",
    "        return torch.Tensor(y.values).to(int)\n",
    "        \n",
    "    def predict(self, test_df):\n",
    "        self.model.eval()\n",
    "        self.model.likelihood.eval()\n",
    "        X = self._get_covar(test_df)\n",
    "        with gpytorch.settings.fast_pred_var(), torch.no_grad():\n",
    "            test_dist = self.model(X)\n",
    "\n",
    "            pred_samples = test_dist.sample(torch.Size((256,))).exp()\n",
    "            probabilities = (pred_samples / pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "        return probabilities[1]\n",
    "    \n",
    "gpc = GPClassifier()\n",
    "gpc.init_fighter_encoder(train_df, test_df)\n",
    "gpc.fit(train_df)\n",
    "y_hat = gpc.predict(test_df)\n",
    "\n",
    "test_y = (test_df[\"Winner\"] == \"Red\").astype(int).values\n",
    "(test_y == np.array(y_hat).round()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0935c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cb3130f",
   "metadata": {},
   "source": [
    "# Something I just realized\n",
    "\n",
    "Okay, so I will only be making predictions for the upcoming event. These elo scores will be stale afterwards. The line obviously has more information than me because it's predicting one day into the future, and I'm currently predicting possibly several months ahead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = gpc._get_covar(train_df)\n",
    "foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeVaryingEloModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, num_classes, n_fighters, time_col_ind):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        \n",
    "        batch_shape = torch.Size((num_classes,))\n",
    "        linear_active_dims = tuple(i for i in range(train_x.shape[1]) if i != time_col_ind)\n",
    "        rbf_active_dims = (time_col_ind,)\n",
    "        \n",
    "        \n",
    "        self.mean_module = ZeroMean(batch_shape=batch_shape)\n",
    "        self.covar_module = ScaleKernel(\n",
    "            LinearKernel(batch_shape=batch_shape, active_dims=linear_active_dims) + \n",
    "            RBFKernel(batch_shape=batch_shape, active_dims=rbf_active_dims),\n",
    "            batch_shape=batch_shape,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "\n",
    "class GPClassifier2(object):\n",
    "    \n",
    "    def __init__(self, training_iter=50, lr=0.1):\n",
    "        self.training_iter = training_iter\n",
    "        self.lr = lr\n",
    "        self.likelihood = None\n",
    "        self.model = None\n",
    "        self.fighter_encoder = None\n",
    "        \n",
    "    def init_model(self, X, y):\n",
    "        self.likelihood = DirichletClassificationLikelihood(y, learn_additional_noise=True)\n",
    "        self.model = TimeVaryingEloModel(X, self.likelihood.transformed_targets, \n",
    "                                    self.likelihood, num_classes=self.likelihood.num_classes,\n",
    "                                        n_fighters=self.n_fighters, time_col_ind=self.time_col_ind)\n",
    "        \n",
    "\n",
    "    def fit(self, train_df):\n",
    "        assert self.fighter_encoder is not None, \"did you forget to call init_fighter_encoder?\"\n",
    "        self.min_date = train_df[\"date\"].min()\n",
    "        X = self._get_covar(train_df)\n",
    "        y = self._get_targets(train_df)\n",
    "        print(X)\n",
    "        self.init_model(X, y)\n",
    "        self.model.train()\n",
    "        self.model.likelihood.train()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "        for i in range(training_iter):\n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            # Output from model\n",
    "            output = self.model(X)\n",
    "            # Calc loss and backprop gradients\n",
    "            loss = -mll(output, self.model.likelihood.transformed_targets).sum()\n",
    "            loss.backward()\n",
    "            if i % 5 == 0:\n",
    "                print('Iter %d/%d - Loss: %.3f   noise: %.3f' % (\n",
    "                    i + 1, training_iter, loss.item(),\n",
    "                    #self.model.covar_module.base_kernel.mean().item(),\n",
    "                    self.model.likelihood.second_noise_covar.noise.mean().item()\n",
    "                ))\n",
    "            optimizer.step()\n",
    "        \n",
    "    def init_fighter_encoder(self, train_df, test_df):\n",
    "        # note that this takes both train_df and test_df in\n",
    "        # i want to call this before calling .fit()\n",
    "        self.fighter_encoder = OneHotEncoder()\n",
    "        fighters = set()\n",
    "        for temp_df in [train_df, test_df]:\n",
    "            for col in [\"R_fighter\", \"B_fighter\"]:\n",
    "                fighters = fighters | set(temp_df[col])\n",
    "        fighters = sorted(fighters)\n",
    "        self.fighter_encoder.fit(np.array(fighters).reshape(-1, 1))\n",
    "        self.n_fighters = len(fighters)\n",
    "        self.time_col_ind = self.n_fighters\n",
    "        \n",
    "    def _get_covar(self, df):\n",
    "        fighter_R = fighter_encoder.transform(\n",
    "            df[\"R_fighter\"].values.reshape(-1, 1)\n",
    "        ).todense()\n",
    "        fighter_B = fighter_encoder.transform(\n",
    "            df[\"B_fighter\"].values.reshape(-1, 1)\n",
    "        ).todense()\n",
    "        X = torch.Tensor(fighter_R - fighter_B)\n",
    "        t = (df[\"date\"] - self.min_date).dt.days\n",
    "        t = torch.Tensor(t.values.reshape(-1,1))\n",
    "        X = torch.cat([X, t], dim=1)\n",
    "        return X\n",
    "    \n",
    "    def _get_targets(self, df):\n",
    "        y = df[\"Winner\"] == \"Red\"\n",
    "        return torch.Tensor(y.values).to(int)\n",
    "        \n",
    "    def predict(self, test_df):\n",
    "        self.model.eval()\n",
    "        self.model.likelihood.eval()\n",
    "        X = self._get_covar(test_df)\n",
    "        with gpytorch.settings.fast_pred_var(), torch.no_grad():\n",
    "            test_dist = self.model(X)\n",
    "\n",
    "            pred_samples = test_dist.sample(torch.Size((256,))).exp()\n",
    "            probabilities = (pred_samples / pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "        return probabilities[1]\n",
    "    \n",
    "gpc = GPClassifier2(lr=0.5)\n",
    "gpc.init_fighter_encoder(train_df, test_df)\n",
    "gpc.fit(train_df)\n",
    "y_hat = gpc.predict(test_df)\n",
    "\n",
    "test_y = (test_df[\"Winner\"] == \"Red\").astype(int).values\n",
    "(test_y == np.array(y_hat).round()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a15e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = gpc.predict(train_df)\n",
    "\n",
    "test_y = (train_df[\"Winner\"] == \"Red\").astype(int).values\n",
    "(test_y == np.array(y_hat).round()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391a7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df990f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2472c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4850d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import UnwhitenedVariationalStrategy\n",
    "\n",
    "\n",
    "class GPClassificationModel(ApproximateGP):\n",
    "    def __init__(self, train_x):\n",
    "        variational_distribution = CholeskyVariationalDistribution(train_x.size(0))\n",
    "        variational_strategy = UnwhitenedVariationalStrategy(\n",
    "            self, train_x, variational_distribution, learn_inducing_locations=False\n",
    "        )\n",
    "        super(GPClassificationModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        latent_pred = gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "        return latent_pred\n",
    "\n",
    "\n",
    "# Initialize model and likelihood\n",
    "model = GPClassificationModel(train_x)\n",
    "likelihood = gpytorch.likelihoods.BernoulliLikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d30563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iterations = 2 if smoke_test else 50\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "# num_data refers to the number of training datapoints\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, train_y.numel())\n",
    "\n",
    "for i in range(training_iterations):\n",
    "    # Zero backpropped gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Get predictive output\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4fbfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test x are regularly spaced by 0.01 0,1 inclusive\n",
    "    test_x = torch.linspace(0, 1, 101)\n",
    "    # Get classification predictions\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "    # Initialize fig and axes for plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "    # Get the predicted labels (probabilites of belonging to the positive class)\n",
    "    # Transform these probabilities to be 0/1 labels\n",
    "#     pred_labels = observed_pred.mean.ge(0.5).float()\n",
    "    pred_labels = observed_pred.mean.float()\n",
    "    ax.plot(test_x.numpy(), pred_labels.numpy(), 'b')\n",
    "    ax.set_ylim([-1, 2])\n",
    "    ax.legend(['Observed Data', 'Mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf00343",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f59942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "class GPWinModel(object):\n",
    "    \n",
    "    def __init__(self, sigma_alpha=1):\n",
    "        self.sigma_alpha = sigma_alpha\n",
    "        self.fighter_encoder = OneHotEncoder()\n",
    "        self.fighters = []\n",
    "        self.stan_data = None\n",
    "        self.stan_fit = None\n",
    "        \n",
    "    def fit_fighter_encoder(self, train_df, test_df):\n",
    "        # have to pool fighters in train and test\n",
    "        # careful about data leakage!\n",
    "        fighters = set()\n",
    "        for temp_df in [train_df, test_df]:\n",
    "            for col in [\"R_fighter\", \"B_fighter\"]:\n",
    "                fighters = fighters | set(temp_df[col])\n",
    "        fighters = sorted(fighters)\n",
    "        self.fighter_encoder.fit(np.array(fighters).reshape(-1, 1)) \n",
    "    \n",
    "    def fit_predict(self, train_df, test_df, mcmc=False, mcmc_iter=1000, mcmc_warmup=500):\n",
    "        self.fit_fighter_encoder(train_df, test_df)\n",
    "        # get stuff to feed into stan\n",
    "        n_fighters = len(self.fighter_encoder.categories_[0])\n",
    "        n_fights = train_df.shape[0]\n",
    "        # n_regressors\n",
    "        y = (train_df[\"Winner\"] == \"Red\").astype(int)\n",
    "        fighter_A = self.fighter_encoder.transform(train_df[\"R_fighter\"].values.reshape(-1, 1)).todense()\n",
    "        fighter_B = self.fighter_encoder.transform(train_df[\"B_fighter\"].values.reshape(-1, 1)).todense()\n",
    "        # X_A, X_B\n",
    "        fight_date = np.zeros(n_fights) # I'll figure out how to calculate this later\n",
    "        sigma_alpha = self.sigma_alpha\n",
    "        # sigma_beta\n",
    "        n_fights_test = test_df.shape[0]\n",
    "        fighter_A_test = self.fighter_encoder.transform(test_df[\"R_fighter\"].values.reshape(-1, 1)).todense()\n",
    "        fighter_B_test = self.fighter_encoder.transform(test_df[\"B_fighter\"].values.reshape(-1, 1)).todense()\n",
    "        fight_date_test = np.zeros(n_fights_test)\n",
    "        \n",
    "        stan_data = {\n",
    "            \"n_fighters\": n_fighters,\n",
    "            \"n_fights\": n_fights,\n",
    "            \"y\": y.values,\n",
    "            \"fighter_A\": fighter_A,\n",
    "            \"fighter_B\": fighter_B,\n",
    "            \"fight_date\": fight_date,\n",
    "            \"sigma_alpha\": sigma_alpha,\n",
    "            \"n_fights_test\": n_fights_test,\n",
    "            \"fighter_A_test\": fighter_A_test,\n",
    "            \"fighter_B_test\": fighter_B_test,\n",
    "            \"fight_date_test\": fight_date_test,\n",
    "        }\n",
    "        self.stan_data = stan_data\n",
    "        # Train the model and generate samples\n",
    "        if mcmc:\n",
    "            self.stan_fit = self.stan_model.sampling(\n",
    "                data=stan_data, \n",
    "                iter=mcmc_iter, warmup=mcmc_warmup,\n",
    "                chains=4, thin=1, seed=101\n",
    "            )\n",
    "        else:\n",
    "            # maybe it's convex?\n",
    "            self.stan_fit = self.stan_model.optimizing(data=stan_data)\n",
    "        return self.stan_fit\n",
    "    \n",
    "    def eval_point_preds(self, test_df):\n",
    "        y_hat = self.stan_fit[\"y_pred\"]\n",
    "        y_hat_logit = self.stan_fit[\"power_A_test\"] - self.stan_fit[\"power_B_test\"]\n",
    "        y_true = (test_df[\"Winner\"] == \"Red\").astype(int)\n",
    "\n",
    "        temp_df = pd.DataFrame({\n",
    "            \"y_hat\": y_hat,\n",
    "            \"y_hat_logit\": y_hat_logit,\n",
    "            \"y\": y_true,\n",
    "        }).sort_values(\"y_hat\")\n",
    "\n",
    "        ax = sns.scatterplot(x=\"y_hat_logit\", y=\"y\", data=temp_df)\n",
    "        ax = sns.lineplot(ax=ax, x=\"y_hat_logit\", y=\"y_hat\", data=temp_df)\n",
    "        ax.axvline(x=0, linestyle=\":\")\n",
    "        # get some metrics\n",
    "        acc = np.mean((y_hat >= 0.5) == (y_true > 0))\n",
    "        log_loss_val = log_loss(y_true=y_true, y_pred=y_hat)\n",
    "        ax.set(title=\"fight pred performance; acc=%.3f  log loss=%.3f\"%(acc, log_loss_val))\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf109ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
